This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
.config/
  constraints.txt
  dictionary.txt
  requirements-docs.in
  requirements-test.in
  requirements.in
.github/
  ISSUE_TEMPLATE/
    bug_report.md
    documentation_report.md
    feature_request.md
    security_bug_report.md
  workflows/
    ack.yml
    push.yml
    release.yml
    tox.yml
  CODE_OF_CONDUCT.md
  CODEOWNERS
  dependabot.yml
  release-drafter.yml
.sonarlint/
  connectedMode.json
docs/
  content_creation.md
  contributing.md
  index.md
  installing.md
src/
  ansible_creator/
    resources/
      collection_project/
        .github/
          workflows/
            release.yml.j2
            tests.yml.j2
        changelogs/
          config.yaml.j2
        docs/
          docsite/
            links.yml.j2
        extensions/
          eda/
            rulebooks/
              rulebook.yml.j2
          molecule/
            integration_hello_world/
              molecule.yml.j2
            utils/
              playbooks/
                converge.yml.j2
                noop.yml.j2
              vars/
                vars.yml
        meta/
          runtime.yml
        plugins/
          action/
            sample_action.py.j2
          filter/
            sample_filter.py.j2
          lookup/
            sample_lookup.py.j2
          modules/
            sample_action.py.j2
            sample_module.py.j2
          test/
            sample_test.py.j2
        tests/
          integration/
            targets/
              hello_world/
                tasks/
                  main.yml.j2
            test_integration.py.j2
          unit/
            test_basic.py.j2
          .gitignore
        .isort.cfg.j2
        .pre-commit-config.yaml.j2
        .prettierignore.j2
        CHANGELOG.rst
        CODE_OF_CONDUCT.md
        CONTRIBUTING
        galaxy.yml.j2
        LICENSE.j2
        pyproject.toml.j2
        README.md.j2
        requirements.txt
        test-requirements.txt
        tox-ansible.ini.j2
      common/
        devcontainer/
          .devcontainer/
            docker/
              devcontainer.json.j2
            podman/
              devcontainer.json.j2
            devcontainer.json.j2
        devfile/
          devfile.yaml.j2
        execution-environment/
          execution-environment.yml.j2
        gitignore/
          __meta__.yml
          .gitignore.j2
        patterns/
          sample_pattern/
            meta/
              pattern.json.j2
            playbooks/
              group_vars/
                all.yml
              site.meta.yml
              site.yml
            README.md
        play-argspec/
          inventory/
            argspec_validation_inventory.yml
          argspec_validation_plays.meta.yml
          argspec_validation_plays.yml
        role/
          roles/
            run/
              defaults/
                main.yml.j2
              handlers/
                main.yml.j2
              meta/
                argument_specs.yml.j2
                main.yml.j2
              tasks/
                main.yml.j2
              tests/
                inventory
              vars/
                main.yml.j2
              README.md.j2
        vscode/
          .vscode/
            extensions.json.j2
      execution_env_project/
        .github/
          workflows/
            ci.yml.j2
        .gitignore
        execution-environment.yml.j2
        README.md
      playbook_project/
        .github/
          workflows/
            tests.yml.j2
          ansible-code-bot.yml.j2
        collections/
          ansible_collections/
            project_org/
              project_repo/
                meta/
                  runtime.yml
                roles/
                  run/
                    tasks/
                      main.yml.j2
                    README.md.j2
                galaxy.yml.j2
                README.md.j2
          requirements.yml.j2
        inventory/
          group_vars/
            all.yml.j2
            db_servers.yml.j2
            production.yml.j2
            test.yml.j2
            web_servers.yml.j2
          host_vars/
            server1.yml.j2
            server2.yml.j2
            server3.yml.j2
            switch1.yml.j2
            switch2.yml.j2
          argspec_validation_inventory.yml
          hosts.yml.j2
        ansible-navigator.yml.j2
        ansible.cfg.j2
        argspec_validation_plays.meta.yml
        argspec_validation_plays.yml
        linux_playbook.yml.j2
        network_playbook.yml.j2
        README.md.j2
        site.yml.j2
    schemas/
      __init__.py
    subcommands/
      __init__.py
      add.py
      init.py
    __init__.py
    __main__.py
    _version.pyi
    arg_parser.py
    cli.py
    compat.py
    config.py
    constants.py
    exceptions.py
    output.py
    templar.py
    types.py
    utils.py
tests/
  fixtures/
    collection/
      testorg/
        testcol/
          .devcontainer/
            docker/
              devcontainer.json
            podman/
              devcontainer.json
            devcontainer.json
          .github/
            workflows/
              release.yml
              tests.yml
          .vscode/
            extensions.json
          changelogs/
            config.yaml
          docs/
            docsite/
              links.yml
          extensions/
            eda/
              rulebooks/
                rulebook.yml
            molecule/
              integration_hello_world/
                molecule.yml
              utils/
                playbooks/
                  converge.yml
                  noop.yml
                vars/
                  vars.yml
          meta/
            runtime.yml
          plugins/
            action/
              sample_action.py
            filter/
              sample_filter.py
            lookup/
              sample_lookup.py
            modules/
              sample_action.py
              sample_module.py
            test/
              sample_test.py
          roles/
            run/
              defaults/
                main.yml
              handlers/
                main.yml
              meta/
                argument_specs.yml
                main.yml
              tasks/
                main.yml
              tests/
                inventory
              vars/
                main.yml
              README.md
          tests/
            integration/
              targets/
                hello_world/
                  tasks/
                    main.yml
              test_integration.py
            unit/
              test_basic.py
            .gitignore
          .gitignore
          .isort.cfg
          .pre-commit-config.yaml
          .prettierignore
          CHANGELOG.rst
          CODE_OF_CONDUCT.md
          CONTRIBUTING
          devfile.yaml
          galaxy.yml
          LICENSE
          pyproject.toml
          README.md
          requirements.txt
          test-requirements.txt
          tox-ansible.ini
    common/
      execution-environment/
        execution-environment.yml
    project/
      ee_project/
        .github/
          workflows/
            ci.yml
        .gitignore
        execution-environment.yml
        README.md
      playbook_project/
        .devcontainer/
          docker/
            devcontainer.json
          podman/
            devcontainer.json
          devcontainer.json
        .github/
          workflows/
            tests.yml
          ansible-code-bot.yml
        .vscode/
          extensions.json
        collections/
          ansible_collections/
            weather/
              demo/
                meta/
                  runtime.yml
                roles/
                  run/
                    tasks/
                      main.yml
                    README.md
                galaxy.yml
                README.md
          requirements.yml
        inventory/
          group_vars/
            all.yml
            db_servers.yml
            production.yml
            test.yml
            web_servers.yml
          host_vars/
            server1.yml
            server2.yml
            server3.yml
            switch1.yml
            switch2.yml
          argspec_validation_inventory.yml
          hosts.yml
        .gitignore
        ansible-navigator.yml
        ansible.cfg
        argspec_validation_plays.meta.yml
        argspec_validation_plays.yml
        devfile.yaml
        linux_playbook.yml
        network_playbook.yml
        README.md
        site.yml
  integration/
    __init__.py
    test_init.py
    test_lint.py
  units/
    __init__.py
    test_add.py
    test_argparse_help.py
    test_basic.py
    test_compat.py
    test_init.py
    test_output.py
    test_templar.py
    test_utils.py
  __init__.py
  conftest.py
  defaults.py
tools/
  report-coverage
.gitignore
.pre-commit-config.yaml
.prettierignore
.prettierrc.yaml
.python-version
.readthedocs.yml
.sonarcloud.properties
.taplo.toml
.tool-versions
.yamllint
ansible.cfg
CHANGELOG.md
codecov.yml
cspell.config.yaml
LICENSE
mise.toml
mkdocs.yml
package.json
pyproject.toml
README.md
tox.ini

================================================================
Files
================================================================

================
File: .config/constraints.txt
================
# This file was autogenerated by uv via the following command:
#    tox run -e deps
ansible-compat==25.6.0    # via ansible-lint
ansible-lint==25.6.1      # via ansible-creator (pyproject.toml)
argcomplete==3.6.2        # via ansible-creator (pyproject.toml)
astroid==3.3.11           # via pylint
attrs==25.3.0             # via jsonschema, referencing
babel==2.17.0             # via mkdocs-material
backrefs==5.9             # via mkdocs-material
beautifulsoup4==4.13.4    # via linkchecker, mkdocs-htmlproofer-plugin
black==25.1.0             # via ansible-lint
bracex==2.6               # via wcmatch
cachetools==6.1.0         # via tox
cairocffi==1.7.1          # via cairosvg
cairosvg==2.8.2           # via mkdocs-ansible
certifi==2025.7.14        # via requests
cffi==1.17.1              # via cairocffi, cryptography
cfgv==3.4.0               # via pre-commit
chardet==5.2.0            # via tox
charset-normalizer==3.4.2  # via requests
click==8.2.1              # via black, mkdocs, pydoclint
colorama==0.4.6           # via griffe, mkdocs-material, tox
coverage==7.10.0          # via ansible-creator (pyproject.toml)
cryptography==45.0.5      # via ansible-core
csscompressor==0.9.5      # via mkdocs-minify-plugin
cssselect2==0.8.0         # via cairosvg
defusedxml==0.7.1         # via cairosvg
dill==0.4.0               # via pylint
distlib==0.4.0            # via virtualenv
dnspython==2.7.0          # via linkchecker
docstring-parser-fork==0.0.12  # via pydoclint
execnet==2.1.1            # via pytest-xdist
filelock==3.18.0          # via ansible-lint, tox, virtualenv
ghp-import==2.1.0         # via mkdocs
griffe==1.8.0             # via mkdocstrings-python
hjson==3.1.0              # via mkdocs-macros-plugin, super-collections
htmlmin2==0.1.13          # via mkdocs-minify-plugin
identify==2.6.12          # via pre-commit
idna==3.10                # via requests
importlib-metadata==8.7.0  # via ansible-lint
iniconfig==2.1.0          # via pytest
isort==6.0.1              # via pylint
jinja2==3.1.6             # via ansible-core, mkdocs, mkdocs-macros-plugin, mkdocs-material, mkdocstrings, ansible-creator (pyproject.toml)
jsmin==3.0.1              # via mkdocs-minify-plugin
jsonschema==4.25.0        # via ansible-compat, ansible-lint
jsonschema-specifications==2025.4.1  # via jsonschema
linkchecker==10.5.0       # via mkdocs-ansible
markdown==3.8.2           # via markdown-include, mkdocs, mkdocs-autorefs, mkdocs-htmlproofer-plugin, mkdocs-material, mkdocstrings, pymdown-extensions
markdown-exec==1.11.0     # via mkdocs-ansible
markdown-include==0.8.1   # via mkdocs-ansible
markupsafe==3.0.2         # via jinja2, mkdocs, mkdocs-autorefs, mkdocstrings
mccabe==0.7.0             # via pylint
mergedeep==1.3.4          # via mkdocs, mkdocs-get-deps
mkdocs==1.6.1             # via mkdocs-ansible, mkdocs-autorefs, mkdocs-gen-files, mkdocs-htmlproofer-plugin, mkdocs-macros-plugin, mkdocs-material, mkdocs-minify-plugin, mkdocs-monorepo-plugin, mkdocstrings
mkdocs-ansible==25.2.0    # via ansible-creator (pyproject.toml)
mkdocs-autorefs==1.4.2    # via mkdocstrings, mkdocstrings-python
mkdocs-gen-files==0.5.0   # via mkdocs-ansible
mkdocs-get-deps==0.2.0    # via mkdocs
mkdocs-htmlproofer-plugin==1.3.0  # via mkdocs-ansible
mkdocs-macros-plugin==1.3.7  # via mkdocs-ansible
mkdocs-material==9.6.16   # via mkdocs-ansible
mkdocs-material-extensions==1.3.1  # via mkdocs-ansible, mkdocs-material
mkdocs-minify-plugin==0.8.0  # via mkdocs-ansible
mkdocs-monorepo-plugin==1.1.2  # via mkdocs-ansible
mkdocstrings==0.30.0      # via mkdocs-ansible, mkdocstrings-python
mkdocstrings-python==1.16.12  # via mkdocs-ansible
mypy==1.17.0              # via ansible-creator (pyproject.toml)
mypy-extensions==1.1.0    # via black, mypy
nodeenv==1.9.1            # via pre-commit
packaging==25.0           # via ansible-compat, ansible-core, ansible-lint, black, mkdocs, mkdocs-macros-plugin, pyproject-api, pytest, pytest-sugar, tox
paginate==0.5.7           # via mkdocs-material
pathspec==0.12.1          # via ansible-lint, black, mkdocs, mkdocs-macros-plugin, mypy, yamllint
pillow==11.3.0            # via cairosvg, mkdocs-ansible
platformdirs==4.3.8       # via black, mkdocs-get-deps, pylint, tox, virtualenv
pluggy==1.6.0             # via pytest, tox
pre-commit==4.2.0         # via ansible-creator (pyproject.toml)
pycparser==2.22           # via cffi
pydoclint==0.6.6          # via ansible-creator (pyproject.toml)
pygments==2.19.2          # via mkdocs-material, pytest
pylint==3.3.7             # via ansible-creator (pyproject.toml)
pymdown-extensions==10.16  # via markdown-exec, mkdocs-ansible, mkdocs-material, mkdocstrings
pyproject-api==1.9.1      # via tox
pytest==8.4.1             # via pytest-instafail, pytest-plus, pytest-sugar, pytest-xdist, ansible-creator (pyproject.toml)
pytest-instafail==0.5.0   # via ansible-creator (pyproject.toml)
pytest-plus==0.8.1        # via ansible-creator (pyproject.toml)
pytest-sugar==1.0.0       # via ansible-creator (pyproject.toml)
pytest-xdist==3.8.0       # via ansible-creator (pyproject.toml)
python-dateutil==2.9.0.post0  # via ghp-import, mkdocs-macros-plugin
python-slugify==8.0.4     # via mkdocs-monorepo-plugin
pyyaml==6.0.2             # via ansible-compat, ansible-core, ansible-lint, mkdocs, mkdocs-get-deps, mkdocs-macros-plugin, pre-commit, pymdown-extensions, pyyaml-env-tag, yamllint, ansible-creator (pyproject.toml)
pyyaml-env-tag==1.1       # via mkdocs
referencing==0.36.2       # via ansible-lint, jsonschema, jsonschema-specifications
requests==2.32.4          # via linkchecker, mkdocs-htmlproofer-plugin, mkdocs-material
rpds-py==0.26.0           # via jsonschema, referencing
ruamel-yaml==0.18.14      # via ansible-lint
ruff==0.12.5              # via ansible-creator (pyproject.toml)
six==1.17.0               # via python-dateutil
soupsieve==2.7            # via beautifulsoup4
subprocess-tee==0.4.2     # via ansible-compat, ansible-lint
super-collections==0.5.3  # via mkdocs-macros-plugin
termcolor==3.1.0          # via mkdocs-macros-plugin, pytest-sugar
text-unidecode==1.3       # via python-slugify
tinycss2==1.4.0           # via cairosvg, cssselect2
toml-sort==0.24.2         # via ansible-creator (pyproject.toml)
tomlkit==0.13.3           # via pylint, toml-sort
tox==4.28.3               # via ansible-creator (pyproject.toml)
types-pyyaml==6.0.12.20250516  # via ansible-creator (pyproject.toml)
urllib3==2.5.0            # via requests
virtualenv==20.32.0       # via pre-commit, tox
watchdog==6.0.0           # via mkdocs
wcmatch==10.1             # via ansible-lint
webencodings==0.5.1       # via cssselect2, tinycss2
yamllint==1.37.1          # via ansible-lint
zipp==3.23.0              # via importlib-metadata

# The following packages were excluded from the output:
# ansible-core
# exceptiongroup
# resolvelib
# ruamel-yaml-clib
# tomli
# typing-extensions
# uv

================
File: .config/dictionary.txt
================
addopts
antsibull
argcomplete
argnames
argspec
argvalues
capsys
chakarborty
conftest
delenv
devcontainer
devcontainers
devfile
devspaces
docsite
endraw
equalto
fileh
flatmap
fqcn
hostvars
httpapi
kubedock
levelname
libera
longtude
maxsplit
myorg
myproject
myuser
netcommon
nilashish
notesdir
PYCMD
pydoclint
rulebook
rulebooks
selectattr
sshpass
sysargs
templated
templating
testcol
testname
testns
testorg
testpaths
webservers
role

================
File: .config/requirements-docs.in
================
mkdocs-ansible>=24.3.0

================
File: .config/requirements-test.in
================
ansible-lint
argcomplete
coverage[toml]
mypy
pre-commit
pydoclint
pylint
pytest
pytest-xdist
pytest-sugar
pytest-instafail
pytest-plus
ruff
toml-sort
tox
types-PyYAML
uv

================
File: .config/requirements.in
================
importlib-resources ; python_version < '3.10'
Jinja2>=3.1.2
PyYAML

================
File: .github/ISSUE_TEMPLATE/bug_report.md
================
---
name: "\U0001F41B Bug report"
about: Create a report to help us improve
labels: bug, new
---

##### ISSUE TYPE

- Bug Report

##### SUMMARY

<!-- Briefly describe the problem. -->

##### ANSIBLE-CREATOR VERSION

<!--- Paste, BELOW THIS COMMENT, verbatim output from "ansible-navigator --version" between quotes below -->

```

```

##### PYTHON VERSION

<!--- Paste output from `python --version` -->

##### LOG FILE

<!--- Paste relevant logs from the ansible-creator
      log file preferably after setting the log-level to `debug`,
      under the prompt line.
      **HINT:** You can paste https://gist.github.com links for larger files..-->

##### STEPS TO REPRODUCE

<!-- Please describe exactly how to reproduce the problem. -->

##### EXPECTED RESULTS

<!-- What did you expect to happen when running the steps above? -->

##### ACTUAL RESULTS

<!-- What actually happened? -->

##### ADDITIONAL INFORMATION

<!-- Include any links screenshots or other
additional information -->

================
File: .github/ISSUE_TEMPLATE/documentation_report.md
================
---
name: "📝 Documentation Report"
about: Ask us about docs
labels: documentation, new
---

##### ISSUE TYPE

- Doc issue

##### SUMMARY

<!-- Explain the problem briefly below, add suggestions to wording or structure. -->

================
File: .github/ISSUE_TEMPLATE/feature_request.md
================
---
name: "✨ Feature request"
about: Suggest an idea for this project
labels: enhancement, new
---

##### ISSUE TYPE

- Feature Idea

##### SUMMARY

<!-- Briefly describe the problem or desired enhancement. -->

================
File: .github/ISSUE_TEMPLATE/security_bug_report.md
================
---
name: "\U0001F525 Security bug report"
about: How to report security vulnerabilities
labels: new
---

For all security related bugs, email security@ansible.com instead of using this
issue tracker and you will receive a prompt response.

For more information on the Ansible community's practices regarding responsible
disclosure, see https://www.ansible.com/security

================
File: .github/workflows/ack.yml
================
# See https://github.com/ansible/team-devtools/blob/main/.github/workflows/ack.yml
name: ack

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

on:
  pull_request_target:
    types: [opened, labeled, unlabeled, synchronize]

jobs:
  ack:
    uses: ansible/team-devtools/.github/workflows/ack.yml@token_revised
    secrets: inherit

================
File: .github/workflows/push.yml
================
---
# See https://github.com/ansible/team-devtools/blob/main/.github/workflows/push.yml
name: push
on:
  push:
    branches:
      - main
      - "releases/**"
      - "stable/**"
  workflow_dispatch:

jobs:
  ack:
    uses: ansible/team-devtools/.github/workflows/push.yml@main

================
File: .github/workflows/release.yml
================
---
name: release

on:
  release:
    types: [published]

jobs:
  release:
    environment: release
    runs-on: ubuntu-latest
    permissions:
      id-token: write

    env:
      FORCE_COLOR: 1
      PY_COLORS: 1

    steps:
      - name: Switch to using Python 3.12 by default
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install tox
        run: python3 -m pip install --user "tox>=4.0.0"

      - name: Check out src from Git
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # needed by setuptools-scm

      - name: Build dists
        run: python3 -m tox -e pkg

      - name: Publish to pypi.org
        uses: pypa/gh-action-pypi-publish@release/v1

  forum_post:
    needs: release
    runs-on: ubuntu-latest

    steps:
      - name: Retreive the forum post script from team-devtools
        run: curl -O https://raw.githubusercontent.com/ansible/team-devtools/main/.github/workflows/forum_post.py

      - name: Run the forum post script
        run: python3 forum_post.py ${{ github.event.repository.full_name }} ${{ github.event.release.tag_name }} ${{ secrets.FORUM_KEY }} ${{ secrets.FORUM_USER }}

================
File: .github/workflows/tox.yml
================
---
name: tox

on:
  merge_group:
    branches:
      - "main"
  push:
    branches:
      - "main"
  pull_request:
    branches:
      - "main"
  schedule:
    - cron: "0 0 * * *"
  workflow_call:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}
  cancel-in-progress: true

jobs:
  tox:
    uses: ansible/team-devtools/.github/workflows/tox.yml@main
    with:
      node-version-file: .tool-versions

================
File: .github/CODE_OF_CONDUCT.md
================
# Community Code of Conduct

Please see the official
[Ansible Community Code of Conduct](https://docs.ansible.com/ansible/latest/community/code_of_conduct.html).

================
File: .github/CODEOWNERS
================
*       @ansible/devtools

================
File: .github/dependabot.yml
================
---
version: 2
updates:
  - package-ecosystem: pip
    directory: /.config/
    schedule:
      day: sunday
      interval: weekly
    labels:
      - dependabot-deps-updates
      - skip-changelog
    groups:
      dependencies:
        patterns:
          - "*"
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: daily
    labels:
      - "dependencies"
      - "skip-changelog"
  - package-ecosystem: npm
    directory: "/"
    schedule:
      interval: weekly
    labels:
      - dependabot-deps-updates
      - skip-changelog

================
File: .github/release-drafter.yml
================
---
# see https://github.com/ansible/team-devtools
_extends: ansible/team-devtools

================
File: .sonarlint/connectedMode.json
================
{
  "sonarCloudOrganization": "ansible",
  "projectKey": "ansible_ansible-creator"
}

================
File: docs/content_creation.md
================
# Creating ansible content using ansible-creator and VS Code Ansible extension

- For users who prefer a graphical interface, ansible-creator seamlessly
  integrates with the
  [Visual Studio Code (VS Code)](https://code.visualstudio.com/docs) and the
  [Ansible extension](https://marketplace.visualstudio.com/items?itemName=redhat.ansible)
  for it, offering an intuitive GUI experience.

- By navigating to the Ansible section in the VS Code activity bar and selecting
  "Ansible Development Tools," users can access a menu-driven interface.

- This GUI provides interactive forms for straightforward input. So you can
  effortlessly manage your Ansible content without delving into the intricacies
  of command-line operations.

- Here is a detailed
  [guide](https://ansible.readthedocs.io/projects/vscode-ansible/) on creating
  an ansible content using the ansible-creator and VS Code Ansible extension.

#TO-DO: Add VS Code extension guide here when its available.

================
File: docs/contributing.md
================
# Contributing to ansible-creator

To actively contribute to the development and enhancement of ansible-creator,
your participation is valued. Please use pull requests on a branch of your own
fork. After
[creating your fork on GitHub](https://docs.github.com/en/get-started/quickstart/contributing-to-projects),
you can do:

```console
$ git clone --recursive git@github.com:your-name/ansible-creator
$ cd ansible-creator
$ git checkout -b your-branch-name

# DO SOME CODING HERE

$ git add your new files
$ git commit -v
$ git push origin your-branch-name
```

You will then be able to create a pull request from your commit. This will
initiate the process of reviewing and merging your contributions.

For contributions affecting core functionality (i.e., anything except docs or
examples), ensure to include corresponding tests that validate the changes. Even
if you're not providing a code fix, your input is valuable—feel free to raise
[issues](https://github.com/ansible/ansible-creator/issues) in the repository.

## Standards

All pull requests undergo automated tests. To ensure that your changes align
with project standards, run checks locally before pushing commits using
[tox](https://tox.wiki/en/latest/).

## Get in touch

Connect with the ansible-creator community!

Join the Ansible forum to ask questions, get help, and interact with us.

- [Get Help](https://forum.ansible.com/c/help/6): get help or help others.
  Please add appropriate tags if you start new discussions, for example the
  `ansible-creator` or `devtools` tags.
- [Social Spaces](https://forum.ansible.com/c/chat/4): meet and interact with
  fellow enthusiasts.
- [News & Announcements](https://forum.ansible.com/c/news/5): track project-wide
  announcements including social events.

To get release announcements and important changes from the community, see the
[Bullhorn newsletter](https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn).

If you encounter security-related concerns, report them via email to
[security@ansible.com](mailto:security@ansible.com).

## Code of Conduct

As with all Ansible projects, adhere to the
[Code of Conduct](https://docs.ansible.com/ansible/latest/community/code_of_conduct.html)
to foster a respectful and inclusive collaborative environment. Your
contributions, feedback, and engagement are essential to the success of
ansible-creator.

================
File: docs/index.md
================
---
hide:
  - navigation
  - toc
---

# Welcome to Ansible-Creator Documentation

The `ansible-creator` is a Command-Line Interface (CLI) tool designed for
effortlessly scaffolding all your Ansible content. Whether you are initializing
an Ansible Collection or creating the framework for specific plugins, this tool
streamlines the process with efficiency and precision based on your
requirements.

This documentation serves as a detailed guide for using ansible-creator,
emphasizing the 'init' and 'add' functionalities. The 'init' functionality
initializes a new Ansible project whereas 'add' enables you to add resources to
an existing ansible project.

## Licensing

**ansible-creator** is licensed under the Apache License version 2. Refer to the
[LICENSE](http://www.apache.org/licenses/LICENSE-2.0) file for the full text.

================
File: docs/installing.md
================
# Installation and Usage

ansible-creator provides two main functionalities: `init` and `add`. The `init`
command allows you to initialize an Ansible project, while `add` command allows
you to add resources to an existing ansible project.

## Installation

{{ install_from_adt('ansible-creator') }}

To install ansible-creator, use the following pip command:

```console
$ pip install ansible-creator
```

## CLI Usage

The Command-Line Interface (CLI) for ansible-creator provides a straightforward
and efficient way to interact with the tool. Users can initiate actions, such as
initializing Ansible Collections and other Ansible Projects, through concise
commands. The CLI is designed for simplicity, allowing users to execute
operations with ease and without the need for an extensive understanding of the
tool's intricacies. It serves as a flexible and powerful option for users who
prefer command-line workflows, enabling them to integrate ansible-creator
seamlessly into their development processes.

If command line is not your preferred method, you can also leverage the GUI
interface within VS Code's Ansible extension that offers a more visually
intuitive experience of ansible-creator. See [here](content_creation.md).

## Command line completion

`ansible-creator` has experimental command line completion for common shells.
Please ensure you have the `argcomplete` package installed and configured.

```shell
$ pip install argcomplete --user
$ activate-global-python-argcomplete --user
```

### General Usage

Get an overview of available commands and options by running:

```console
$ ansible-creator --help
```

## Initialize projects

### Initialize Ansible collection project

The `init collection` command enables you to initialize an Ansible collection
project. Use the following command template:

```console
$ ansible-creator init collection <collection-name> <path>
```

#### Positional Arguments

| Parameter       | Description                                             |
| --------------- | ------------------------------------------------------- |
| collection-name | The collection name in the format '<namespace>.<name>'. |
| path            | The destination directory for the collection project.   |

#### Optional Arguments

| Short flag | Long flag      | Flag argument | Description                                                                                                                              |
| ---------- | -------------- | ------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| -f         | --force        |               | Force re-initialize the specified directory as an Ansible collection. This flag is deprecated and will be removed soon. (default: False) |
| -o         | --overwrite    |               | Overwrites existing files or directories. (default: False)                                                                               |
| -no        | --no-overwrite |               | Restricts the overwriting operation for files or directories. (default: False)                                                           |
|            | --json         |               | Output messages as JSON (default: False)                                                                                                 |
| --la       | --log-append   | bool          | Append to log file. (choices: true, false) (default: true)                                                                               |
| --lf       | --log-file     | file          | Log file to write to. (default: ./ansible-creator.log)                                                                                   |
| --ll       | --log-level    | level         | Log level for file output. (choices: notset, debug, info, warning, error, critical) (default: notset)                                    |
| --na       | --no-ansi      |               | Disable the use of ANSI codes for terminal color. (default: False)                                                                       |
| -h         | --help         |               | Show this help message and exit                                                                                                          |
| -v         | --verbosity    |               | Give more Cli output. Option is additive, and can be used up to 3 times. (default: 0)                                                    |

#### Example

```console
$ ansible-creator init collection testns.testname $HOME/collections/ansible_collections
```

This command will scaffold the collection `testns.testname` at
`/home/ansible-dev/collections/ansible_collections/testns/testname`

#### Generated Ansible Collection Structure

Running the `init collection` command generates an Ansible collection project
with a comprehensive directory structure. Explore it using:

```console
$ tree -lla /home/ansible-dev/collections/ansible_collections/testns/testname
.
├── CHANGELOG.rst
├── changelogs
│   └── config.yaml
├── CODE_OF_CONDUCT.md
├── CONTRIBUTING
├── .devcontainer
│   ├── devcontainer.json
│   ├── docker
│   │   └── devcontainer.json
│   └── podman
│       └── devcontainer.json
├── devfile.yaml
├── docs
│   ├── docsite
│   │   └── links.yml
│   └── .keep
├── extensions
│   ├── eda
│   │   └── rulebooks
│   │       └── rulebook.yml
│   └── molecule
│       ├── integration_hello_world
│       │   └── molecule.yml
│       └── utils
│           ├── playbooks
│           │   ├── converge.yml
│           │   └── noop.yml
│           └── vars
│               └── vars.yml
├── galaxy.yml
├── .github
│   └── workflows
│       ├── release.yml
│       └── test.yml
├── .isort.cfg
├── LICENSE
├── MAINTAINERS
├── meta
│   └── runtime.yml
├── plugins
│   ├── action
│   │   ├── sample_action.py
│   │   └── __init__.py
│   ├── cache
│   │   └── __init__.py
│   ├── lookup
│   │   ├── sample_lookup.py
│   │   └── __init__.py
│   ├── filter
│   │   ├── sample_filter.py
│   │   └── __init__.py
│   ├── inventory
│   │   └── __init__.py
│   ├── modules
│   │   ├── sample_module.py
│   │   ├── sample_action.py
│   │   └── __init__.py
│   ├── module_utils
│   │   └── __init__.py
│   ├── plugin_utils
│   │   └── __init__.py
│   ├── sub_plugins
│   │   └── __init__.py
│   ├── test
│   │   ├── sample_test.py
│   │   └── __init__.py
├── .pre-commit-config.yaml
├── .prettierignore
├── pyproject.toml
├── README.md
├── roles
│   └── run
│       ├── defaults
│       │   └── main.yml
│       ├── files
│       │   └── .keep
│       ├── handlers
│       │   └── main.yaml
│       ├── meta
│       │   └── main.yml
│       ├── README.md
│       ├── tasks
│       │   └── main.yml
│       ├── templates
│       │   └── .keep
│       ├── tests
│       │   └── inventory
│       ├── vars
│       │   └── main.yml
├── tests
│   ├── .gitignore
│   ├── integration
│   │   ├── __init__.py
│   │   ├── targets
│   │   │   └── hello_world
│   │   │       └── tasks
│   │   │           └── main.yml
│   │   └── test_integration.py
│   └── unit
│       └── .keep
└── .vscode
    └── extensions.json
```

**Note:**

The scaffolded collection includes a `sample_filter` filter plugin, along with a
molecule scenario and an integration test target for it, that can be run using
`pytest`. This serves as an example for you to refer when writing tests for your
Ansible plugins and can be removed when it is no longer required.

To run the `hello_world` integration test, follow these steps:

- Git initialize the repository containing the scaffolded collection with
  `git init`.
- `pip install ansible-dev-tools`.
- Invoke `pytest` from collection root.

### Initialize Ansible playbook project

The `init playbook` command enables you to initialize an Ansible playbook
project. Use the following command template:

```console
$ ansible-creator init playbook <collection-name> <path>
```

#### Positional Arguments

| Parameter       | Description                                                                       |
| --------------- | --------------------------------------------------------------------------------- |
| collection-name | The name for the playbook adjacent collection in the format '<namespace>.<name>'. |
| path            | The destination directory for the playbook project.                               |

#### Optional Arguments

| Short flag | Long flag      | Flag argument | Description                                                                                                                              |
| ---------- | -------------- | ------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| -f         | --force        |               | Force re-initialize the specified directory as an Ansible collection. This flag is deprecated and will be removed soon. (default: False) |
| -o         | --overwrite    |               | Overwrites existing files or directories. (default: False)                                                                               |
| -no        | --no-overwrite |               | Restricts the overwriting operation for files or directories. (default: False)                                                           |
|            | --json         |               | Output messages as JSON (default: False)                                                                                                 |
| --la       | --log-append   | bool          | Append to log file. (choices: true, false) (default: true)                                                                               |
| --lf       | --log-file     | file          | Log file to write to. (default: ./ansible-creator.log)                                                                                   |
| --ll       | --log-level    | level         | Log level for file output. (choices: notset, debug, info, warning, error, critical) (default: notset)                                    |
| --na       | --no-ansi      |               | Disable the use of ANSI codes for terminal color. (default: False)                                                                       |
| -h         | --help         |               | Show this help message and exit                                                                                                          |
| -v         | --verbosity    |               | Give more Cli output. Option is additive, and can be used up to 3 times. (default: 0)                                                    |

Example:

```console
$ ansible-creator init playbook myorg.myproject $HOME/ansible-projects/playbook-project
```

This command will scaffold the new Ansible playbook project at
`/home/user/ansible-projects/playbook-project`.

#### Generated Ansible playbook project Structure

Running the `init playbook` command generates an Ansible playbook project with a
comprehensive directory structure. Explore it using:

```console
$ tree -la /home/user/ansible-projects/playbook-project
.
├── ansible.cfg
├── ansible-navigator.yml
├── collections
│   ├── ansible_collections
│   │   └── myorg
│   │       └── myproject
│   │           ├── README.md
│   │           └── roles
│   │               └── run
│   │                   ├── README.md
│   │                   └── tasks
│   │                       └── main.yml
│   └── requirements.yml
├── .devcontainer
│   ├── devcontainer.json
│   ├── docker
│   │   └── devcontainer.json
│   └── podman
│       └── devcontainer.json
├── devfile.yaml
├── .github
│   ├── ansible-code-bot.yml
│   └── workflows
│       └── tests.yml
├── inventory
│   ├── group_vars
│   │   ├── all.yml
│   │   └── web_servers.yml
│   ├── hosts.yml
│   └── host_vars
│       ├── server1.yml
│       ├── server2.yml
│       ├── server3.yml
│       ├── switch1.yml
│       └── switch2.yml
├── linux_playbook.yml
├── network_playbook.yml
├── README.md
├── site.yml
└── .vscode
    └── extensions.json
```

It also comes equipped with Github Action Workflows that use
[ansible-content-actions](https://github.com/marketplace/actions/ansible-content-actions)
for testing and publishing the collection. For details on how to use these,
please refer to the following:

- [Using the testing workflow](https://ansible.readthedocs.io/projects/dev-tools/user-guide/ci-setup/)
- [Using the release workflow](https://ansible.readthedocs.io/projects/dev-tools/user-guide/content-release/)

Please ensure that you review any potential `TO-DO` items in the scaffolded
content and make the necessary modifications according to your requirements.

### Initialize execution environment project

The `init execution_env` command enables you to initialize an Ansible execution
environment project. Use the following command template:

```console
$ ansible-creator init execution_env <path>
```

Example:

```console
$ ansible-creator init execution_env $HOME/ansible-projects/ee-project
```

This command will scaffold the new execution environment playbook project at
`/home/user/ansible-projects/ee-project`.

#### Generated Ansible execution environment project Structure

Running the `init execution_env` command generates an Ansible execution
environment project with a comprehensive directory structure. Explore it using:

```console
$ tree -la /home/user/ansible-projects/ee-project
.
├── .github
│   └── workflows
│       └── ci.yml
├── .gitignore
├── README.md
└── execution-environment.yml
```

## Add resources

The `add` subcommand allows users to scaffold content types like resources and
plugins into an existing project. This feature is designed to streamline the
development environment setup by automatically generating the necessary
configuration files.

### General Usage

Get an overview of available commands and options by running:

```console
$ ansible-creator add --help
```

#### Positional Arguments

| Parameter | Description                                   |
| --------- | --------------------------------------------- |
| resource  | Add resources to an existing Ansible project. |
| plugin    | Add a plugin to an Ansible collection.        |

#### Optional Arguments

| Short flag | Long flag | Flag argument | Description                      |
| ---------- | --------- | ------------- | -------------------------------- |
| -h         | --help    |               | Show this help message and exit. |

### Add resource to an existing project

The `add resource` command enables you to add a resource to an already existing
project. Use the following command template:

```console
$ ansible-creator add resource <resource-type> <path>
```

#### Positional Arguments

| Parameter             | Description                                                        |
| --------------------- | ------------------------------------------------------------------ |
| devcontainer          | Add devcontainer files to an existing Ansible project.             |
| devfile               | Add a devfile file to an existing Ansible project.                 |
| execution-environment | Add a sample execution-environment.yml file to an existing path.   |
| pattern               | Add a pattern structure to an existing Ansible collection.         |
| play-argspec          | Add playbook argspec examples file to an existing Ansible project. |
| role                  | Add a role to an existing Ansible collection.                      |

#### Example of adding a resource

```console
$ ansible-creator add resource devcontainer /home/user/..path/to/your/existing_project
```

This command will scaffold the devcontainer directory at
`/home/user/..path/to/your/existing_project`

### Add plugins to an existing ansible collection

The `add plugin` command enables you to add a plugin to an existing collection
project. Use the following command template:

```console
$ ansible-creator add plugin <plugin-type> <plugin-name> <collection-path>
```

#### Positional Arguments

| Parameter | Description                                             |
| --------- | ------------------------------------------------------- |
| action    | Add an action plugin to an existing Ansible Collection. |
| filter    | Add a filter plugin to an existing Ansible Collection.  |
| lookup    | Add a lookup plugin to an existing Ansible Collection.  |
| module    | Add a generic module to an existing Ansible Collection. |
| test      | Add a test plugin to an existing Ansible Collection.    |

#### Example of adding a plugin

```console
$ ansible-creator add plugin action test_plugin /home/user/..path/to/your/existing_collection
```

This command will scaffold an action plugin at
`/home/user/..path/to/your/existing_collection`

================
File: src/ansible_creator/resources/collection_project/.github/workflows/release.yml.j2
================
---
name: Release {{ namespace }}.{{ collection_name }}
{% raw %}
on: # yamllint disable-line rule:truthy
  release:
    types: [published]

jobs:
  release_automation_hub:
    uses: ansible/ansible-content-actions/.github/workflows/release_galaxy.yaml@main
    with:
      environment: release
    secrets:
      ansible_galaxy_api_key: ${{ secrets.ANSIBLE_GALAXY_API_KEY }}
{%- endraw %}

================
File: src/ansible_creator/resources/collection_project/.github/workflows/tests.yml.j2
================
---
name: "CI"
{% raw %}
concurrency:
  group: ${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

on: # yamllint disable-line rule:truthy
  pull_request:
    branches: [main]
  workflow_dispatch:
  # TO-DO: Below is an example cron scheduler. Uncomment and tweak it as per your requirement
  # schedule:
    # - cron: '0 0 * * *'

jobs:
  changelog:
    uses: ansible/ansible-content-actions/.github/workflows/changelog.yaml@main
    if: github.event_name == 'pull_request'
  build-import:
    uses: ansible/ansible-content-actions/.github/workflows/build_import.yaml@main
  ansible-lint:
    uses: ansible/ansible-content-actions/.github/workflows/ansible_lint.yaml@main
  sanity:
    uses: ansible/ansible-content-actions/.github/workflows/sanity.yaml@main
  unit-galaxy:
    uses: ansible/ansible-content-actions/.github/workflows/unit.yaml@main
  unit-source:
    uses: ansible-network/github_actions/.github/workflows/unit_source.yml@main
    with:
      collection_pre_install: >-
        git+https://github.com/ansible-collections/ansible.utils.git
  all_green:
    if: ${{ always() }}
    needs:
      - changelog
      - build-import
      - sanity
      - unit-galaxy
      - unit-source
      - ansible-lint
    runs-on: ubuntu-latest
    steps:
      - run: >-
          python -c "assert 'failure' not in
          set([
          '${{ needs.changelog.result }}',
          '${{ needs.sanity.result }}',
          '${{ needs.unit-galaxy.result }}'
          '${{ needs.ansible-lint.result }}'
          '${{ needs.unit-source.result }}'
          ])"
{%- endraw %}

================
File: src/ansible_creator/resources/collection_project/changelogs/config.yaml.j2
================
---
changelog_filename_template: ../CHANGELOG.rst
changelog_filename_version_depth: 0
changes_file: changelog.yaml
changes_format: combined
keep_fragments: false
mention_ancestor: true
new_plugins_after_name: removed_features
notesdir: fragments
prelude_section_name: release_summary
prelude_section_title: Release Summary
flatmap: true
sections:
  - - major_changes
    - Major Changes
  - - minor_changes
    - Minor Changes
  - - breaking_changes
    - Breaking Changes / Porting Guide
  - - deprecated_features
    - Deprecated Features
  - - removed_features
    - Removed Features (previously deprecated)
  - - security_fixes
    - Security Fixes
  - - bugfixes
    - Bugfixes
  - - known_issues
    - Known Issues
  - - doc_changes
    - Documentation Changes
title: "{{ namespace|capitalize }} {{ collection_name|capitalize }} Collection"
trivial_section_name: trivial

================
File: src/ansible_creator/resources/collection_project/docs/docsite/links.yml.j2
================
---
# This will make sure that plugin and module documentation gets Edit on GitHub links
# that allow users to directly create a PR for this plugin or module in GitHub's UI.
# Remove this section if the collection repository is not on GitHub, or if you do not
# want this functionality for your collection.
edit_on_github:
  # TO-DO: Update this if your collection lives in a different GitHub organization.
  repository: ansible-collections/{{ namespace }}.{{ collection_name }}
  branch: main
  # If your collection root (the directory containing galaxy.yml) does not coincide with your
  # repository's root, you have to specify the path to the collection root here. For example,
  # if the collection root is in a subdirectory ansible_collections/community/REPO_NAME
  # in your repository, you have to set path_prefix to 'ansible_collections/community/REPO_NAME'.
  path_prefix: ""

# Here you can add arbitrary extra links. Please keep the number of links down to a
# minimum! Also please keep the description short, since this will be the text put on
# a button.
#
# Also note that some links are automatically added from information in galaxy.yml.
# The following are automatically added:
#   1. A link to the issue tracker (if `issues` is specified);
#   2. A link to the homepage (if `homepage` is specified and does not equal the
#      `documentation` or `repository` link);
#   3. A link to the collection's repository (if `repository` is specified).

extra_links:
  - description: Report an issue
    # TO-DO: Update this if your collection lives in a different GitHub organization.
    url: https://github.com/ansible-collections/{{ namespace }}.{{ collection_name }}/issues/new/choose

# Specify communication channels for your collection. We suggest to not specify more
# than one place for communication per communication tool to avoid confusion.
communication:
  forum:
    - topic: Ansible Forum
      url: https://forum.ansible.com/

================
File: src/ansible_creator/resources/collection_project/extensions/eda/rulebooks/rulebook.yml.j2
================
---
- name: Hello Events
  hosts: localhost
  sources:
    - ansible.eda.range:
        limit: 5
  rules:
    - name: Say Hello
      condition: event.i == 1
      action:
        run_playbook:
          name: ansible.eda.hello

================
File: src/ansible_creator/resources/collection_project/extensions/molecule/integration_hello_world/molecule.yml.j2
================
{% raw %}---
platforms:
  - name: na

provisioner:
  name: ansible
  playbooks:
    cleanup: ../utils/playbooks/noop.yml
    converge: ../utils/playbooks/converge.yml
    destroy: ../utils/playbooks/noop.yml
    prepare: ../utils/playbooks/noop.yml
  config_options:
    defaults:
      collections_path: ${ANSIBLE_COLLECTIONS_PATH}
scenario:
  test_sequence:
    - prepare
    - converge
  destroy_sequence:
    - destroy
{%- endraw %}

================
File: src/ansible_creator/resources/collection_project/extensions/molecule/utils/playbooks/converge.yml.j2
================
{% raw %}---
- name: Shared integration test runner
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Load the vars
      ansible.builtin.include_vars:
        file: ../../utils/vars/vars.yml

    - name: "Integration test: {{ test_name }}"
      ansible.builtin.include_role:
        name: "{{ test_path }}"
      vars:
        test_path: "{{ integration_tests_path }}{{ test_name }}"
        test_name: "{{ molecule_scenario_name.replace('integration_', '') }}"
{%- endraw %}

================
File: src/ansible_creator/resources/collection_project/extensions/molecule/utils/playbooks/noop.yml.j2
================
---
- name: No-op
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Run a noop
      ansible.builtin.debug:
        msg: "This does nothing!"

================
File: src/ansible_creator/resources/collection_project/extensions/molecule/utils/vars/vars.yml
================
collection_root: "{{ lookup('env', 'MOLECULE_PROJECT_DIRECTORY') }}/.."
integration_tests_path: "{{ collection_root }}/tests/integration/targets/"
molecule_scenario_name: "{{ molecule_scenario_directory | basename }}"

================
File: src/ansible_creator/resources/collection_project/meta/runtime.yml
================
---
requires_ansible: ">=2.15.0"

================
File: src/ansible_creator/resources/collection_project/plugins/action/sample_action.py.j2
================
{# action_plugin_template.j2 #}
{%- set action_name = plugin_name | default("sample_action",true) -%}
{%- set author = author | default("Your Name") -%}
{%- set description = description | default("A custom action plugin for Ansible.") -%}
{%- set license = license | default("GPL-3.0-or-later") -%}
# {{ action_name }}.py - {{ description }}
# Author: {{ author }}
# License: {{ license }}
# pylint: disable=E0401

from __future__ import absolute_import, annotations, division, print_function

__metaclass__ = type  # pylint: disable=C0103

from typing import TYPE_CHECKING
from ansible_collections.ansible.utils.plugins.module_utils.common.argspec_validate import (  # type: ignore
    AnsibleArgSpecValidator,
)
from ansible_collections.ansible.utils.plugins.modules.fact_diff import DOCUMENTATION  # type: ignore
from ansible.plugins.action import ActionBase  # type: ignore


if TYPE_CHECKING:
    from typing import Optional, Dict, Any


class ActionModule(ActionBase):  # type: ignore[misc]
    """
    Custom Ansible action plugin: {{ action_name }}
    A custom action plugin for Ansible.
    """

    def _check_argspec(self, result: dict[str, Any]) -> None:
        aav = AnsibleArgSpecValidator(
            data=self._task.args,
            schema=DOCUMENTATION,
            schema_format="doc",
            name=self._task.action,
        )
        valid, errors, self._task.args = aav.validate()
        if not valid:
            result["failed"] = True
            result["msg"] = errors

    def run(
        self,
        tmp: Optional[str] = None,
        task_vars: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Executes the action plugin.

        Args:
            tmp: Temporary path provided by Ansible for the module execution. Defaults to None.
            task_vars: Dictionary of task variables available to the plugin. Defaults to None.

        Returns:
            dict: Result of the action plugin execution.
        """
        # Get the task arguments
        if task_vars is None:
            task_vars = {}
        result: Dict[str, Any] = {}
        warnings: list[str] = []

        # Example processing logic - Replace this with actual action code
        result = super(ActionModule, self).run(tmp, task_vars)
        self._check_argspec(result)

        # Copy the task arguments
        module_args = self._task.args.copy()

        prefix = module_args.get("prefix", "DefaultPrefix")
        message = module_args.get("msg", "No message provided")
        module_args["msg"] = f"{prefix}: {message}"

        result.update(
            self._execute_module(
                module_name="debug",
                module_args=module_args,
                task_vars=task_vars,
                tmp=tmp,
            ),
        )

        if warnings:
            if "warnings" in result:
                result["warnings"].extend(warnings)
            else:
                result["warnings"] = warnings
        return result

================
File: src/ansible_creator/resources/collection_project/plugins/filter/sample_filter.py.j2
================
{# filter_plugin_template.j2 #}
{%- set filter_name = plugin_name | default("sample_filter",true) -%}
{%- set author = author | default("Your Name") -%}
{%- set description = description | default("A custom filter plugin for Ansible.") -%}
{%- set license = license | default("GPL-3.0-or-later") -%}
# {{ filter_name }}.py - {{ description }}
# Author: {{ author }}
# License: {{ license }}

from __future__ import absolute_import, annotations, division, print_function


__metaclass__ = type  # pylint: disable=C0103

from typing import TYPE_CHECKING


if TYPE_CHECKING:
    from typing import Callable


DOCUMENTATION = """
    name: {{ filter_name }}
    author: {{ author }}
    version_added: "1.0.0"
    short_description: {{ description }}
    description:
      - This is a demo filter plugin designed to return Hello message.
    options:
      name:
        description: Value specified here is appended to the Hello message.
        type: str
"""

EXAMPLES = """
# {{ filter_name }} filter example
{% raw %}
- name: Display a hello message
  ansible.builtin.debug:
    msg: "{{ 'ansible-creator' {%- endraw %} | {{ filter_name }} }}"
"""


def _sample_filter(name: str) -> str:
    """Returns Hello message.

    Args:
        name: The name to greet.

    Returns:
        str: The greeting message.
    """
    return "Hello, " + name


class FilterModule:
    """filter plugin."""

    def filters(self) -> dict[str, Callable[[str], str]]:
        """Map filter plugin names to their functions.

        Returns:
            dict: The filter plugin functions.
        """
        return {"{{ filter_name }}": _sample_filter}

================
File: src/ansible_creator/resources/collection_project/plugins/lookup/sample_lookup.py.j2
================
{# lookup_plugin_template.j2 #}
{%- set lookup_name = plugin_name | default("sample_lookup",true) -%}
{%- set author = author | default("Your Name (@username)") -%}
{%- set description = description | default("A custom lookup plugin for Ansible.") -%}
{%- set license = license | default("GPL-3.0-or-later") -%}
# {{ lookup_name }}.py - {{ description }}

# pylint: disable=E0401
# {{ lookup_name }}.py - {{ description }}
# Author: {{ author }}
# Copyright 2020 Red Hat
# GNU General Public License v3.0+
# (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

DOCUMENTATION = """
    name: {{ lookup_name }}
    author: {{ author }}
    version_added: "1.0.0"
    short_description: {{ description }}
    description:
      - This is a custom lookup plugin to provide lookup functionality.
    options:
      _terms:
        description: Terms to lookup
        required: True
    notes:
      - This is a scaffold template. Customize the plugin to fit your needs.
"""

EXAMPLES = """
- name: Example usage of {{ lookup_name }}
{%- raw %}
  ansible.builtin.debug:
    msg: "{{ lookup('{%- endraw %}{{ lookup_name }}', 'example_term') }}"
"""

RETURN = """
_list:
  description: The list of values found by the lookup
  type: list
"""

from typing import Any, Dict, List, Optional

from ansible.errors import AnsibleError  # type: ignore
from ansible.plugins.lookup import LookupBase  # type: ignore
from ansible.utils.display import Display  # type: ignore

display = Display()


class LookupModule(LookupBase):  # type: ignore[misc]
    """
    Custom Ansible lookup plugin: {{ lookup_name }}
    A custom lookup plugin for Ansible.
    """

    def run(
        self,
        terms: List[str],
        variables: Optional[Dict[str, Any]] = None,
        **kwargs: Dict[str, Any],
    ) -> list[str]:
        """
        Run the lookup with the specified terms.

        Args:
            terms: A list of terms to lookup.
            variables: Additional variables.
            **kwargs: Additional keyword arguments.

        Returns:
            list: A list of processed results.

        Raises:
            AnsibleError: If the 'terms' parameter is not a list.
        """
        if not isinstance(terms, list):
            raise AnsibleError("The 'terms' parameter must be a list.")

        display.vvv(f"Running {{ lookup_name }} lookup plugin with terms: {terms}")

        try:
            # Example processing logic - Replace this with actual lookup code
            result = [term.upper() for term in terms]

            display.vvv(f"Result from {{ lookup_name }} lookup: {result}")
            return result

        except Exception as e:
            raise AnsibleError(f"Error in {{ lookup_name }} plugin: {e}") from e

================
File: src/ansible_creator/resources/collection_project/plugins/modules/sample_action.py.j2
================
{%- set module_name = plugin_name | default("sample_action",true) -%}
{%- set author = author | default("Your Name (@username)") -%}
# {{ module_name }}.py
# GNU General Public License v3.0+

DOCUMENTATION = """
    module: {{ module_name }}
    author: {{ author }}
    version_added: "1.0.0"
    short_description: A custom action plugin for Ansible.
    description:
      - This is a custom action plugin to provide action functionality.
    options:
      prefix:
        description:
          - A string that is added as a prefix to the message passed to the module.
        type: str
      msg:
        description: The message to display in the output.
        type: str
      with_prefix:
        description:
          - A boolean flag indicating whether to include the prefix in the message.
        type: bool
    notes:
      - This is a scaffold template. Customize the plugin to fit your needs.
"""

EXAMPLES = """
- name: Example Action Plugin
  hosts: localhost
  tasks:
    - name: Example {{ module_name }} plugin
      with_prefix:
        prefix: "Hello, World"
        msg: "Ansible!"
"""

================
File: src/ansible_creator/resources/collection_project/plugins/modules/sample_module.py.j2
================
{# module_plugin_template.j2 #}
{%- set module_name = plugin_name | default("sample_module",true) -%}
{%- set author = author |  default("Your Name (@username)") -%}
{%- set description = description | default("A custom module plugin for Ansible.") -%}
{%- set license = license | default("GPL-3.0-or-later") -%}
#!/usr/bin/python
# pylint: disable=E0401
# {{ module_name }}.py - {{ description }}
# Author: {{ author }}
# License: {{ license }}
# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import absolute_import, annotations, division, print_function


DOCUMENTATION = """
    module: {{ module_name }}
    author: {{ author }}
    version_added: "1.0.0"
    short_description: {{ description }}
    description:
      - This is a demo module plugin designed to return Hello message.
    options:
      name:
        description: Value specified here is appended to the Hello message.
        type: str
        required: true
"""

EXAMPLES = """
- name: Run the module
  register: result
  {{ module_name }}:
    name: "ansible-creator"

- name: Display the message
  ansible.builtin.debug:
    msg: result.message
"""

RETURN = """
message:
  description:
  - A demo message.
  type: str
  returned: always
  sample: "Hello, ansible-creator"
"""


__metaclass__ = type  # pylint: disable=C0103

from typing import TYPE_CHECKING

from ansible.module_utils.basic import AnsibleModule  # type: ignore


if TYPE_CHECKING:
    from typing import Callable


def _sample_module(name: str) -> str:
    """Returns Hello message.

    Args:
        name: The name to greet.

    Returns:
        str: The greeting message.
    """
    return "Hello, " + name


def main() -> None:
    """Entry point for module execution"""
    argument_spec = dict(
        name=dict(type="str", required=True),
    )
    module = AnsibleModule(
        argument_spec=argument_spec,
    )

    message = _sample_module(module.params["name"])

    result = {
        "changed": False,
        "message": message,
    }
    module.exit_json(**result)


if __name__ == "__main__":
    main()

================
File: src/ansible_creator/resources/collection_project/plugins/test/sample_test.py.j2
================
{# test_plugin_template.j2 #}
{%- set test_name = plugin_name | default("sample_test",true) -%}
{%- set author = author | default("Your Name") -%}
{%- set description = description | default("A custom test plugin for Ansible.") -%}
{%- set license = license | default("GPL-3.0-or-later") -%}
# {{ test_name }}.py - {{ description }}
# Author: {{ author }}
# License: {{ license }}

from __future__ import absolute_import, annotations, division, print_function


__metaclass__ = type  # pylint: disable=C0103

from typing import TYPE_CHECKING


if TYPE_CHECKING:
    from typing import Callable


DOCUMENTATION = """
    name: {{ test_name }}
    author: {{ author }}
    version_added: "1.0.0"
    short_description: {{ description }}
    description:
      - This is a demo test plugin designed to return a bool.
    options:
      name:
        type: bool
        description: This is a sample option.
"""

EXAMPLES = """
# {{ test_name }} test example
{% raw %}
- name: Display a bool
  ansible.builtin.debug:
    msg: "{{ 50 {%- endraw %} | {{ test_name }} }}"
"""


def _sample_test(val: int) -> bool:
    """Returns a bool.

    Args:
        val: The value to test.

    Returns:
        bool: The result.
    """
    return val > 42


class TestModule:
    """test plugin."""

    def tests(self) -> dict[str, Callable[[int], bool]]:
        """Map test plugin names to their functions.

        Returns:
            dict: The test plugin functions.
        """
        return {"{{ test_name }}": _sample_test}

================
File: src/ansible_creator/resources/collection_project/tests/integration/targets/hello_world/tasks/main.yml.j2
================
---
- name: Test the Hello World filter plugin
  ansible.builtin.set_fact:
    msg: {% raw %}"{{ 'ansible-creator' | {% endraw %}{{ namespace }}.{{ collection_name }}.{% raw %}sample_filter }}"{% endraw %}

- name: Assert that the filter worked
  ansible.builtin.assert:
    that:
      - msg == 'Hello, ansible-creator'

================
File: src/ansible_creator/resources/collection_project/tests/integration/test_integration.py.j2
================
"""Tests for molecule scenarios."""

from __future__ import absolute_import, division, print_function

from pytest_ansible.molecule import MoleculeScenario


def test_integration(molecule_scenario: MoleculeScenario) -> None:
    """Run molecule for each scenario.

    Args:
        molecule_scenario: The molecule scenario object
    Raises:
        AssertionError: If the molecule scenario test does not return a zero exit code.
    """
    proc = molecule_scenario.test()
    assert proc.returncode == 0

================
File: src/ansible_creator/resources/collection_project/tests/unit/test_basic.py.j2
================
"""Unit tests for {{ namespace }}.{{ collection_name }}."""


def test_basic() -> None:
    """Dummy unit test that always passes.

    Raises:
        AssertionError: If the assertion fails.
    """
    assert bool(1) is True

================
File: src/ansible_creator/resources/collection_project/tests/.gitignore
================
output/

================
File: src/ansible_creator/resources/collection_project/.isort.cfg.j2
================
[settings]
known_first_party=ansible_collections.{{ namespace }}.{{ collection_name }}
line_length=100
lines_after_imports=2
lines_between_types=1
profile=black

================
File: src/ansible_creator/resources/collection_project/.pre-commit-config.yaml.j2
================
---
repos:
  - repo: https://github.com/ansible-network/collection_prep
    rev: 1.1.1
    hooks:
      - id: update-docs

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: check-merge-conflict
      - id: check-symlinks
      - id: debug-statements
      - id: end-of-file-fixer
      - id: no-commit-to-branch
        args: [--branch, main]
      - id: trailing-whitespace

  - repo: https://github.com/asottile/add-trailing-comma
    rev: v3.0.0
    hooks:
      - id: add-trailing-comma

  - repo: https://github.com/pre-commit/mirrors-prettier
    rev: "v3.0.0"
    hooks:
      - id: prettier
        entry: env CI=1 bash -c "prettier --list-different . || ec=$? && prettier --loglevel=error --write . && exit $ec"
        pass_filenames: false
        args: []
        additional_dependencies:
          - prettier
          - prettier-plugin-toml

  - repo: https://github.com/PyCQA/isort
    rev: 5.12.0
    hooks:
      - id: isort
        name: Sort import statements using isort
        args: ["--filter-files"]

  - repo: https://github.com/psf/black
    rev: 23.7.0
    hooks:
      - id: black

  - repo: https://github.com/pycqa/flake8
    rev: 7.0.0
    hooks:
      - id: flake8

================
File: src/ansible_creator/resources/collection_project/.prettierignore.j2
================
# files we don't want prettier to ever to look into
.*/
coverage/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# A linked collection directory created by pytest-ansible-units
collections/

tests/output/

README.md

================
File: src/ansible_creator/resources/collection_project/CHANGELOG.rst
================
This should be updated by antsibull-changelog. Do not edit this manually!

See https://github.com/ansible-community/antsibull-changelog/blob/main/docs/changelogs.rst for
information on how to use antsibull-changelog.

Check out ``changelogs/config.yaml`` for its configuration. You need to change at least the ``title`` field in there.

================
File: src/ansible_creator/resources/collection_project/CODE_OF_CONDUCT.md
================
# Community Code of Conduct

Please see the official
[Ansible Community Code of Conduct](https://docs.ansible.com/ansible/latest/community/code_of_conduct.html).

================
File: src/ansible_creator/resources/collection_project/CONTRIBUTING
================
# Contributing

Refer to the [Ansible community guide](https://docs.ansible.com/ansible/devel/community/index.html).

================
File: src/ansible_creator/resources/collection_project/galaxy.yml.j2
================
---
# This collection is initialized by https://github.com/ansible/ansible-creator {{ creator_version }}

# See https://docs.ansible.com/ansible/latest/dev_guide/collections_galaxy_meta.html

namespace: "{{ namespace }}"
name: "{{ collection_name }}"
version: 1.0.0
readme: README.md
authors:
  - your name <example@domain.com>

description: your collection description
license_file: LICENSE

# TO-DO: update the tags based on your content type
tags: ["linux", "tools"]

# TO-DO: maintain this list to reflect the collection's dependencies
dependencies:
  "ansible.utils": "*" # note: "*" selects the latest version available

repository: http://example.com/repository
documentation: http://docs.example.com
homepage: http://example.com
issues: http://example.com/issue/tracker

# A list of file glob-like patterns used to filter any files or directories that should not be included in the build
# artifact. A pattern is matched from the relative path of the file or directory of the collection directory. This
# uses 'fnmatch' to match the files or directories. Some directories and files like 'galaxy.yml', '*.pyc', '*.retry',
# and '.git' are always filtered. Mutually exclusive with 'manifest'
build_ignore:
  - .gitignore
  - changelogs/.plugin-cache.yaml
# A dict controlling use of manifest directives used in building the collection artifact. The key 'directives' is a
# list of MANIFEST.in style
# L(directives,https://packaging.python.org/en/latest/guides/using-manifest-in/#manifest-in-commands). The key
# 'omit_default_directives' is a boolean that controls whether the default directives are used. Mutually exclusive
# with 'build_ignore'
# manifest: null

================
File: src/ansible_creator/resources/collection_project/LICENSE.j2
================
GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

  Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

  For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

  Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

  Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Use with the GNU Affero General Public License.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

    <program>  Copyright (C) <year>  <name of author>
    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an "about box".

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU GPL, see
<https://www.gnu.org/licenses/>.

  The GNU General Public License does not permit incorporating your program
into proprietary programs.  If your program is a subroutine library, you
may consider it more useful to permit linking proprietary applications with
the library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.  But first, please read
<https://www.gnu.org/licenses/why-not-lgpl.html>.

================
File: src/ansible_creator/resources/collection_project/pyproject.toml.j2
================
[tool.black]
line-length = 100

[tool.pytest.ini_options]
addopts = ["-vvv", "-n", "2", "--log-level", "WARNING", "--color", "yes"]
filterwarnings = ['ignore:AnsibleCollectionFinder has already been configured']
testpaths = ["tests"]

================
File: src/ansible_creator/resources/collection_project/README.md.j2
================
# {{ namespace|capitalize }} {{ collection_name|capitalize }} Collection

This repository contains the `{{ namespace }}.{{ collection_name }}` Ansible Collection.

<!--start requires_ansible-->
<!--end requires_ansible-->

## External requirements

Some modules and plugins require external libraries. Please check the
requirements for each plugin or module you use in the documentation to find out
which requirements are needed.

## Included content

<!--start collection content-->
<!--end collection content-->

## Using this collection

```bash
    ansible-galaxy collection install {{ namespace }}.{{ collection_name }}
```

You can also include it in a `requirements.yml` file and install it via
`ansible-galaxy collection install -r requirements.yml` using the format:

```yaml
collections:
  - name: {{ namespace }}.{{ collection_name }}
```

To upgrade the collection to the latest available version, run the following
command:

```bash
ansible-galaxy collection install {{ namespace }}.{{ collection_name }} --upgrade
```

You can also install a specific version of the collection, for example, if you
need to downgrade when something is broken in the latest version (please report
an issue in this repository). Use the following syntax where `X.Y.Z` can be any
[available version](https://galaxy.ansible.com/{{ namespace }}/{{ collection_name }}):

```bash
ansible-galaxy collection install {{ namespace }}.{{ collection_name }}:==X.Y.Z
```

See
[Ansible Using Collections](https://docs.ansible.com/ansible/latest/user_guide/collections_using.html)
for more details.

## Release notes

See the
[changelog](https://github.com/ansible-collections/{{ namespace }}.{{ collection_name }}/tree/main/CHANGELOG.rst).

## Roadmap

<!-- Optional. Include the roadmap for this collection, and the proposed release/versioning strategy so users can anticipate the upgrade/update cycle. -->

## More information

<!-- List out where the user can find additional information, such as working group meeting times, slack/matrix channels, or documentation for the product this collection automates. At a minimum, link to: -->

- [Ansible collection development forum](https://forum.ansible.com/c/project/collection-development/27)
- [Ansible User guide](https://docs.ansible.com/ansible/devel/user_guide/index.html)
- [Ansible Developer guide](https://docs.ansible.com/ansible/devel/dev_guide/index.html)
- [Ansible Collections Checklist](https://docs.ansible.com/ansible/devel/community/collection_contributors/collection_requirements.html)
- [Ansible Community code of conduct](https://docs.ansible.com/ansible/devel/community/code_of_conduct.html)
- [The Bullhorn (the Ansible Contributor newsletter)](https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn)
- [News for Maintainers](https://forum.ansible.com/tag/news-for-maintainers)

## Licensing

GNU General Public License v3.0 or later.

See [LICENSE](https://www.gnu.org/licenses/gpl-3.0.txt) to see the full text.

================
File: src/ansible_creator/resources/collection_project/requirements.txt
================
# TO-DO: add python packages that are required for this collection

================
File: src/ansible_creator/resources/collection_project/test-requirements.txt
================
# TO-DO: add python packages that are required for testing this collection
pytest-ansible
pytest-xdist
molecule

================
File: src/ansible_creator/resources/collection_project/tox-ansible.ini.j2
================
[ansible]

skip =
    py3.7
    py3.8
    2.9
    2.10
    2.11
    2.12
    2.13

================
File: src/ansible_creator/resources/common/devcontainer/.devcontainer/docker/devcontainer.json.j2
================
{
  "name": "ansible-dev-container-docker",
  "image": "{{ dev_container_image }}",
  "containerUser": "root",
  "runArgs": [
    "--security-opt",
    "seccomp=unconfined",
    "--security-opt",
    "label=disable",
    "--cap-add=SYS_ADMIN",
    "--cap-add=SYS_RESOURCE",
    "--device",
    "/dev/fuse",
    "--security-opt",
    "apparmor=unconfined",
    "--hostname=ansible-dev-container"
  ],
  "updateRemoteUserUID": true,
  "customizations": {
    "vscode": {
      "extensions": {{ recommended_extensions | json }}
    }
  }
}

================
File: src/ansible_creator/resources/common/devcontainer/.devcontainer/podman/devcontainer.json.j2
================
{
  "name": "ansible-dev-container-podman",
  "image": "{{ dev_container_image }}",
  "containerUser": "root",
  "runArgs": [
    "--cap-add=CAP_MKNOD",
    "--cap-add=NET_ADMIN",
    "--cap-add=SYS_ADMIN",
    "--cap-add=SYS_RESOURCE",
    "--device",
    "/dev/fuse",
    "--security-opt",
    "seccomp=unconfined",
    "--security-opt",
    "label=disable",
    "--security-opt",
    "apparmor=unconfined",
    "--security-opt",
    "unmask=/sys/fs/cgroup",
    "--userns=host",
    "--hostname=ansible-dev-container"
  ],
  "customizations": {
    "vscode": {
      "extensions": {{ recommended_extensions | json }}
    }
  }
}

================
File: src/ansible_creator/resources/common/devcontainer/.devcontainer/devcontainer.json.j2
================
{
  "name": "ansible-dev-container-codespaces",
  "image": "{{ dev_container_image }}",
  "containerUser": "root",
  "runArgs": [
    "--security-opt",
    "seccomp=unconfined",
    "--security-opt",
    "label=disable",
    "--cap-add=SYS_ADMIN",
    "--cap-add=SYS_RESOURCE",
    "--device",
    "/dev/fuse",
    "--security-opt",
    "apparmor=unconfined",
    "--hostname=ansible-dev-container"
  ],
  "updateRemoteUserUID": true,
  "customizations": {
    "vscode": {
      "extensions": {{ recommended_extensions | json }}
    }
  }
}

================
File: src/ansible_creator/resources/common/devfile/devfile.yaml.j2
================
schemaVersion: 2.2.2
metadata:
  name: {{ dev_file_name }}
components:
  - name: tooling-container
    container:
      image: {{ dev_file_image }}
      memoryRequest: 256M
      memoryLimit: 6Gi
      cpuRequest: 250m
      cpuLimit: 2000m
      args: ["tail", "-f", "/dev/null"]
      env:
        - name: KUBEDOCK_ENABLED
          value: "true"

================
File: src/ansible_creator/resources/common/execution-environment/execution-environment.yml.j2
================
---
version: 3

images:
  base_image:
    name: {{ execution_environment_image }}

dependencies:
  ansible_core:
    package_pip: ansible-core

  ansible_runner:
    package_pip: ansible-runner

  system:
    - openssh-clients
    - sshpass

  python:
    - requests
    - boto3

  galaxy:
    collections:
      - name: ansible.posix
      - name: ansible.utils

additional_build_steps:
  append_base:
    - RUN $PYCMD -m pip install -U pip

options:
  tags:
    - ansible_sample_ee

================
File: src/ansible_creator/resources/common/gitignore/__meta__.yml
================
collection_project:
  additions:
    template: False
    value: ""

playbook_project:
  additions:
    template: True
    value: |
      .logs/*
      *.retry
      *.vault
      collections/*
      !collections/ansible_collections
      !collections/requirements.yml
      collections/ansible_collections/*
      !collections/ansible_collections/{{ namespace }}
      collections/ansible_collections/{{ namespace }}/*
      !collections/ansible_collections/{{ namespace }}/{{ collection_name }}

================
File: src/ansible_creator/resources/common/gitignore/.gitignore.j2
================
{{ additions }}# https://raw.githubusercontent.com/github/gitignore/main/Python.gitignore
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# MacOS
.DS_Store

# Ansible
.ansible/

================
File: src/ansible_creator/resources/common/patterns/sample_pattern/meta/pattern.json.j2
================
{
  "schema_version": "1.0",
  "name": "{{ pattern_name }}",
  "title": "Weather Forecasting",
  "description": "This pattern is designed to help get the weather forecast for a given airport code. It creates a project, EE, and job templates in automation controller to get the weather forecast.",
  "short_description": "This pattern is designed to help get the weather forecast for a given airport code.",
  "tags": ["weather", "forecasting"],
  "aap_resources": {
    "controller_project": {
      "name": "Weather Forecasting",
      "description": "Project for the Weather Forecasting pattern"
    },
    "controller_execution_environment": {
      "name": "Weather Forecasting",
      "description": "EE for the Weather Forecasting pattern",
      "image_name": "weather-demo-ee",
      "pull": "missing"
    },
    "controller_labels": ["weather", "forecasting"],
    "controller_job_templates": [
      {
        "name": "Get Weather Forecast",
        "description": "This job template gets the weather at the location of a provided airport code.",
        "execution_environment": "Weather Forecasting",
        "playbook": "site.yml",
        "primary": true,
        "labels": ["weather", "forecasting"],
        "survey": {
          "name": "Weather Forecasting",
          "description": "Survey to configure the weather forecasting pattern",
          "spec": [
            {
              "type": "text",
              "question_name": "Location",
              "question_description": "Enter the airport code for which you want to get the weather forecast",
              "variable": "location",
              "required": true
            }
          ]
        }
      }
    ]
  }
}

================
File: src/ansible_creator/resources/common/patterns/sample_pattern/playbooks/group_vars/all.yml
================
---
api_url: https://api.weather.gov/points/
repo_url: https://github.com/ip2location/ip2location-iata-icao
airport_code: RDU

================
File: src/ansible_creator/resources/common/patterns/sample_pattern/playbooks/site.meta.yml
================
---
short_description: Display weather forecast
description: This playbook retrieves and displays a weather forecast from a specific airport location
argument_specs:
  weather_forecast:
    short_description: Get weather forecast
    description:
      - Use an airport code to retrieve and display weather forecast data
    author:
      - developer (@developer)
    options:
      airport_code:
        type: str
        required: true
    examples: |
      - import_playbook: site.yml
        vars:
          airport_code: RDU
    return: ~

================
File: src/ansible_creator/resources/common/patterns/sample_pattern/playbooks/site.yml
================
---
- name: Weather forecast
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Collections requirements
      ansible.builtin.debug:
        msg: |
          Warning: This sample pattern relies on the ansible.scm, ansible.utils and community.general collections.
          Please manually add these to the collection's requirements file to use the sample pattern as-is.

    - name: Ensure the airport code has been defined
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs']['weather_forecast']['options'] }}"
      vars:
        filename: "site.meta.yml"

    - name: Clone the latitude longtude repo locally
      ansible.scm.git_retrieve:
        origin:
          url: "{{ repo_url }}"
      register: cloned

    - name: Convert the CSV to structured data
      community.general.read_csv:
        path: "{{ cloned.path }}/iata-icao.csv"
      register: contents

    - name: Extract the matching airport from the list of all airports
      ansible.builtin.set_fact:
        airport_details: "{{ contents.list | selectattr('iata', 'equalto', airport_code) | first }}"
      ignore_errors: true

    - name: Handle airport code not found
      ansible.builtin.fail:
        msg: "Airport code '{{ airport_code }}' could not be found."
      when: airport_details is not defined

    - name: Retrieve weather information using the latitude and longitude
      ansible.builtin.uri:
        url: "{{ api_url }}{{ lat_long }}"
      register: root_call
      vars:
        lat_long: "{{ airport_details.latitude }},{{ airport_details.longitude }}"

    - name: Get the URL for the forecast
      ansible.builtin.set_fact:
        forecast_url: "{{ lookup('ansible.utils.get_path', root_call.json, forecast_url_path) }}"
      vars:
        forecast_url_path: properties.forecast

    - name: Retrieve the current forecast
      ansible.builtin.uri:
        url: "{{ forecast_url }}"
      register: forecast

    - name: Extract the daily forecast
      ansible.builtin.set_fact:
        daily_forecast: "{{ lookup('ansible.utils.get_path', forecast.json, first_forecast) }}"
      vars:
        first_forecast: properties.periods.0.detailedForecast

    - name: Show the forecast
      ansible.builtin.debug:
        msg: "The forecast for {{ airport_code }} is: {{ daily_forecast }}"

================
File: src/ansible_creator/resources/common/patterns/sample_pattern/README.md
================
## Weather Forecasting Pattern

### Description

This pattern is designed to help get the weather forecast for a given location.
It uses the `site.yml` playbook to retrieve the weather forecast for a specified
location.

### What This Pattern Covers

- Retrieves the weather forecast for a given location.
- Uses the `site.yml` playbook to perform the weather forecasting task.

### Resources Created by This Pattern

1. Project

- Ensures that all relevant files and configurations are logically arranged,
  facilitating easier maintenance and execution of automation tasks.
- This project is used to organize and manage the weather forecasting task.

2. Execution Environment

- A custom EE configuration to provide the necessary dependencies and
  environment for the task execution.

3. Job Templates

- Outline the necessary parameters and configurations to perform weather
  forecasting task using the provided playbook.

### How to Use

1. Load the pattern

- Ensure the custom EE is correctly built and available in your Ansible
  Automation Platform. Use the pattern service to load the pattern within the
  Ansible Automation Platform.

2. Use the Job Templates

- In the Weather Forecasting Patterns execute the required job template to
  retrieve the weather forecast for a given airport code. Monitor the job
  execution and verify that the forecast has been successfully retrieved.

### Contribution

Contributions to this project are welcome. Please fork the repository, make your
changes, and submit a pull request.

### License

GNU General Public License v3.0 or later.

See LICENSE to see the full text. This project is licensed under the MIT
License. See the LICENSE file for details.

================
File: src/ansible_creator/resources/common/play-argspec/inventory/argspec_validation_inventory.yml
================
---
all:
  vars:
    ping_data: Pong
    stat:
      description: Custom stat data
      returned: always
      type: raw
      sample: Hello, World!

================
File: src/ansible_creator/resources/common/play-argspec/argspec_validation_plays.meta.yml
================
# Example play argspec file
---
short_description: A shorter summary of `description` below
description: This is a description of a playbook, that may contain multiple plays with multiple play argument specs
argument_specs:
  debug_localhost:
    short_description: Play for printing a debug message
    description:
      - Example play within a collection containing an argspec for printing a debug message
    author:
      - developer (@developer)
    options:
      message:
        description: Debug message to print
        type: str
        required: true
    examples: |
      - import_playbook: argspec_validation_plays.yml
        vars:
          message: 'Custom debug message'
    return: ~
  ping_localhost:
    short_description: Play for pinging localhost with custom data
    description:
      - Example play within a collection containing an argspec for pinging localhost with custom data
    author:
      - developer (@developer)
    options:
      ping_data:
        description: Ping data
        type: str
        required: true
    examples: |
      - import_playbook: argspec_validation_plays.yml
        vars:
          data: Pong
    return: ~
  set_stats:
    short_description: Play for setting a custom stat
    description:
      - Example play within a collection containing an argspec for setting a custom stat
    author:
      - developer (@developer)
    options:
      stat:
        description: Stat data
        type: raw
        required: true
    notes:
      - This play has some notes
      - They specify additional information
    examples: |
      - import_playbook: argspec_validation_plays.yml
        vars:
          stat: This is some custom stat
    return:
      stat:
        description: Custom stat data
        returned: always
        type: raw
        sample: Hello, World!

================
File: src/ansible_creator/resources/common/play-argspec/argspec_validation_plays.yml
================
# Example playbook using play argspec validation
# Run with:
# ansible-playbook argspec_validation_plays.yml -e message=hello -i inventory/argspec_validation_inventory.yml
---
- name: Debug_localhost
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Verify with argspec
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs'][lowercase_play_name]['options'] }}"
      vars:
        lowercase_play_name: "{{ ansible_play_name | lower }}"
        filename: "argspec_validation_plays.meta.yml"
    - name: Print debug message
      ansible.builtin.debug:
        msg: "{{ message }}"

- name: Ping_localhost
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Verify with argspec
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs'][lowercase_play_name]['options'] }}"
      vars:
        lowercase_play_name: "{{ ansible_play_name | lower }}"
        filename: "argspec_validation_plays.meta.yml"
    - name: Print debug message
      ansible.builtin.ping:
        data: "{{ ping_data }}"

- name: Set_stats
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Verify with argspec
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs'][lowercase_play_name]['options'] }}"
      vars:
        lowercase_play_name: "{{ ansible_play_name | lower }}"
        filename: "argspec_validation_plays.meta.yml"
    - name: Set custom stats
      ansible.builtin.set_stats:
        data: "{{ stat }}"

================
File: src/ansible_creator/resources/common/role/roles/run/defaults/main.yml.j2
================
---
# defaults file for {{ namespace }}.{{ collection_name }}.{{ role_name }}

================
File: src/ansible_creator/resources/common/role/roles/run/handlers/main.yml.j2
================
---
# handlers file for {{ namespace }}.{{ collection_name }}.{{ role_name }}

================
File: src/ansible_creator/resources/common/role/roles/run/meta/argument_specs.yml.j2
================
---
# argument spec file for {{ namespace }}.{{ collection_name }}.{{ role_name }}

argument_specs:
  main:
    short_description: Role description.
    options:
      my_variable:
        type: str
        description: A simple string argument for demonstration.
        default: "default_value"

================
File: src/ansible_creator/resources/common/role/roles/run/meta/main.yml.j2
================
galaxy_info:
  author: foo
  description: {{ namespace }}.{{ collection_name }} {{ role_name }} Role
  company: {{ namespace }}

  # If the issue tracker for your role is not on github, uncomment the
  # next line and provide a value
  # issue_tracker_url: http://example.com/issue/tracker

  # Choose a valid license ID from https://spdx.org - some suggested licenses:
  # - BSD-3-Clause (default)
  # - MIT
  # - GPL-2.0-or-later
  # - GPL-3.0-only
  # - Apache-2.0
  # - CC-BY-4.0
  license: GPL-2.0-or-later

  min_ansible_version: "2.14"

  # If this a Container Enabled role, provide the minimum Ansible Container version.
  # min_ansible_container_version:

  #
  # Provide a list of supported platforms, and for each platform a list of versions.
  # If you don't wish to enumerate all versions for a particular platform, use 'all'.
  # To view available platforms and versions (or releases), visit:
  # https://galaxy.ansible.com/api/v1/platforms/
  #
  # platforms:
  # - name: Fedora
  #   versions:
  #   - all
  #   - 25
  # - name: SomePlatform
  #   versions:
  #   - all
  #   - 1.0
  #   - 7
  #   - 99.99

  galaxy_tags:
    []
    # List tags for your role here, one per line. A tag is a keyword that describes
    # and categorizes the role. Users find roles by searching for tags. Be sure to
    # remove the '[]' above, if you add tags to this list.
    #
    # NOTE: A tag is limited to a single word comprised of alphanumeric characters.
    #       Maximum 20 tags per role.

dependencies:
  []
  # List your role dependencies here, one per line. Be sure to remove the '[]' above,
  # if you add dependencies to this list.

================
File: src/ansible_creator/resources/common/role/roles/run/tasks/main.yml.j2
================
---
# tasks file for {{ namespace }}.{{ collection_name }}.{{ role_name }}

# task example for debugging a value
- name: Debug the value of my_variable
  ansible.builtin.debug:
    msg: "The value of my_variable is {% raw %}{{ my_variable }}{% endraw %}"

================
File: src/ansible_creator/resources/common/role/roles/run/tests/inventory
================
localhost

================
File: src/ansible_creator/resources/common/role/roles/run/vars/main.yml.j2
================
---
# vars file for {{ namespace }}.{{ collection_name }}.{{ role_name }}

================
File: src/ansible_creator/resources/common/role/roles/run/README.md.j2
================
{{ namespace }}.{{ collection_name }} {{ role_name }} Role
========================

A brief description of the role goes here.

Requirements
------------

Any pre-requisites that may not be covered by Ansible itself or the role should be mentioned here. For instance, if the role uses the EC2 module, it may be a good idea to mention in this section that the boto package is required.

Role Variables
--------------

A description of the settable variables for this role should go here, including any variables that are in defaults/main.yml, vars/main.yml, and any variables that can/should be set via parameters to the role. Any variables that are read from other roles and/or the global scope (ie. hostvars, group vars, etc.) should be mentioned here as well.

Dependencies
------------

A list of other roles hosted on Galaxy should go here, plus any details in regards to parameters that may need to be set for other roles, or variables that are used from other roles.

Example Playbook
----------------

Including an example of how to use your role (for instance, with variables passed in as parameters) is always nice for users too:

```yaml
- name: Execute tasks on servers
  hosts: servers
  roles:
    - role: {{ namespace }}.{{ collection_name }}.run
      run_x: 42
```

Another way to consume this role would be:

```yaml
- name: Initialize the run role from {{ namespace }}.{{ collection_name }}
  hosts: servers
  gather_facts: false
  tasks:
    - name: Trigger invocation of run role
      ansible.builtin.include_role:
        name: {{ namespace }}.{{ collection_name }}.run
      vars:
        run_x: 42
```

Role Idempotency
----------------

Designation of the role as idempotent (True/False)

Role Atomicity
----------------

Designation of the role as atomic if applicable (True/False)

Roll-back capabilities
----------------------

Define the roll-back capabilities of the role

Argument Specification
----------------------

Including an example of how to add an argument Specification file that validates the arguments provided to the role.

```
argument_specs:
  main:
    short_description: Role description.
    options:
      string_arg1:
        description: string argument description.
        type: "str"
        default: "x"
        choices: ["x", "y"]
```

License
-------

# TO-DO: Update the license to the one you want to use (delete this line after setting the license)
BSD

Author Information
------------------

An optional section for the role authors to include contact information, or a website (HTML is not allowed).

================
File: src/ansible_creator/resources/common/vscode/.vscode/extensions.json.j2
================
{
  "recommendations": {{ recommended_extensions | json }}
}

================
File: src/ansible_creator/resources/execution_env_project/.github/workflows/ci.yml.j2
================
# Combine workflow for pull-request, push-to-main and release events.

name: Execution environment build

on:
  pull_request_target:
    branches:
      - main
    types: [opened, reopened, synchronize]
  push:
    branches:
      - main
  release:
    types: [published]
{% raw %}
jobs:
  ee-build:
    uses: ansible/ansible-content-actions/.github/workflows/ee-build.yml@main
    with:
      registry: ghcr.io
    secrets:
      registry_username: ${{ github.actor }}
      registry_password: ${{ secrets.GITHUB_TOKEN }}
      # Only needed if base image of execution-environment.yml file is from Red Hat (ee-minimal)
      # registry_redhat_username: ${{ secrets.registry_redhat_username }}
      # registry_redhat_password: ${{ secrets.registry_redhat_password }}
{%- endraw %}

================
File: src/ansible_creator/resources/execution_env_project/.gitignore
================
context/
.DS_Store

================
File: src/ansible_creator/resources/execution_env_project/execution-environment.yml.j2
================
---
version: 3

images:
  base_image:
    name: quay.io/fedora/fedora:41

dependencies:
  # Use python3
  python_interpreter:
    package_system: python3
    python_path: /usr/bin/python3

  ansible_core:
    package_pip: ansible-core

  ansible_runner:
    package_pip: ansible-runner

  system:
    - openssh-clients
    - sshpass

  python:
    - ansible-navigator
    - boto3
    - requests

  galaxy:
    collections:
      - name: ansible.posix
      - name: ansible.utils

additional_build_steps:
  append_base:
    - RUN $PYCMD -m pip install -U pip

options:
  tags:
    - ansible_sample_ee

================
File: src/ansible_creator/resources/execution_env_project/README.md
================
# Execution Environment Project

### This is a sample execution environment project to build and publish your EE.

## Included content/ Directory Structure

The directory structure follows best practices recommended by the Ansible
community. Feel free to customize this template according to your specific
project requirements.

```
├── .github
│   └── workflows
│       └── ci.yml
├── .gitignore
├── README.md
└── execution-environment.yml
```

================
File: src/ansible_creator/resources/playbook_project/.github/workflows/tests.yml.j2
================
---
name: "CI"
{% raw %}
concurrency:
  group: ${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

on:  # yamllint disable-line rule:truthy
  pull_request:
    branches: [main]
  workflow_dispatch:
  # TO-DO: Below is an example cron scheduler. Uncomment and tweak it as per your requirement
  # schedule:
    # - cron: '0 0 * * *'

jobs:
  ansible-lint:
    uses: ansible/ansible-content-actions/.github/workflows/ansible_lint.yaml@main
{%- endraw %}

================
File: src/ansible_creator/resources/playbook_project/.github/ansible-code-bot.yml.j2
================
---
schedule:
  interval: "daily"

================
File: src/ansible_creator/resources/playbook_project/collections/ansible_collections/project_org/project_repo/meta/runtime.yml
================
---
requires_ansible: ">=2.17.0"

================
File: src/ansible_creator/resources/playbook_project/collections/ansible_collections/project_org/project_repo/roles/run/tasks/main.yml.j2
================
{% raw %}---
- name: Debug print task-1
  ansible.builtin.debug:
    msg: "This is task-1"

- name: Debug print task-2
  ansible.builtin.debug:
    msg: "This is task-2"

- name: Debug print task-3
  ansible.builtin.debug:
    msg: "This is task-3"
{%- endraw %}

================
File: src/ansible_creator/resources/playbook_project/collections/ansible_collections/project_org/project_repo/roles/run/README.md.j2
================
{{ namespace|capitalize }}.{{ collection_name|capitalize }} Run Role
========================

A brief description of the role is here.

Requirements
------------

Any prerequisites that may not be covered by Ansible itself or the role should be mentioned here. For instance, if the role uses the EC2 module, it may be a good idea to mention in this section that the boto package is required.

Role Variables
--------------

A description of the settable variables for this role should go here, including any variables that are in defaults/main.yml, vars/main.yml, and any variables that can/should be set via parameters to the role. Any variables that are read from other roles and/or the global scope (ie. host vars, group vars, etc.) should be mentioned here as well.

Dependencies
------------

A list of other roles hosted on Galaxy should go here, plus any details in regards to parameters that may need to be set for other roles, or variables that are used from other roles.

Example Playbook
----------------

Including an example of how to use your role (for instance, with variables passed in as parameters) is always nice for users too:

```yaml
- name: Execute tasks on servers
  hosts: servers
  roles:
    - role: {{ namespace }}.{{ collection_name }}.run
      run_x: 42
```

Another way to consume this role would be:

```yaml
- name: Initialize the run role from {{ namespace }}.{{ collection_name }}
  hosts: servers
  gather_facts: false
  tasks:
    - name: Trigger invocation of run role
      ansible.builtin.include_role:
        name: {{ namespace }}.{{ collection_name }}.run
      vars:
        run_x: 42
```

License
-------

# TO-DO: Update the license to the one you want to use (delete this line after setting the license)
BSD

Author Information
------------------

An optional section for the role authors to include contact information, or a website (HTML is not allowed).

================
File: src/ansible_creator/resources/playbook_project/collections/ansible_collections/project_org/project_repo/galaxy.yml.j2
================
---
# Minimal galaxy.yml for a playbook project for tools to recognize this as a collection

namespace: "{{ namespace }}"
name: "{{ collection_name }}"
readme: README.md
version: 0.0.1
authors:
  - your name <example@domain.com>

description: Collection for {{ namespace }}.{{ collection_name }} playbook project

# TO-DO: update the tags based on your content type
tags: ["tools"]

repository: NA

================
File: src/ansible_creator/resources/playbook_project/collections/ansible_collections/project_org/project_repo/README.md.j2
================
# {{ namespace|capitalize }} {{ collection_name|capitalize }} Collection

This repository contains the `{{ namespace }}.{{ collection_name }}` Ansible Collection.

## Tested with Ansible

Tested with ansible-core >=2.14 releases and the current development version of
ansible-core.

## External requirements

Some modules and plugins require external libraries. Please check the
requirements for each plugin or module you use in the documentation to find out
which requirements are needed.

## Included content

Please check the included content on the
[Ansible Galaxy page for this collection](https://galaxy.ansible.com/{{ namespace }}/{{ collection_name }}).

## Using this collection

```
    ansible-galaxy collection install {{ namespace }}.{{ collection_name }}
```

You can also include it in a `requirements.yml` file and install it via
`ansible-galaxy collection install -r requirements.yml` using the format:

```yaml
collections:
  - name: {{ namespace }}.{{ collection_name }}
```

To upgrade the collection to the latest available version, run the following
command:

```bash
ansible-galaxy collection install {{ namespace }}.{{ collection_name }} --upgrade
```

You can also install a specific version of the collection, for example, if you
need to downgrade when something is broken in the latest version (please report
an issue in this repository). Use the following syntax where `X.Y.Z` can be any
[available version](https://galaxy.ansible.com/{{ namespace }}/{{ collection_name }}):

```bash
ansible-galaxy collection install {{ namespace }}.{{ collection_name }}:==X.Y.Z
```

See
[Ansible Using Collections](https://docs.ansible.com/ansible/latest/user_guide/collections_using.html)
for more details.

## Release notes

See the
[changelog](https://github.com/ansible-collections/{{ namespace }}.{{ collection_name }}/tree/main/CHANGELOG.rst).

## Roadmap

<!-- Optional. Include the roadmap for this collection, and the proposed release/versioning strategy so users can anticipate the upgrade/update cycle. -->

## More information

<!-- List out where the user can find additional information, such as working group meeting times, slack/Matrix channels, or documentation for the product this collection automates. At a minimum, link to: -->

- [Ansible collection development forum](https://forum.ansible.com/c/project/collection-development/27)
- [Ansible User guide](https://docs.ansible.com/ansible/devel/user_guide/index.html)
- [Ansible Developer guide](https://docs.ansible.com/ansible/devel/dev_guide/index.html)
- [Ansible Collections Checklist](https://docs.ansible.com/ansible/devel/community/collection_contributors/collection_requirements.html)
- [Ansible Community code of conduct](https://docs.ansible.com/ansible/devel/community/code_of_conduct.html)
- [The Bullhorn (the Ansible Contributor newsletter)](https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn)
- [News for Maintainers](https://forum.ansible.com/tag/news-for-maintainers)

## Licensing

GNU General Public License v3.0 or later.

See [LICENSE](https://www.gnu.org/licenses/gpl-3.0.txt) to see the full text.

================
File: src/ansible_creator/resources/playbook_project/collections/requirements.yml.j2
================
---
collections:
  - name: ansible.posix
    version: 1.4.0

  - name: ansible.scm
    version: 2.0.0

  - name: ansible.utils
    version: 4.0.0

  - name: cisco.ios

  - name: https://github.com/redhat-cop/network.backup
    type: git

  # TO-DO: User's own collections can also be specified as mention below.
  # - name: my_organization.my_collection
  #   version: 1.2.3
  #   source: https://github.com/my_organization/my_collection.git

================
File: src/ansible_creator/resources/playbook_project/inventory/group_vars/all.yml.j2
================
---
ansible_user: your_username
ansible_ssh_private_key_file: /path/to/your/private/key

================
File: src/ansible_creator/resources/playbook_project/inventory/group_vars/db_servers.yml.j2
================
---
http_port: 80
app_version: "1.0.0"

================
File: src/ansible_creator/resources/playbook_project/inventory/group_vars/production.yml.j2
================
---
http_port: 80
app_version: "1.0.0"

================
File: src/ansible_creator/resources/playbook_project/inventory/group_vars/test.yml.j2
================
---
http_port: 80
app_version: "1.0.0"

================
File: src/ansible_creator/resources/playbook_project/inventory/group_vars/web_servers.yml.j2
================
---
http_port: 80
app_version: "1.0.0"

================
File: src/ansible_creator/resources/playbook_project/inventory/host_vars/server1.yml.j2
================
---
server_name: webserver1

================
File: src/ansible_creator/resources/playbook_project/inventory/host_vars/server2.yml.j2
================
---
server_name: webserver2

================
File: src/ansible_creator/resources/playbook_project/inventory/host_vars/server3.yml.j2
================
---
server_name: webserver3

================
File: src/ansible_creator/resources/playbook_project/inventory/host_vars/switch1.yml.j2
================
---
ansible_network_os: cisco.ios.ios
ansible_connection: ansible.netcommon.network_cli
ansible_become: true

================
File: src/ansible_creator/resources/playbook_project/inventory/host_vars/switch2.yml.j2
================
---
ansible_network_os: cisco.nxos.nxos
ansible_connection: ansible.netcommon.httpapi
ansible_httpapi_port: 80

================
File: src/ansible_creator/resources/playbook_project/inventory/argspec_validation_inventory.yml
================
---
all:
  vars:
    ping_data: Pong
    stat:
      description: Custom stat data
      returned: always
      type: raw
      sample: Hello, World!

================
File: src/ansible_creator/resources/playbook_project/inventory/hosts.yml.j2
================
---
all:
  hosts:
    server1:
      ansible_host: 192.168.1.101
    server2:
      ansible_host: 192.168.1.102
    switch1:
      ansible_host: 192.168.1.106
    switch2:
      ansible_host: 192.168.1.107
  children:
    web_servers:
      hosts:
        server1:
        server2:
    db_servers:
      hosts:
        server3:
          ansible_host: 192.168.1.103
    switches:
      hosts:
        switch1:
        switch2:
    production:
      hosts:
        server1:
          ansible_host: 192.168.1.101
        server2:
          ansible_host: 192.168.1.102
    test:
      hosts:
        server3:
          ansible_host: 192.168.1.103

================
File: src/ansible_creator/resources/playbook_project/ansible-navigator.yml.j2
================
{% raw %}---
ansible-navigator:
  logging:
    level: debug
    append: false
    file: $PWD/.logs/ansible-navigator.log

  playbook-artifact:
    enable: true
    save-as: "$PWD/.logs/{playbook_name}-artifact-{time_stamp}.json"
{%- endraw %}

================
File: src/ansible_creator/resources/playbook_project/ansible.cfg.j2
================
[defaults]
# Specify the inventory file
inventory = inventory/hosts.yml

# Define the directory for host and group variables
host_vars_inventory = inventory/host_vars
group_vars_inventory = inventory/group_vars

# Set the logging verbosity level
verbosity = 2

# Set the default user for SSH connections
remote_user = myuser

# Define the default become method
become_method = sudo

[persistent_connection]
# Controls how long the persistent connection will remain idle before it is destroyed
connect_timeout=30

# Controls the amount of time to wait for response from remote device before timing out persistent connection
command_timeout=30

================
File: src/ansible_creator/resources/playbook_project/argspec_validation_plays.meta.yml
================
# Example play argspec file
---
short_description: A shorter summary of `description` below
description: This is a description of a playbook, that may contain multiple plays with multiple play argument specs
argument_specs:
  debug_localhost:
    short_description: Play for printing a debug message
    description:
      - Example play within a collection containing an argspec for printing a debug message
    author:
      - developer (@developer)
    options:
      message:
        description: Debug message to print
        type: str
        required: true
    examples: |
      - import_playbook: argspec_validation_plays.yml
        vars:
          message: 'Custom debug message'
    return: ~
  ping_localhost:
    short_description: Play for pinging localhost with custom data
    description:
      - Example play within a collection containing an argspec for pinging localhost with custom data
    author:
      - developer (@developer)
    options:
      ping_data:
        description: Ping data
        type: str
        required: true
    examples: |
      - import_playbook: argspec_validation_plays.yml
        vars:
          data: Pong
    return: ~
  set_stats:
    short_description: Play for setting a custom stat
    description:
      - Example play within a collection containing an argspec for setting a custom stat
    author:
      - developer (@developer)
    options:
      stat:
        description: Stat data
        type: raw
        required: true
    notes:
      - This play has some notes
      - They specify additional information
    examples: |
      - import_playbook: argspec_validation_plays.yml
        vars:
          stat: This is some custom stat
    return:
      stat:
        description: Custom stat data
        returned: always
        type: raw
        sample: Hello, World!

================
File: src/ansible_creator/resources/playbook_project/argspec_validation_plays.yml
================
# Example playbook using play argspec validation
# Run with:
# ansible-playbook argspec_validation_plays.yml -e message=hello -i inventory/argspec_validation_inventory.yml
---
- name: Debug_localhost
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Verify with argspec
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs'][lowercase_play_name]['options'] }}"
      vars:
        lowercase_play_name: "{{ ansible_play_name | lower }}"
        filename: "argspec_validation_plays.meta.yml"
    - name: Print debug message
      ansible.builtin.debug:
        msg: "{{ message }}"

- name: Ping_localhost
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Verify with argspec
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs'][lowercase_play_name]['options'] }}"
      vars:
        lowercase_play_name: "{{ ansible_play_name | lower }}"
        filename: "argspec_validation_plays.meta.yml"
    - name: Print debug message
      ansible.builtin.ping:
        data: "{{ ping_data }}"

- name: Set_stats
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Verify with argspec
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs'][lowercase_play_name]['options'] }}"
      vars:
        lowercase_play_name: "{{ ansible_play_name | lower }}"
        filename: "argspec_validation_plays.meta.yml"
    - name: Set custom stats
      ansible.builtin.set_stats:
        data: "{{ stat }}"

================
File: src/ansible_creator/resources/playbook_project/linux_playbook.yml.j2
================
---
- name: Update web servers
  hosts: webservers
  become: true

  tasks:
    - name: Ensure apache is at the present version
      ansible.builtin.dnf:
        name: httpd
        state: present

    - name: Write the apache config file
      ansible.builtin.template:
        src: /srv/httpd.j2
        dest: /etc/httpd.conf
        mode: "0644"

- name: Update db servers
  hosts: databases
  become: true

  tasks:
    - name: Ensure postgresql is at the present version
      ansible.builtin.dnf:
        name: postgresql
        state: present

    - name: Ensure that postgresql is started
      ansible.builtin.service:
        name: postgresql
        state: started

================
File: src/ansible_creator/resources/playbook_project/network_playbook.yml.j2
================
{% raw %}---
- name: Network Getting Started First Playbook Extended
  gather_facts: false
  hosts: switch1
  tasks:
    - name: Get config for IOS devices
      cisco.ios.ios_facts:
        gather_subset: all

    - name: Display the config
      ansible.builtin.debug:
        msg: "The hostname is {{ ansible_net_hostname }} and the OS is {{ ansible_net_version }}"

    - name: Update the hostname
      cisco.ios.ios_config:
        lines:
          - hostname ios-changed

    - name: Get changed config for IOS devices
      cisco.ios.ios_facts:
        gather_subset: all

    - name: Display the changed config
      ansible.builtin.debug:
        msg: "The new hostname is {{ ansible_net_hostname }} and the OS is {{ ansible_net_version }}"
{%- endraw %}

================
File: src/ansible_creator/resources/playbook_project/README.md.j2
================
# {{ namespace|capitalize }} {{ collection_name|capitalize }} Ansible Project

## Included content/ Directory Structure

The directory structure follows best practices recommended by the Ansible
community. Feel free to customize this template according to your specific
project requirements.

```
 ansible-project/
 |── .devcontainer/
 |    └── docker/
 |        └── devcontainer.json
 |    └── podman/
 |        └── devcontainer.json
 |    └── devcontainer.json
 |── .github/
 |    └── workflows/
 |        └── tests.yml
 |    └── ansible-code-bot.yml
 |── .vscode/
 |    └── extensions.json
 |── collections/
 |   └── requirements.yml
 |   └── ansible_collections/
 |       └── project_org/
 |           └── project_repo/
 |               └── README.md
 |               └── roles/sample_role/
 |                         └── README.md
 |                         └── tasks/main.yml
 |── inventory/
 |   |── hosts.yml
 |   |── argspec_validation_inventory.yml
 |   └── groups_vars/
 |   └── host_vars/
 |── ansible-navigator.yml
 |── ansible.cfg
 |── devfile.yaml
 |── linux_playbook.yml
 |── network_playbook.yml
 |── README.md
 |── site.yml
```

## Compatible with Ansible-lint

Tested with ansible-lint >=24.2.0 releases and the current development version
of ansible-core.

================
File: src/ansible_creator/resources/playbook_project/site.yml.j2
================
---
- name: Example playbook
  hosts: localhost
  roles:
    - role: {{ namespace }}.{{ collection_name }}.run

================
File: src/ansible_creator/schemas/__init__.py
================
"""A package containing all schemas required by ansible-creator."""

================
File: src/ansible_creator/subcommands/__init__.py
================
"""A package containing all actions supported by ansible-creator."""

================
File: src/ansible_creator/subcommands/add.py
================
"""Definitions for ansible-creator add action."""

from __future__ import annotations

import uuid

from pathlib import Path
from typing import TYPE_CHECKING

import yaml

from ansible_creator.constants import GLOBAL_TEMPLATE_VARS
from ansible_creator.exceptions import CreatorError
from ansible_creator.templar import Templar
from ansible_creator.types import TemplateData
from ansible_creator.utils import Copier, Walker, ask_yes_no


if TYPE_CHECKING:
    from ansible_creator.config import Config
    from ansible_creator.output import Output


class Add:
    """Class to handle the add subcommand."""

    def __init__(
        self,
        config: Config,
        *,
        skip_collection_check: bool = False,
    ) -> None:
        """Initialize the add action.

        Args:
            config: App configuration object.
            skip_collection_check: Whether to skip the check for a valid collection before adding.
        """
        self._resource_type: str = config.resource_type
        self._role_name: str = config.role_name
        self._pattern_name: str = config.pattern_name
        self._plugin_type: str = config.plugin_type
        self._resource_id: str = f"common.{self._resource_type}"
        self._plugin_id: str = f"collection_project.plugins.{self._plugin_type}"
        self._plugin_name: str = config.plugin_name
        self._add_path: Path = Path(config.path)
        self._force = config.force
        self._overwrite = config.overwrite
        self._no_overwrite = config.no_overwrite
        self._creator_version = config.creator_version
        self._project = config.project
        self._dev_container_image = config.image
        self.output: Output = config.output
        self.templar = Templar()
        self._namespace: str = config.namespace or ""
        self._collection_name: str = config.collection_name or ""

        self._skip_collection_check = skip_collection_check

    @property
    def _plugin_type_output(self) -> str:
        """Format the plugin type for output.

        Returns:
            Formatted plugin type string for display in output messages.
        """
        if self._plugin_type == "modules":
            return "Module"
        return self._plugin_type.capitalize()

    def run(self) -> None:
        """Start scaffolding the resource file."""
        self._check_path_exists()
        self.output.debug(msg=f"final collection path set to {self._add_path}")
        if self._resource_type:
            self._resource_scaffold()
        elif self._plugin_type:
            self._check_collection_path()
            plugin_path = self._add_path / "plugins" / self._plugin_type
            plugin_path.mkdir(parents=True, exist_ok=True)
            self._plugin_scaffold(plugin_path)

    def _check_path_exists(self) -> None:
        """Validate the provided add path.

        Raises:
            CreatorError: If the add path does not exist.
        """
        if not self._add_path.exists():
            msg = f"The path {self._add_path} does not exist. Please provide an existing directory."
            raise CreatorError(msg)

    def _check_collection_path(self) -> None:
        """Validates if the provided path is an Ansible collection.

        Raises:
            CreatorError: If the path is not a collection path.
        """
        if self._skip_collection_check:
            return

        galaxy_file_path = self._add_path / "galaxy.yml"
        if not Path.is_file(galaxy_file_path):
            msg = (
                f"The path {self._add_path} is not a valid Ansible collection path. "
                "Please provide the root path of a valid ansible collection."
            )
            raise CreatorError(msg)

    def unique_name_in_devfile(self) -> str:
        """Use project specific name in devfile.

        Returns:
            Unique name entry.
        """
        final_name = ".".join(self._add_path.parts[-2:])
        final_uuid = str(uuid.uuid4())[:8]
        return f"{final_name}-{final_uuid}"

    def update_galaxy_dependency(self) -> None:
        """Update galaxy.yml file with the required dependency."""
        galaxy_file = self._add_path / "galaxy.yml"

        # Load the galaxy.yml file
        with galaxy_file.open("r", encoding="utf-8") as file:
            data = yaml.safe_load(file)

        # Ensure the dependencies key exists
        if "dependencies" not in data:
            data["dependencies"] = {"ansible.utils": "*"}

        # Empty dependencies key or dependencies key without ansible.utils
        elif not data["dependencies"] or "ansible.utils" not in data["dependencies"]:
            data["dependencies"]["ansible.utils"] = "*"

        # Save the updated YAML back to the file
        with galaxy_file.open("w", encoding="utf-8") as file:
            yaml.dump(data, file, sort_keys=False)

    def role_galaxy(self) -> tuple[str, str]:
        """Fetch values from galaxy.yml file.

        Returns:
        tuple[str, str]: A tuple containing the namespace and collection name.
                          Defaults are ('your-collection-namespace', 'your-collection-name')
                          if the file is missing or keys are absent.
        """
        galaxy_file = self._add_path / "galaxy.yml"

        # Load the galaxy.yml file
        with galaxy_file.open("r", encoding="utf-8") as file:
            data = yaml.safe_load(file)

        # Ensure the namespace and name key exists
        namespace = data.get("namespace", "your-collection-namespace")
        collection_name = data.get("name", "your-collection-name")

        return namespace, collection_name

    def _resource_scaffold(self) -> None:
        """Scaffold the specified resource file based on the resource type.

        Raises:
            CreatorError: If unsupported resource type is given.
        """
        self.output.debug(f"Started adding {self._resource_type} to destination")
        dest_path = self._add_path

        # Call the appropriate scaffolding function based on the resource type
        if self._resource_type == "devfile":
            template_data = self._get_devfile_template_data()
        elif self._resource_type == "devcontainer":
            template_data = self._get_devcontainer_template_data()
        elif self._resource_type == "execution-environment":
            template_data = self._get_ee_template_data()
        elif self._resource_type == "patterns":
            self._check_collection_path()
            pattern_path = self._add_path / "extensions" / "patterns"
            pattern_path.mkdir(parents=True, exist_ok=True)
            dest_path = pattern_path
            template_data = self._get_patterns_template_data()
        elif self._resource_type == "play-argspec":
            template_data = self._get_play_argspec_template_data()
        elif self._resource_type == "role":
            self._check_collection_path()
            self._namespace, self._collection_name = self.role_galaxy()
            template_data = self._get_role_template_data()
        else:
            msg = f"Unsupported resource type: {self._resource_type}"
            raise CreatorError(msg)

        self._perform_resource_scaffold(template_data, dest_path)

    def _perform_resource_scaffold(self, template_data: TemplateData, dest_path: Path) -> None:
        """Perform the actual scaffolding process using the provided template data.

        Args:
            template_data: TemplateData
            dest_path: Path where the resource will be scaffolded.

        Raises:
            CreatorError: If there are conflicts and overwriting is not allowed, or if the
                      destination directory contains files that will be overwritten.
        """
        walker = Walker(
            resources=(f"common.{self._resource_type}",),
            resource_id=self._resource_id,
            dest=dest_path,
            output=self.output,
            template_data=template_data,
            templar=self.templar,
        )
        paths = walker.collect_paths()
        copier = Copier(output=self.output)

        if self._no_overwrite and paths.has_conflicts():
            msg = (
                "The flag `--no-overwrite` restricts overwriting."
                "\nThe destination directory contains files that can be overwritten."
                "\nPlease re-run ansible-creator with --overwrite to continue."
            )
            raise CreatorError(msg)

        if not paths.has_conflicts() or self._force or self._overwrite:
            copier.copy_containers(paths)
            self.output.note(f"Resource added to {self._add_path}")
            return

        if not self._overwrite:
            question = (
                "Files in the destination directory will be overwritten. Do you want to proceed?"
            )
            if ask_yes_no(question):
                copier.copy_containers(paths)
            else:
                msg = (
                    "The destination directory contains files that will be overwritten."
                    " Please re-run ansible-creator with --overwrite to continue."
                )
                raise CreatorError(msg)

        self.output.note(f"Resource added to {self._add_path}")

    def _plugin_scaffold(self, plugin_path: Path) -> None:
        """Scaffold the specified plugin file based on the plugin type.

        Args:
            plugin_path: Path where the plugin will be scaffolded.

        Raises:
            CreatorError: If unsupported plugin type is given.
        """
        self.output.debug(f"Started adding {self._plugin_type} plugin to destination")

        # Call the appropriate scaffolding function based on the plugin type
        if self._plugin_type == "action":
            self.update_galaxy_dependency()
            template_data = self._get_plugin_template_data()
            self._perform_action_plugin_scaffold(template_data, plugin_path)

        elif self._plugin_type == "filter":
            template_data = self._get_plugin_template_data()
            self._perform_filter_plugin_scaffold(template_data, plugin_path)

        elif self._plugin_type == "lookup":
            template_data = self._get_plugin_template_data()
            self._perform_lookup_plugin_scaffold(template_data, plugin_path)

        elif self._plugin_type == "modules":
            template_data = self._get_plugin_template_data()
            self._perform_module_plugin_scaffold(template_data, plugin_path)

        elif self._plugin_type == "test":
            template_data = self._get_plugin_template_data()
            self._perform_test_plugin_scaffold(template_data, plugin_path)

        else:
            msg = f"Unsupported plugin type: {self._plugin_type}"
            raise CreatorError(msg)

    def _perform_action_plugin_scaffold(
        self,
        template_data: TemplateData,
        plugin_path: Path,
    ) -> None:
        resources = (
            f"collection_project.plugins.{self._plugin_type}",
            "collection_project.plugins.modules",
        )
        module_path = self._add_path / "plugins" / "modules"
        module_path.mkdir(parents=True, exist_ok=True)
        final_plugin_path = [plugin_path, module_path]
        self._perform_plugin_scaffold(resources, template_data, final_plugin_path)

    def _perform_filter_plugin_scaffold(
        self,
        template_data: TemplateData,
        plugin_path: Path,
    ) -> None:
        resources = (f"collection_project.plugins.{self._plugin_type}",)
        self._perform_plugin_scaffold(resources, template_data, plugin_path)

    def _perform_lookup_plugin_scaffold(
        self,
        template_data: TemplateData,
        plugin_path: Path,
    ) -> None:
        resources = (f"collection_project.plugins.{self._plugin_type}",)
        self._perform_plugin_scaffold(resources, template_data, plugin_path)

    def _perform_module_plugin_scaffold(
        self,
        template_data: TemplateData,
        plugin_path: Path,
    ) -> None:
        resources = (f"collection_project.plugins.{self._plugin_type}",)
        self._perform_plugin_scaffold(resources, template_data, plugin_path)

    def _perform_test_plugin_scaffold(
        self,
        template_data: TemplateData,
        plugin_path: Path,
    ) -> None:
        resources = (f"collection_project.plugins.{self._plugin_type}",)
        self._perform_plugin_scaffold(resources, template_data, plugin_path)

    def _perform_plugin_scaffold(
        self,
        resources: tuple[str, ...],
        template_data: TemplateData,
        plugin_path: Path | list[Path],
    ) -> None:
        """Perform the actual scaffolding process using the provided template data.

        Args:
            resources: Tuple of resources.
            template_data: TemplateData
            plugin_path: Path where the plugin will be scaffolded.

        Raises:
            CreatorError: If there are conflicts and overwriting is not allowed, or if the
                      destination directory contains files that will be overwritten.
        """
        walker = Walker(
            resources=resources,
            resource_id=self._plugin_id,
            dest=plugin_path,
            output=self.output,
            template_data=template_data,
            templar=self.templar,
        )
        paths = walker.collect_paths()
        copier = Copier(output=self.output)

        if self._no_overwrite and paths.has_conflicts():
            msg = (
                "The flag `--no-overwrite` restricts overwriting."
                "\nThe destination directory contains files that can be overwritten."
                "\nPlease re-run ansible-creator with --overwrite to continue."
            )
            raise CreatorError(msg)

        # This check is for action plugins (having module file as an additional path)
        if isinstance(plugin_path, list):
            plugin_path = plugin_path[0]

        if not paths.has_conflicts() or self._force or self._overwrite:
            copier.copy_containers(paths)
            self.output.note(f"{self._plugin_type_output} plugin added to {plugin_path}")
            return

        if not self._overwrite:
            question = (
                "Files in the destination directory will be overwritten. Do you want to proceed?"
            )
            if ask_yes_no(question):
                copier.copy_containers(paths)
            else:
                msg = (
                    "The destination directory contains files that will be overwritten."
                    " Please re-run ansible-creator with --overwrite to continue."
                )
                raise CreatorError(msg)

        self.output.note(f"{self._plugin_type_output} plugin added to {plugin_path}")

    def _get_devfile_template_data(self) -> TemplateData:
        """Get the template data for devfile resources.

        Returns:
            TemplateData: Data required for templating the devfile resource.
        """
        return TemplateData(
            resource_type=self._resource_type,
            creator_version=self._creator_version,
            dev_file_name=self.unique_name_in_devfile(),
        )

    def _get_devcontainer_template_data(self) -> TemplateData:
        """Get the template data for devcontainer resources.

        Returns:
            TemplateData: Data required for templating the devcontainer resource.
        """
        image_mapping = {
            "auto": GLOBAL_TEMPLATE_VARS["DEV_CONTAINER_IMAGE"],
            "upstream": GLOBAL_TEMPLATE_VARS["DEV_CONTAINER_UPSTREAM_IMAGE"],
            "aap": GLOBAL_TEMPLATE_VARS["DEV_CONTAINER_DOWNSTREAM_IMAGE"],
        }

        dev_container_image = image_mapping.get(
            self._dev_container_image,
            self._dev_container_image,
        )

        return TemplateData(
            resource_type=self._resource_type,
            creator_version=self._creator_version,
            dev_file_name=self.unique_name_in_devfile(),
            dev_container_image=dev_container_image,
        )

    def _get_plugin_template_data(self) -> TemplateData:
        """Get the template data for plugin.

        Returns:
            TemplateData: Data required for templating the plugin.
        """
        return TemplateData(
            plugin_type=self._plugin_type,
            plugin_name=self._plugin_name,
            creator_version=self._creator_version,
        )

    def _get_ee_template_data(self) -> TemplateData:
        """Get the template data for ee resources.

        Returns:
            TemplateData: Data required for templating the ee resources.
        """
        return TemplateData(
            resource_type=self._resource_type,
            creator_version=self._creator_version,
        )

    def _get_play_argspec_template_data(self) -> TemplateData:
        """Get the template data for playbook argspec resources.

        Returns:
            TemplateData: Data required for templating the playbook argspec resources.
        """
        return TemplateData(
            resource_type=self._resource_type,
            creator_version=self._creator_version,
        )

    def _get_patterns_template_data(self) -> TemplateData:
        """Get the template data for pattern structure.

        Returns:
            TemplateData: Data required for templating the plugin.
        """
        return TemplateData(
            resource_type=self._resource_type,
            pattern_name=self._pattern_name,
            creator_version=self._creator_version,
        )

    def _get_role_template_data(self) -> TemplateData:
        """Get the template data for role resources.

        Returns:
            TemplateData: Data required for templating the role resource.
        """
        return TemplateData(
            resource_type=self._resource_type,
            role_name=self._role_name,
            namespace=self._namespace,
            collection_name=self._collection_name,
            creator_version=self._creator_version,
        )

================
File: src/ansible_creator/subcommands/init.py
================
"""Definitions for ansible-creator init action."""

from __future__ import annotations

import shutil
import uuid

from pathlib import Path
from typing import TYPE_CHECKING

from ansible_creator.exceptions import CreatorError
from ansible_creator.templar import Templar
from ansible_creator.types import TemplateData
from ansible_creator.utils import Copier, Walker, ask_yes_no


if TYPE_CHECKING:
    from ansible_creator.config import Config
    from ansible_creator.output import Output


class Init:
    """Class representing ansible-creator init subcommand.

    Attributes:
        common_resources: List of common resources to copy.
    """

    common_resources: tuple[str, ...] = (
        "common.devcontainer",
        "common.devfile",
        "common.gitignore",
        "common.vscode",
    )

    def __init__(
        self,
        config: Config,
    ) -> None:
        """Initialize the init action.

        Args:
            config: App configuration object.
        """
        self._namespace: str = config.namespace
        self._collection_name = config.collection_name or ""
        self._init_path: Path = Path(config.init_path)
        self._force = config.force
        self._overwrite = config.overwrite
        self._no_overwrite = config.no_overwrite
        self._creator_version = config.creator_version
        self._project = config.project
        self._templar = Templar()
        self.output: Output = config.output
        self._role_name: str = config.role_name

    def run(self) -> None:
        """Start scaffolding skeleton."""
        self._construct_init_path()
        self.output.debug(msg=f"final destination path set to {self._init_path}")

        if self._init_path.exists():
            self.init_exists()
        self._init_path.mkdir(parents=True, exist_ok=True)

        self._scaffold()

    def _construct_init_path(self) -> None:
        """Construct the init path based on project type."""
        if self._project in ("playbook", "execution_env"):
            return

        if (
            self._init_path.parts[-2:] == ("collections", "ansible_collections")
            and self._project == "collection"
            and isinstance(self._collection_name, str)
        ):
            self._init_path = self._init_path / self._namespace / self._collection_name

    def init_exists(self) -> None:
        """Handle existing init path.

        Raises:
            CreatorError: When init path is a file or not empty and --force is not provided.
        """
        # check if init_path already exists
        # init-path exists and is a file
        if self._init_path.is_file():
            msg = f"the path {self._init_path} already exists, but is a file - aborting"
            raise CreatorError(msg)
        if next(self._init_path.iterdir(), None) and self._force:
            # user requested --force, re-initializing existing directory
            self.output.warning(
                "The `force` flag is deprecated and will be removed soon. "
                "Please start using `overwrite` flag.",
            )
            self.output.warning(
                f"re-initializing existing directory {self._init_path}",
            )
            try:
                shutil.rmtree(self._init_path)
            except OSError as e:
                err = f"failed to remove existing directory {self._init_path}: {e}"
                raise CreatorError(err) from e

    def unique_name_in_devfile(self) -> str:
        """Use project specific name in devfile.

        Returns:
            Unique name entry.
        """
        final_name = f"{self._namespace}.{self._collection_name}"
        final_uuid = str(uuid.uuid4())[:8]
        return f"{final_name}-{final_uuid}"

    def _scaffold(self) -> None:
        """Scaffold an ansible project.

        Raises:
            CreatorError: When the destination directory contains files that will be overwritten and
                the user chooses not to proceed.
        """
        resources: tuple[str, ...]
        self.output.debug(
            msg=f"started copying {self._project} skeleton to destination",
        )
        template_data = TemplateData(
            namespace=self._namespace,
            collection_name=self._collection_name,
            creator_version=self._creator_version,
            dev_file_name=self.unique_name_in_devfile(),
            role_name=self._role_name,
        )

        if self._project == "execution_env":
            resources = (f"{self._project}_project",)
        elif self._project == "collection":
            self.common_resources = (*self.common_resources, "common.role")
            resources = (f"{self._project}_project", *self.common_resources)
        else:
            resources = (f"{self._project}_project", *self.common_resources)

        walker = Walker(
            resources=resources,
            resource_id=f"{self._project}_project",
            dest=self._init_path,
            output=self.output,
            templar=self._templar,
            template_data=template_data,
        )
        paths = walker.collect_paths()

        copier = Copier(
            output=self.output,
        )

        if self._no_overwrite and paths.has_conflicts():
            msg = (
                "The flag `--no-overwrite` restricts overwriting."
                "\nThe destination directory contains files that can be overwritten."
                "\nPlease re-run ansible-creator with --overwrite to continue."
            )
            raise CreatorError(msg)

        if not paths.has_conflicts() or self._force or self._overwrite:
            copier.copy_containers(paths)
            self.output.note(f"{self._project} project created at {self._init_path}")
            return

        if not self._overwrite:
            question = (
                "Files in the destination directory will be overwritten. Do you want to proceed?"
            )
            answer = ask_yes_no(question)
            if answer:
                copier.copy_containers(paths)
            else:
                msg = (
                    "The destination directory contains files that will be overwritten."
                    " Please re-run ansible-creator with --overwrite to continue."
                )
                raise CreatorError(msg)

        self.output.note(f"{self._project} project created at {self._init_path}")

================
File: src/ansible_creator/__init__.py
================
"""The ansible-creator application."""

================
File: src/ansible_creator/__main__.py
================
"""A runpy entry point for ansible-creator.

This makes it possible to invoke CLI
via :command:`python3 -m ansible_creator`.
"""

from __future__ import annotations

from .cli import main


if __name__ == "__main__":
    main()

================
File: src/ansible_creator/_version.pyi
================
version: str

================
File: src/ansible_creator/arg_parser.py
================
"""Parse the command line arguments."""

from __future__ import annotations

import argparse
import re
import sys

from argparse import HelpFormatter
from operator import attrgetter
from pathlib import Path
from typing import TYPE_CHECKING, TypeAlias

from ansible_creator.output import Level, Msg


if TYPE_CHECKING:
    from collections.abc import Iterable
    from typing import Any


try:
    import argcomplete

    HAS_ARGCOMPLETE = True
except ImportError:  # pragma: no cover
    HAS_ARGCOMPLETE = False

try:
    from ._version import version as __version__  # type: ignore[unused-ignore,import-not-found]
except ImportError:  # pragma: no cover
    __version__ = "source"

MIN_COLLECTION_NAME_LEN = 2
MAX_COLLECTION_NAME_LEN = 64


class Parser:
    """A parser for the command line arguments."""

    def __init__(self) -> None:
        """Initialize the parser."""
        self.args: argparse.Namespace
        self.pending_logs: list[Msg] = []

    def parse_args(self) -> tuple[argparse.Namespace, list[Msg]]:
        """Parse the root arguments.

        Returns:
            The parsed arguments and any pending logs
        """
        is_init = sys.argv[1:2] == ["init"]
        not_empty = sys.argv[2:] != []
        not_help = not any(arg in sys.argv for arg in ["-h", "--help"])
        if all((is_init, not_empty, not_help)):
            proceed = self.handle_deprecations()
            if not proceed:
                return argparse.Namespace(), self.pending_logs

        parser = ArgumentParser(
            description="The fastest way to generate all your ansible content.",
            formatter_class=CustomHelpFormatter,
        )
        parser.add_argument(
            "--version",
            action="version",
            help="Print ansible-creator version and exit.",
            version=__version__,
        )
        subparser = parser.add_subparsers(
            dest="subcommand",
            metavar="command",
            required=True,
        )
        self._add(subparser=subparser)
        self._init(subparser=subparser)

        if HAS_ARGCOMPLETE:
            argcomplete.autocomplete(parser)
        self.args = parser.parse_args()

        return self.args, self.pending_logs

    def _add(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add resources to an existing Ansible project.

        Args:
            subparser: The subparser to add the resources to
        """
        parser = subparser.add_parser(
            "add",
            formatter_class=CustomHelpFormatter,
            help="Add resources to an existing Ansible project.",
        )
        subparser = parser.add_subparsers(
            dest="type",
            required=True,
            metavar="content-type",
        )
        self._add_resource(subparser=subparser)
        self._add_plugin(subparser=subparser)

    def _add_args_common(self, parser: ArgumentParser) -> None:
        """Add common arguments to the parser.

        Args:
            parser: The parser to add common arguments to
        """
        parser.add_argument(
            "--na",
            "--no-ansi",
            action="store_true",
            default=False,
            dest="no_ansi",
            help="Disable the use of ANSI codes for terminal color.",
        )

        parser.add_argument(
            "--lf",
            "--log-file <file>",
            dest="log_file",
            default=str(Path.cwd() / "ansible-creator.log"),
            help="Log file to write to.",
        )

        parser.add_argument(
            "--ll",
            "--log-level <level>",
            dest="log_level",
            default="notset",
            choices=["notset", "debug", "info", "warning", "error", "critical"],
            help="Log level for file output.",
        )

        parser.add_argument(
            "--la",
            "--log-append <bool>",
            dest="log_append",
            choices=["true", "false"],
            default="true",
            help="Append to log file.",
        )

        parser.add_argument(
            "--json",
            dest="json",
            action="store_true",
            default=False,
            help="Output messages as JSON",
        )

        parser.add_argument(
            "-v",
            "--verbosity",
            dest="verbose",
            action="count",
            default=0,
            help="Give more Cli output. Option is additive, and can be used up to 3 times.",
        )

    def _add_args_init_common(self, parser: ArgumentParser) -> None:
        """Add common init arguments to the parser.

        Args:
            parser: The parser to add common init arguments to
        """
        parser.add_argument(
            "-f",
            "--force",
            default=False,
            dest="force",
            action="store_true",
            help=(
                "Force re-initialize the specified directory. "
                "This flag is deprecated and will be removed soon."
            ),
        )
        self._add_overwrite(parser)

    def _add_args_plugin_common(self, parser: ArgumentParser) -> None:
        """Add common plugin arguments to the parser.

        Args:
            parser: The parser to add common plugin arguments to
        """
        parser.add_argument(
            "plugin_name",
            help="The name of the plugin to add.",
        )
        parser.add_argument(
            "path",
            default="./",
            nargs="?",
            help="The path to the Ansible collection. The default is the "
            "current working directory.",
        )

    def _add_resource(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add resources to an existing Ansible project.

        Args:
            subparser: The subparser to add resource to
        """
        parser = subparser.add_parser(
            "resource",
            help="Add resources to an existing Ansible project.",
            formatter_class=CustomHelpFormatter,
        )
        subparser = parser.add_subparsers(
            dest="resource_type",
            metavar="resource-type",
            required=True,
        )
        self._add_resource_devcontainer(subparser=subparser)
        self._add_resource_devfile(subparser=subparser)
        self._add_resource_execution_env(subparser=subparser)
        self._add_resource_patterns(subparser=subparser)
        self._add_resource_play_argspec(subparser=subparser)
        self._add_resource_role(subparser=subparser)

    def _add_resource_devcontainer(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add devcontainer files to an existing Ansible project.

        Args:
            subparser: The subparser to add devcontainer files to
        """
        parser = subparser.add_parser(
            "devcontainer",
            help="Add devcontainer files to an existing Ansible project.",
            formatter_class=CustomHelpFormatter,
        )

        parser.add_argument(
            "path",
            default="./",
            metavar="path",
            nargs="?",
            help="The destination directory for the devcontainer files. The default is the "
            "current working directory.",
        )

        parser.add_argument(
            "-i",
            "--image",
            default="auto",
            dest="image",
            required=False,
            help="Image with which devcontainer needs to be scaffolded",
        )

        self._add_overwrite(parser)
        self._add_args_common(parser)

    def _add_resource_devfile(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add a devfile file to an existing Ansible project.

        Args:
            subparser: The subparser to add devfile file to
        """
        parser = subparser.add_parser(
            "devfile",
            help="Add a devfile file to an existing Ansible project.",
            formatter_class=CustomHelpFormatter,
        )
        parser.add_argument(
            "path",
            default="./",
            metavar="path",
            nargs="?",
            help="The destination directory for the devfile file. The default is the "
            "current working directory.",
        )

        self._add_overwrite(parser)
        self._add_args_common(parser)

    def _add_resource_execution_env(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add execution environment sample file to an existing path.

        Args:
            subparser: The subparser to add execution environment file to
        """
        parser = subparser.add_parser(
            "execution-environment",
            help="Add a sample execution-environment.yml file to an existing path.",
            formatter_class=CustomHelpFormatter,
        )

        parser.add_argument(
            "path",
            default="./",
            metavar="path",
            nargs="?",
            help="The destination directory for the execution environment file. "
            "The default is the current working directory.",
        )

        self._add_overwrite(parser)
        self._add_args_common(parser)

    def _add_resource_patterns(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add pattern structure to an existing collection.

        Args:
            subparser: The subparser to add pattern structure to
        """
        parser = subparser.add_parser(
            "pattern",
            help="Add a pattern structure to an existing Ansible collection.",
            formatter_class=CustomHelpFormatter,
        )

        parser.add_argument(
            "pattern_name",
            help="The name of the pattern.",
            type=self._valid_pattern_name,
        )
        parser.add_argument(
            "path",
            default="./",
            metavar="path",
            nargs="?",
            help="The path to the Ansible collection. The default is the "
            "current working directory.",
        )
        self._add_overwrite(parser)
        self._add_args_common(parser)

    def _add_resource_play_argspec(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add example playbook argspec files to an existing Ansible project.

        Args:
            subparser: The subparser to add playbook argspec files to
        """
        parser = subparser.add_parser(
            "play-argspec",
            help="Add example playbook argspec files to an existing Ansible project.",
            formatter_class=CustomHelpFormatter,
        )

        parser.add_argument(
            "path",
            default="./",
            metavar="path",
            nargs="?",
            help="The destination directory for the playbook argspec files. The default is the "
            "current working directory.",
        )

        self._add_overwrite(parser)
        self._add_args_common(parser)

    def _add_resource_role(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add a role to an existing Ansible collection.

        Args:
            subparser: The subparser to add role to
        """
        parser = subparser.add_parser(
            "role",
            help="Add a role to an existing Ansible collection.",
            formatter_class=CustomHelpFormatter,
        )
        parser.add_argument(
            "role_name",
            help="The name of the role to add.",
        )
        parser.add_argument(
            "path",
            default="./",
            metavar="path",
            nargs="?",
            help="The path to the Ansible collection. The default is the "
            "current working directory.",
        )

        self._add_overwrite(parser)
        self._add_args_common(parser)

    def _add_plugin(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add a plugin to an Ansible project.

        Args:
            subparser: The subparser to add plugin to
        """
        parser = subparser.add_parser(
            "plugin",
            help="Add a plugin to an Ansible collection.",
            formatter_class=CustomHelpFormatter,
        )
        subparser = parser.add_subparsers(
            dest="plugin_type",
            metavar="plugin-type",
            required=True,
        )

        self._add_plugin_action(subparser=subparser)
        self._add_plugin_filter(subparser=subparser)
        self._add_plugin_lookup(subparser=subparser)
        self._add_plugin_module(subparser=subparser)
        self._add_plugin_test(subparser=subparser)

    def _add_plugin_action(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add an action plugin to an existing Ansible collection project.

        Args:
            subparser: The subparser to add action plugin to
        """
        parser = subparser.add_parser(
            "action",
            help="Add an action plugin to an existing Ansible collection.",
            formatter_class=CustomHelpFormatter,
        )
        self._add_args_common(parser)
        self._add_overwrite(parser)
        self._add_args_plugin_common(parser)

    def _add_plugin_filter(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add a filter plugin to an existing Ansible collection project.

        Args:
            subparser: The subparser to add filter plugin to
        """
        parser = subparser.add_parser(
            "filter",
            help="Add a filter plugin to an existing Ansible collection.",
            formatter_class=CustomHelpFormatter,
        )
        self._add_args_common(parser)
        self._add_overwrite(parser)
        self._add_args_plugin_common(parser)

    def _add_plugin_lookup(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add a lookup plugin to an existing Ansible collection project.

        Args:
            subparser: The subparser to add lookup plugin to
        """
        parser = subparser.add_parser(
            "lookup",
            help="Add a lookup plugin to an existing Ansible collection.",
            formatter_class=CustomHelpFormatter,
        )
        self._add_args_common(parser)
        self._add_overwrite(parser)
        self._add_args_plugin_common(parser)

    def _add_plugin_module(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add a module plugin to an existing Ansible collection project.

        Args:
            subparser: The subparser to add module plugin to
        """
        parser = subparser.add_parser(
            "module",
            help="Add a module plugin to an existing Ansible collection.",
            formatter_class=CustomHelpFormatter,
        )
        self._add_args_common(parser)
        self._add_overwrite(parser)
        self._add_args_plugin_common(parser)

    def _add_plugin_test(self, subparser: SubParser[ArgumentParser]) -> None:
        """Add a test plugin to an existing Ansible collection project.

        Args:
            subparser: The subparser to add test plugin to
        """
        parser = subparser.add_parser(
            "test",
            help="Add a test plugin to an existing Ansible collection.",
            formatter_class=CustomHelpFormatter,
        )
        self._add_args_common(parser)
        self._add_overwrite(parser)
        self._add_args_plugin_common(parser)

    def _add_overwrite(self, parser: ArgumentParser) -> None:
        """Add overwrite and no-overwrite arguments to the parser.

        Args:
            parser: The parser to add overwrite and no_overwrite options
        """
        parser.add_argument(
            "-o",
            "--overwrite",
            default=False,
            dest="overwrite",
            action="store_true",
            help="Overwrite existing files or directories.",
        )
        parser.add_argument(
            "-no",
            "--no-overwrite",
            default=False,
            dest="no_overwrite",
            action="store_true",
            help="Flag that restricts overwriting operation.",
        )

    def _init(self, subparser: SubParser[ArgumentParser]) -> None:
        """Initialize an Ansible project.

        Args:
            subparser: The subparser add init to
        """
        parser = subparser.add_parser(
            "init",
            formatter_class=CustomHelpFormatter,
            help="Initialize a new Ansible project.",
        )
        subparser = parser.add_subparsers(
            dest="project",
            metavar="project-type",
            required=True,
        )

        self._init_collection(subparser=subparser)
        self._init_playbook(subparser=subparser)
        self._init_ee_project(subparser=subparser)

    def _init_collection(self, subparser: SubParser[ArgumentParser]) -> None:
        """Initialize an Ansible collection.

        Args:
            subparser: The subparser to add collection to
        """
        parser = subparser.add_parser(
            "collection",
            help="Create a new Ansible collection project.",
            formatter_class=CustomHelpFormatter,
        )
        parser.add_argument(
            "collection",
            help="The collection name in the format '<namespace>.<name>'.",
            metavar="collection-name",
            type=self._valid_collection_name,
        )
        parser.add_argument(
            "init_path",
            default="./",
            metavar="path",
            nargs="?",
            help="The destination directory for the collection project. The default is the "
            "current working directory.",
        )

        self._add_args_common(parser)
        self._add_args_init_common(parser)

    def _init_playbook(self, subparser: SubParser[ArgumentParser]) -> None:
        """Initialize an Ansible playbook.

        Args:
            subparser: The subparser to add playbook to
        """
        parser = subparser.add_parser(
            "playbook",
            help="Create a new Ansible playbook project.",
            formatter_class=CustomHelpFormatter,
        )

        parser.add_argument(
            "collection",
            help="The name for the playbook adjacent collection in the format"
            " '<namespace>.<name>'.",
            metavar="collection-name",
            type=self._valid_collection_name,
        )

        parser.add_argument(
            "init_path",
            default="./",
            metavar="path",
            nargs="?",
            help="The destination directory for the playbook project. The default is the "
            "current working directory.",
        )
        self._add_args_common(parser)
        self._add_args_init_common(parser)

    def _init_ee_project(self, subparser: SubParser[ArgumentParser]) -> None:
        """Initialize an EE project.

        Args:
            subparser: The subparser to add EE project to
        """
        parser = subparser.add_parser(
            "execution_env",
            help="Create a new execution environment project.",
            formatter_class=CustomHelpFormatter,
        )
        parser.add_argument(
            "init_path",
            metavar="path",
            nargs="?",
            help="The destination directory for the EE project.",
        )

        self._add_args_common(parser)
        self._add_args_init_common(parser)

    def _valid_collection_name(self, collection: str) -> str:
        """Validate the collection name.

        Args:
            collection: The collection name to validate

        Returns:
            The validated collection name
        """
        fqcn = collection.split(".", maxsplit=1)
        expected_parts = 2
        name_filter = re.compile(r"^(?!_)[a-z0-9_]+$")

        if len(fqcn) != expected_parts:
            msg = "Collection name must be in the format '<namespace>.<name>'."
            self.pending_logs.append(Msg(prefix=Level.CRITICAL, message=msg))
        elif not name_filter.match(fqcn[0]) or not name_filter.match(fqcn[1]):
            msg = (
                "Collection name can only contain lower case letters, underscores, and numbers"
                " and cannot begin with an underscore."
            )
            self.pending_logs.append(Msg(prefix=Level.CRITICAL, message=msg))
        elif len(fqcn[0]) <= MIN_COLLECTION_NAME_LEN or len(fqcn[1]) <= MIN_COLLECTION_NAME_LEN:
            msg = "Both the collection namespace and name must be longer than 2 characters."
            self.pending_logs.append(Msg(prefix=Level.CRITICAL, message=msg))
        return collection

    def _valid_pattern_name(self, pattern_name: str) -> str:
        """Validate the pattern name.

        Args:
            pattern_name: The pattern name to validate

        Returns:
            The validated pattern name
        """
        name_filter = re.compile(r"^(?!_)[a-z0-9_]+$")

        if not name_filter.match(pattern_name):
            msg = (
                "Pattern name can only contain lower case letters, underscores, and numbers"
                " and cannot begin with an underscore."
            )
            self.pending_logs.append(Msg(prefix=Level.CRITICAL, message=msg))
        elif (
            len(pattern_name) >= MAX_COLLECTION_NAME_LEN
            or len(pattern_name) <= MIN_COLLECTION_NAME_LEN
        ):
            msg = "The pattern name must be longer than 2 characters and less than 64 characters."
            self.pending_logs.append(Msg(prefix=Level.CRITICAL, message=msg))
        return pattern_name

    def handle_deprecations(self) -> bool:  # noqa: C901
        """Start parsing args passed from Cli.

        Returns:
            True if parsing can proceed, False otherwise
        """
        parser = argparse.ArgumentParser()
        parser.add_argument("command", help="")
        parser.add_argument("collection", nargs="?", help="")
        parser.add_argument("--project", help="")
        parser.add_argument("--scm-org", help="")
        parser.add_argument("--scm-project", help="")
        parser.add_argument("--init-path", help="")
        args, extras = parser.parse_known_args()

        if args.collection in ["playbook", "collection", "execution_env"]:
            return True
        if args.project:
            msg = "The `project` flag is no longer needed and will be removed."
            self.pending_logs.append(Msg(prefix=Level.WARNING, message=msg))
        if not args.project:
            msg = "The default value `collection` for project type will be removed."
            self.pending_logs.append(Msg(prefix=Level.WARNING, message=msg))
            args.project = "collection"
        if args.scm_org:
            msg = "The `scm-org` flag is no longer needed and will be removed."
            self.pending_logs.append(Msg(prefix=Level.WARNING, message=msg))
        if args.scm_project:
            msg = "The `scm-project` flag is no longer needed and will be removed."
            self.pending_logs.append(Msg(prefix=Level.WARNING, message=msg))
        if args.init_path:
            msg = "The `init-path` flag is no longer needed and will be removed."
            self.pending_logs.append(Msg(prefix=Level.WARNING, message=msg))

        exit_msg = "The CLI has changed. Please refer to `--help` for the new syntax."
        if args.project == "ansible-project":
            args.project = "playbook"
            if not args.scm_org or not args.scm_project:
                self.pending_logs.append(Msg(prefix=Level.CRITICAL, message=exit_msg))
                return False
            msg = "The `ansible-project` project type is deprecated. Please use `playbook`."
            self.pending_logs.append(Msg(prefix=Level.WARNING, message=msg))
            args.collection = f"{args.scm_org}.{args.scm_project}"
        if args.project == "collection" and not args.collection:
            self.pending_logs.append(Msg(prefix=Level.CRITICAL, message=exit_msg))
            return False
        # ansible-creator init collection, ansible-creator init playbook

        base_cli = ["ansible-creator", args.command, args.project, args.collection]
        if args.init_path:
            base_cli.append(args.init_path)
        new_cli = base_cli + extras
        hint = f"Please use the following command in the future: `{' '.join(new_cli)}`"
        self.pending_logs.append(Msg(prefix=Level.HINT, message=hint))
        sys.argv = new_cli
        return True


class ArgumentParser(argparse.ArgumentParser):
    """A custom argument parser."""

    def add_argument(  # type: ignore[override]
        self,
        *args: Any,  # noqa: ANN401
        **kwargs: Any,  # noqa: ANN401
    ) -> None:
        """Add an argument.

        Args:
            *args: The arguments
            **kwargs: The keyword arguments
        """
        if "choices" in kwargs:
            kwargs["help"] += f" (choices: {', '.join(kwargs['choices'])})"
        if "default" in kwargs and kwargs["default"] != "==SUPPRESS==":
            kwargs["help"] += f" (default: {kwargs['default']})"
        kwargs["help"] = kwargs["help"][0].upper() + kwargs["help"][1:]
        super().add_argument(*args, **kwargs)

    def add_argument_group(
        self,
        *args: Any,  # noqa: ANN401
        **kwargs: Any,  # noqa: ANN401
    ) -> argparse._ArgumentGroup:
        """Add an argument group.

        Args:
            *args: The arguments
            **kwargs: The keyword arguments

        Returns:
            The argument group
        """
        group = super().add_argument_group(*args, **kwargs)
        if group.title:
            group.title = group.title.capitalize()
        return group


if TYPE_CHECKING:
    SubParser: TypeAlias = argparse._SubParsersAction  # noqa: SLF001


class CustomHelpFormatter(HelpFormatter):
    """A custom help formatter."""

    def __init__(self, prog: str) -> None:
        """Initialize the help formatter.

        Args:
            prog: The program name
        """
        long_string = "--abc  --really_really_really_log"
        # 3 here accounts for the spaces in the ljust(6) below
        HelpFormatter.__init__(
            self,
            prog=prog,
            indent_increment=1,
            max_help_position=len(long_string) + 3,
        )

    def _format_action_invocation(
        self,
        action: argparse.Action,
    ) -> str:
        """Format the action invocation.

        Args:
            action: The action to format

        Raises:
            ValueError: If more than 2 options are given

        Returns:
            The formatted action invocation
        """
        if not action.option_strings:
            default = self._get_default_metavar_for_positional(action)
            (metavar,) = self._metavar_formatter(action, default)(1)
            return metavar

        if len(action.option_strings) == 1:
            return action.option_strings[0]

        max_variations = 2
        if len(action.option_strings) == max_variations:
            # Account for a --1234 --long-option-name
            return f"{action.option_strings[0].ljust(6)} {action.option_strings[1]}"
        msg = "Too many option strings"
        raise ValueError(msg)

    def add_arguments(self, actions: Iterable[argparse.Action]) -> None:
        """Add arguments sorted by option strings.

        Args:
            actions: The actions to add
        """
        actions = sorted(actions, key=attrgetter("option_strings"))
        super().add_arguments(actions)

================
File: src/ansible_creator/cli.py
================
# PYTHON_ARGCOMPLETE_OK
"""The ansible-creator Cli."""

from __future__ import annotations

import os
import sys

from importlib import import_module
from typing import Any

from ansible_creator.arg_parser import Parser
from ansible_creator.config import Config
from ansible_creator.exceptions import CreatorError
from ansible_creator.output import Msg, Output
from ansible_creator.utils import TermFeatures, expand_path


try:
    from ._version import version as __version__
except ImportError:  # pragma: no cover
    __version__ = "source"


class Cli:
    """Class representing the ansible-creator Cli."""

    def __init__(self) -> None:
        """Initialize the Cli and parse Cli args."""
        self.args: dict[str, Any]
        self.output: Output
        self.pending_logs: list[Msg]
        self.term_features: TermFeatures
        self.parse_args()

    def init_output(self) -> None:
        """Initialize the output object.

        In case the arg parsing exited early, set some sane default values.
        """
        no_ansi = self.args.pop("no_ansi", False)
        if not sys.stdout.isatty():
            self.term_features = TermFeatures(color=False, links=False)
        else:
            self.term_features = TermFeatures(
                color=False if os.environ.get("NO_COLOR") else not no_ansi,
                links=not no_ansi,
            )

        self.output = Output(
            log_append=self.args.pop("log_append", False),
            log_file=str(expand_path(self.args.pop("log_file", "./ansible-creator.log"))),
            log_level=self.args.pop("log_level", "info"),
            term_features=self.term_features,
            verbosity=self.args.pop("verbose", 0),
            display="json" if self.args.pop("json", None) else "text",
        )

    def parse_args(self) -> None:
        """Start parsing args passed from Cli."""
        args, pending_logs = Parser().parse_args()
        self.args = vars(args)
        self.pending_logs = pending_logs

    def process_pending_logs(self) -> None:
        """Log any pending logs."""
        for msg in self.pending_logs:
            getattr(self.output, msg.prefix.value.lower())(msg.message)

    def run(self) -> None:
        """Dispatch work to correct subcommand class."""
        self.output.debug(msg=f"parsed args {self.args!s}")
        subcommand = self.args["subcommand"]
        subcommand_module = f"ansible_creator.subcommands.{subcommand}"
        subcommand_cls = f"{subcommand}".capitalize()
        self.args.update({"creator_version": __version__})

        try:
            self.output.debug(msg=f"starting requested action '{subcommand}'")
            subcommand = getattr(import_module(subcommand_module), subcommand_cls)
            self.output.debug(f"found action class {subcommand}")
            subcommand(config=Config(**self.args, output=self.output)).run()
        except CreatorError as exc:
            self.output.error(str(exc))
            sys.exit(1)

        self.output.debug(msg="exiting ansible-creator")


def main() -> None:
    """Entry point for ansible-creator Cli."""
    cli = Cli()
    cli.init_output()
    cli.process_pending_logs()
    cli.run()


if __name__ == "__main__":
    main()

================
File: src/ansible_creator/compat.py
================
"""Compat library for ansible-creator.

This contains compatibility definitions for older python
When we need to import a module differently depending on python versions, we do it
here.
"""

from __future__ import annotations

import sys


if sys.version_info >= (3, 11):
    from importlib.resources.abc import Traversable as _Traversable
else:
    from importlib.abc import (  # pylint: disable = deprecated-class
        Traversable as _Traversable,  # pragma: no cover
    )

Traversable = _Traversable

================
File: src/ansible_creator/config.py
================
"""Application configuration class for ansible-creator."""

from __future__ import annotations

from dataclasses import dataclass
from typing import TYPE_CHECKING

from ansible_creator.utils import expand_path


if TYPE_CHECKING:
    from pathlib import Path

    from ansible_creator.output import Output


@dataclass(frozen=True)
class Config:
    """The application configuration for ansible-creator.

    Attributes:
        creator_version: The version of ansible-creator.
        output: The output object to use for logging.
        subcommand: The subcommand to execute.
        collection: The collection name to scaffold.
        force: Whether to overwrite existing files.
        overwrite: To overwrite files in an existing directory.
        no_overwrite: To not overwrite files in an existing directory.
        init_path: The path to initialize the project.
        project: The type of project to scaffold.
        collection_name: The name of the collection.
        namespace: The namespace for the collection.
        resource_type: The type of resource to be scaffolded.
        plugin_name: The name of plugin to be scaffolded.
        plugin_type: The type of plugin to be scaffolded.
        type: The type of the project for which the resource is being scaffolded.
        path: The file path where the resource should be added.
        image: The image to be used while scaffolding devcontainer.
        pattern_name: The pattern to be scaffolded.
        role_name: The role to be scaffolded.
    """

    creator_version: str
    output: Output
    subcommand: str
    collection: str = ""
    force: bool = False
    overwrite: bool = False
    no_overwrite: bool = False
    init_path: str | Path = "./"
    project: str = ""
    collection_name: str | None = None
    namespace: str = ""
    resource_type: str = ""
    plugin_name: str = ""
    plugin_type: str = ""
    type: str = ""
    path: str | Path = "./"
    image: str = ""
    pattern_name: str = "sample_pattern"
    role_name: str = "run"

    def __post_init__(self) -> None:
        """Post process config values."""
        if self.project == "ansible-project":
            object.__setattr__(self, "project", "playbook")

        if self.collection:
            fqcn = self.collection.split(".", maxsplit=1)
            object.__setattr__(self, "namespace", fqcn[0])
            object.__setattr__(self, "collection_name", fqcn[-1])

        if isinstance(self.init_path, str):
            object.__setattr__(self, "init_path", expand_path(self.init_path))

        if self.plugin_type == "module":
            object.__setattr__(self, "plugin_type", "modules")

        if self.resource_type == "pattern":
            object.__setattr__(self, "resource_type", "patterns")

================
File: src/ansible_creator/constants.py
================
"""Definition of constants for this package."""

from __future__ import annotations


GLOBAL_TEMPLATE_VARS = {
    # DEV_CONTAINER_IMAGE gets updated with the downstream image when the package
    # is installed using rpm
    # See: https://gitlab.cee.redhat.com/aap-cpaas/config/ansible-creator/-/blob/ansible-automation-platform-2.5/distgit/rpms/ansible-creator/ansible-creator.spec.in?ref_type=heads#L34
    "DEV_CONTAINER_IMAGE": "ghcr.io/ansible/community-ansible-dev-tools:latest",
    "DEV_CONTAINER_UPSTREAM_IMAGE": "ghcr.io/ansible/community-ansible-dev-tools:latest",
    "DEV_CONTAINER_DOWNSTREAM_IMAGE": (
        "registry.redhat.io/ansible-automation-platform-25/ansible-dev-tools-rhel8:latest"
    ),
    "DEV_FILE_IMAGE": "ghcr.io/ansible/ansible-devspaces:latest",
    "RECOMMENDED_EXTENSIONS": ["redhat.ansible", "redhat.vscode-redhat-account"],
    "EXECUTION_ENVIRONMENT_DEFAULT_IMAGE": "quay.io/fedora/fedora:41",
}

MIN_COLLECTION_NAME_LEN = 2

# directory names that will be skipped in any resource
SKIP_DIRS = ("__pycache__",)
# file types that will be skipped in any resource
SKIP_FILES_TYPES = (".pyc",)

================
File: src/ansible_creator/exceptions.py
================
"""Custom exception classes for ansible-creator."""

from __future__ import annotations


class CreatorError(Exception):
    """Class representing exceptions raised from creator code."""

    def __init__(self, message: str) -> None:
        """Instantiate an object of this class.

        Args:
            message: The exception message.
        """
        super().__init__(message)
        self._message = message

    @property
    def message(self) -> str:
        """Craft and return the CreatorError message.

        Includes the 'cause' when raised from another exception.

        Returns:
            An exception message.
        """
        msg = self._message
        if getattr(self, "__cause__", ""):
            msg += f"\n{self.__cause__!s}"
        return msg

    def __str__(self) -> str:
        """Return a string representation of the exception.

        Returns:
            The exception message as a string.
        """
        return self.message

================
File: src/ansible_creator/output.py
================
"""Output functionality."""

from __future__ import annotations

import decimal
import json
import logging
import os
import shutil
import sys
import textwrap

from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from typing import TYPE_CHECKING, TypeVar


if TYPE_CHECKING:
    from .utils import TermFeatures


T = TypeVar("T", bound="Level")
GOLDEN_RATIO = 1.61803398875


def round_half_up(number: float) -> int:
    """Round a number to the nearest integer with ties going away from zero.

    This is different the round() where exact halfway cases are rounded to the nearest
    even result instead of away from zero. (e.g. round(2.5) = 2, round(3.5) = 4).

    This will always round based on distance from zero. (e.g round(2.5) = 3, round(3.5) = 4).

    Args:
        number: The number to round
    Returns:
        The rounded number as an int
    """
    rounded = decimal.Decimal(number).quantize(
        decimal.Decimal(1),
        rounding=decimal.ROUND_HALF_UP,
    )
    return int(rounded)


def console_width() -> int:
    """Get a console width based on common screen widths.

    Returns:
        The console width
    """
    columns = int(os.environ.get("COLUMNS", "0"))
    if columns:
        return columns
    medium = 80
    wide = 132
    width = shutil.get_terminal_size().columns
    if width <= medium:
        return width
    if width <= wide:
        return max(80, round_half_up(width / GOLDEN_RATIO))
    return wide


class Color:
    """Color constants.

    Attributes:
        BLACK: Black color
        RED: Red color
        GREEN: Green color
        YELLOW: Yellow color
        BLUE: Blue color
        MAGENTA: Magenta color
        CYAN: Cyan color
        WHITE: White color
        GREY: Bright black color
        BRIGHT_RED: Bright red color
        BRIGHT_GREEN: Bright green color
        BRIGHT_YELLOW: Bright yellow color
        BRIGHT_BLUE: Bright blue color
        BRIGHT_MAGENTA: Bright magenta color
        BRIGHT_CYAN: Bright cyan color
        BRIGHT_WHITE: Bright white color
        END: End
    """

    BLACK = "\033[30m"
    RED = "\033[31m"
    GREEN = "\033[32m"
    YELLOW = "\033[33m"
    BLUE = "\033[34m"
    MAGENTA = "\033[35m"
    CYAN = "\033[36m"
    WHITE = "\033[37m"
    GREY = "\033[90m"  # Bright black?
    BRIGHT_RED = "\033[91m"
    BRIGHT_GREEN = "\033[92m"
    BRIGHT_YELLOW = "\033[93m"
    BRIGHT_BLUE = "\033[94m"
    BRIGHT_MAGENTA = "\033[95m"
    BRIGHT_CYAN = "\033[96m"
    BRIGHT_WHITE = "\033[97m"
    END = "\033[0m"


class Level(Enum):
    """An exit message prefix.

    Attributes:
        CRITICAL: Critical
        DEBUG: Debug
        ERROR: Error
        HINT: Hint
        INFO: Info
        NOTE: Note
        WARNING: Warning
    """

    CRITICAL = "Critical"
    DEBUG = "Debug"
    ERROR = "Error"
    HINT = "Hint"
    INFO = "Info"
    NOTE = "Note"
    WARNING = "Warning"

    @property
    def log_level(self) -> int:
        """Return a log level.

        :returns: The log level
        """
        mapping = {
            Level.CRITICAL: logging.CRITICAL,
            Level.DEBUG: logging.DEBUG,
            Level.ERROR: logging.ERROR,
            Level.HINT: logging.INFO,
            Level.INFO: logging.INFO,
            Level.NOTE: logging.INFO,
            Level.WARNING: logging.WARNING,
        }
        return mapping[self]

    @classmethod
    def _longest_name(cls) -> int:
        """Return the longest exit message prefix.

        Returns:
            The longest exit message prefix
        """
        return max(len(member.value) for member in cls)

    @classmethod
    def longest_formatted(cls) -> int:
        """Return the longest exit message prefix.

        Returns:
            The longest exit message prefix
        """
        return max(len(str(member)) for member in cls)

    def __str__(self) -> str:
        """Return the exit message prefix as a string.

        Returns:
            The exit message prefix as a string
        """
        return f"{' ' * (self._longest_name() - len(self.name))}{self.name.capitalize()}: "


@dataclass
class Msg:
    """An object to hold a message to present when exiting.

    Attributes:
        message: The message that will be presented
        prefix: The prefix for the message, used for formatting
    """

    message: str
    prefix: Level = Level.ERROR

    @property
    def color(self) -> str:
        """Return a color for the prefix.

        :returns: The color for the prefix
        """
        color_mapping = {
            Level.CRITICAL: Color.BRIGHT_RED,
            Level.DEBUG: Color.GREY,
            Level.ERROR: Color.RED,
            Level.HINT: Color.CYAN,
            Level.INFO: Color.MAGENTA,
            Level.NOTE: Color.GREEN,
            Level.WARNING: Color.YELLOW,
        }
        return color_mapping[self.prefix]

    def to_lines(
        self,
        color: bool,  # noqa: FBT001
        width: int,
        with_prefix: bool,  # noqa: FBT001
    ) -> list[str]:
        """Output exit message to the console.

        Args:
            color: Whether to color the message
            width: Constrain message to width
            with_prefix: Whether to prefix the message
        Returns:
            The exit message as a string
        """
        prefix_length = Level.longest_formatted()
        indent = " " * prefix_length

        lines = []
        message_lines = self.message.splitlines()

        lines.extend(
            textwrap.fill(
                message_lines[0],
                width=width,
                break_on_hyphens=False,
                initial_indent=str(self.prefix) if with_prefix else indent,
                subsequent_indent=indent,
            ).splitlines(),
        )

        if len(message_lines) > 1:
            for line in message_lines[1:]:
                lines.extend(
                    textwrap.fill(
                        line,
                        width=width,
                        break_on_hyphens=False,
                        initial_indent=indent,
                        subsequent_indent=indent,
                    ).splitlines(),
                )

        start_color = self.color if color else ""
        end_color = Color.END if color else ""

        return [f"{start_color}{line}{end_color}" for line in lines]


class Output:
    """Output functionality."""

    def __init__(  # noqa: PLR0913 # pylint: disable=too-many-positional-arguments
        self,
        log_file: str,
        log_level: str,
        log_append: str,
        term_features: TermFeatures,
        verbosity: int,
        display: str = "text",
    ) -> None:
        """Initialize the output object.

        Args:
            log_file: The path to the log file
            log_level: The log level
            log_append: Whether to append to the log file
            term_features: Terminal features
            verbosity: The verbosity level
            display: Whether to output as text or JSON
        """
        self._verbosity = verbosity
        self.call_count: dict[str, int] = {
            "critical": 0,
            "debug": 0,
            "error": 0,
            "hint": 0,
            "info": 0,
            "note": 0,
            "warning": 0,
        }
        self.term_features = term_features
        self.logger = logging.getLogger("ansible_creator")
        if log_level != "notset":
            self.logger.setLevel(log_level.upper())
            log_file_path = Path(log_file)
            if log_file_path.exists() and log_append == "false":
                log_file_path.unlink()
            formatter = logging.Formatter(
                fmt="%(asctime)s %(levelname)s '%(name)s.%(module)s.%(funcName)s' %(message)s",
            )
            handler = logging.FileHandler(log_file)
            handler.setFormatter(formatter)
            handler.setLevel(log_level.upper())
            self.logger.addHandler(handler)
            self.log_to_file = True
        else:
            self.log_to_file = False
        self.display = display

    def critical(self, msg: str) -> None:
        """Print a critical message to the console.

        Args:
            msg: The message to print
        """
        self.call_count["critical"] += 1
        self.log(msg, level=Level.CRITICAL)
        sys.exit(1)

    def debug(self, msg: str) -> None:
        """Print a debug message to the console.

        Args:
            msg: The message to print
        """
        self.call_count["debug"] += 1
        self.log(msg, level=Level.DEBUG)

    def error(self, msg: str) -> None:
        """Print an error message to the console.

        Args:
            msg: The message to print
        """
        self.call_count["error"] += 1
        self.log(msg, level=Level.ERROR)

    def hint(self, msg: str) -> None:
        """Print a hint message to the console.

        Args:
            msg: The message to print
        """
        self.call_count["hint"] += 1
        self.log(msg, level=Level.HINT)

    def info(self, msg: str) -> None:
        """Print a info message to the console.

        Args:
            msg: The message to print
        """
        self.call_count["info"] += 1
        self.log(msg, level=Level.INFO)

    def note(self, msg: str) -> None:
        """Print a note message to the console.

        Args:
            msg: The message to print
        """
        self.call_count["note"] += 1
        self.log(msg, level=Level.NOTE)

    def warning(self, msg: str) -> None:
        """Print a warning message to the console.

        Args:
            msg: The message to print
        """
        self.call_count["warning"] += 1
        self.log(msg, level=Level.WARNING)

    def log(self, msg: str, level: Level = Level.ERROR) -> None:
        """Print a message to the console.

        Args:
            msg: The message to print
            level: The level of the message
        """
        if self.log_to_file:
            self.logger.log(level.log_level, msg, stacklevel=3)

        debug = 2
        info = 1
        if (self._verbosity < debug and level == Level.DEBUG) or (
            self._verbosity < info and level == Level.INFO
        ):
            return

        if self.display == "json":
            print(  # noqa: T201
                json.dumps({"level": level.name, "msg": msg}),
                flush=True,
            )
            return

        lines = Msg(message=msg, prefix=level).to_lines(
            color=self.term_features.color,
            width=console_width(),
            with_prefix=True,
        )
        final_msg = "\n".join(lines)

        file = sys.stderr if level in [Level.CRITICAL, Level.ERROR] else sys.stdout

        print(final_msg, file=file)

================
File: src/ansible_creator/templar.py
================
"""A Jinja2 template engine."""

from __future__ import annotations

import json

from dataclasses import asdict
from typing import TYPE_CHECKING


if TYPE_CHECKING:
    from ansible_creator.types import TemplateData


try:
    from jinja2 import Environment, StrictUndefined

    HAS_JINJA2 = True
except ImportError:
    HAS_JINJA2 = False


class Templar:
    """Class representing a Jinja2 template engine."""

    def __init__(self) -> None:
        """Instantiate the template engine.

        Raises:
            ImportError: when jinja2 is not installed.
        """
        if not HAS_JINJA2:
            msg = (
                "jinja2 is required but does not appear to be installed."
                "It can be installed using `pip install jinja2`"
            )
            raise ImportError(
                msg,
            )
        self.env: Environment = Environment(  # noqa: S701
            undefined=StrictUndefined,
            keep_trailing_newline=True,
        )
        self.env.filters["json"] = json.dumps

    def render_from_content(self, template: str, data: TemplateData) -> str:
        """Render a template with provided data.

        Args:
            template: The template to load and render.
            data: Data to render template with.

        Returns:
            Templated content.
        """
        return self.env.from_string(template).render(asdict(data))

================
File: src/ansible_creator/types.py
================
"""A home for shared types."""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import TYPE_CHECKING

from ansible_creator.constants import GLOBAL_TEMPLATE_VARS


if TYPE_CHECKING:
    from collections.abc import Sequence


@dataclass
class TemplateData:
    """Dataclass representing the template data.

    Attributes:
        resource_type: The type of resource to be scaffolded.
        plugin_type: The type of plugin to be scaffolded.
        plugin_name: The name of the plugin to be scaffolded.
        pattern_name: The name of the pattern to be scaffolded.
        role_name: The name of the role to be scaffolded.
        additions: A dictionary containing additional data to add to the gitignore.
        collection_name: The name of the collection.
        creator_version: The version of the creator.
        dev_container_image: The devcontainer image.
        dev_file_image: The devfile image.
        dev_file_name: The unique name entry in devfile.
        namespace: The namespace of the collection.
        execution_environment_image: The execution environment image.
        recommended_extensions: A list of recommended VsCode extensions.
    """

    resource_type: str = ""
    plugin_type: str = ""
    plugin_name: str = ""
    pattern_name: str = ""
    role_name: str = ""
    additions: dict[str, dict[str, dict[str, str | bool]]] = field(default_factory=dict)
    collection_name: str = ""
    creator_version: str = ""
    dev_container_image: Sequence[str] = GLOBAL_TEMPLATE_VARS["DEV_CONTAINER_IMAGE"]
    dev_file_image: Sequence[str] = GLOBAL_TEMPLATE_VARS["DEV_FILE_IMAGE"]
    dev_file_name: str = ""
    namespace: str = ""
    execution_environment_image: Sequence[str] = GLOBAL_TEMPLATE_VARS[
        "EXECUTION_ENVIRONMENT_DEFAULT_IMAGE"
    ]
    recommended_extensions: Sequence[str] = field(
        default_factory=lambda: GLOBAL_TEMPLATE_VARS["RECOMMENDED_EXTENSIONS"],
    )

================
File: src/ansible_creator/utils.py
================
"""Re-usable utility functions used by this package."""

from __future__ import annotations

import copy
import os
import shutil

from dataclasses import dataclass
from functools import cached_property
from importlib import resources as impl_resources
from pathlib import Path
from typing import TYPE_CHECKING

import yaml

from ansible_creator.constants import SKIP_DIRS, SKIP_FILES_TYPES
from ansible_creator.output import Color


if TYPE_CHECKING:
    from ansible_creator.compat import Traversable
    from ansible_creator.output import Output
    from ansible_creator.templar import Templar
    from ansible_creator.types import TemplateData


PATH_REPLACERS = {
    "project_org": "namespace",
    "project_repo": "collection_name",
    "sample_module": "plugin_name",
    "sample_action": "plugin_name",
    "sample_filter": "plugin_name",
    "sample_lookup": "plugin_name",
    "sample_test": "plugin_name",
    "sample_pattern": "pattern_name",
    "run": "role_name",
}


@dataclass
class TermFeatures:
    """Terminal features.

    Attributes:
        color: Enable color output.
        links: Enable clickable links.
    """

    color: bool
    links: bool

    def any_enabled(self) -> bool:
        """Return True if any features are enabled.

        Returns:
            bool: True if any features are enabled.
        """
        return any((self.color, self.links))


def expand_path(path: str) -> Path:
    """Resolve absolute path.

    Args:
        path: Path to expand.

    Returns:
        Expanded absolute path.
    """
    _path = Path(os.path.expandvars(path))
    _path = _path.expanduser()
    return _path.resolve()


@dataclass
class DestinationFile:
    """Container to hold information about a file to be copied.

    Attributes:
        source: The path of the original copy.
        dest: The path the file will be written to.
        content: The templated content to be written to dest.
    """

    source: Traversable
    dest: Path
    content: str = ""

    def __str__(self) -> str:
        """Supports str() on DestinationFile.

        Returns:
            A string representation of the destination path.
        """
        return str(self.dest)

    @cached_property
    def conflict(self) -> str:
        """Check for file conflicts.

        Returns:
            String describing the file conflict, if any.
        """
        if not self.dest.exists():
            return ""

        if self.source.is_file():
            if self.dest.is_file():
                dest_content = self.dest.read_text("utf8")
                if self.content != dest_content:
                    return f"{self.dest} already exists"
            else:
                return f"{self.dest} already exists and is a directory!"

        if self.source.is_dir() and not self.dest.is_dir():
            return f"{self.dest} already exists and is a file!"

        return ""

    @cached_property
    def needs_write(self) -> bool:
        """Check if file needs to be written to.

        Returns:
            True if dest differs from source else False.
        """
        # Skip files in SKIP_FILES_TYPES and __meta__.yaml
        if self.source.is_file() and (
            self.source.name.split(".")[-1] in SKIP_FILES_TYPES
            or self.source.name == "__meta__.yml"
        ):
            return False

        if not self.dest.exists():
            return True
        return bool(self.conflict)

    def set_content(self, template_data: TemplateData, templar: Templar | None) -> None:
        """Set expected content from source file, templated by templar if necessary.

        Args:
            template_data: A dictionary containing current data to render templates with.
            templar: An instance of the Templar class.
        """
        content = self.source.read_text(encoding="utf-8")
        # only render as templates if both of these are provided,
        # and original file suffix was j2
        if templar and template_data and self.source.name.endswith("j2"):
            content = templar.render_from_content(
                template=content,
                data=template_data,
            )
        self.content = content

    def remove_existing(self) -> None:
        """Remove existing files or directories at destination path."""
        if self.dest.is_file():
            self.dest.unlink()
        elif self.dest.is_dir():
            shutil.rmtree(self.dest)


class FileList(list[DestinationFile]):
    """A list subclass holding DestinationFiles with convenience methods."""

    def has_conflicts(self) -> bool:
        """Check if any files have conflicts in the destination.

        Returns:
            True if there are any conflicts else False.
        """
        return any(path.conflict for path in self)


@dataclass
class Walker:
    """Configuration for the Walker class.

    Attributes:
        resources: List of resource containers to copy.
        resource_id: The id of the resource to copy.
        dest: The destination path to copy resources to.
        output: An instance of the Output class.
        template_data: A dictionary containing the original data to render templates with.
        resource_root: Root path for the resources.
        templar: An instance of the Templar class.
    """

    resources: tuple[str, ...]
    resource_id: str
    dest: Path | list[Path]
    output: Output
    template_data: TemplateData
    resource_root: str = "ansible_creator.resources"
    templar: Templar | None = None

    def _recursive_walk(
        self,
        root: Traversable,
        resource: str,
        current_index: int,
        template_data: TemplateData,
    ) -> FileList:
        """Recursively traverses a resource container looking for content to copy.

        Args:
            root: A traversable object representing root of the container to copy.
            resource: The resource being scanned.
            current_index: Current index in the list of objects.
            template_data: A dictionary containing current data to render templates with.

        Returns:
            A list of paths to be written to.
        """
        self.output.debug(msg=f"current root set to {root}")

        file_list = FileList()

        # Process all objects in the directory
        for obj in root.iterdir():
            file_list.extend(
                self.each_obj(
                    current_index,
                    obj,
                    resource=resource,
                    template_data=template_data,
                ),
            )
        return file_list

    def each_obj(
        self,
        current_index: int,
        obj: Traversable,
        resource: str,
        template_data: TemplateData,
    ) -> FileList:
        """Recursively traverses a resource container and copies content to destination.

        Args:
            current_index: Current index in the list of objects.
            obj: A traversable object representing the root of the container to copy.
            resource: The resource to consult for path names.
            template_data: A dictionary containing current data to render templates with.

        Returns:
            A list of paths.
        """
        # resource names may have a . but directories use / in the path
        dest_name = str(obj).split(
            resource.replace(".", "/") + "/",
            maxsplit=1,
        )[-1]

        # replace placeholders in destination path with real values
        for key, val in PATH_REPLACERS.items():
            repl_val = getattr(template_data, val)
            if key in dest_name and repl_val:
                dest_name = dest_name.replace(key, repl_val)
        dest_name = dest_name.removesuffix(".j2")

        if isinstance(self.dest, list):
            # If self.dest is a list of Path
            dest_path = DestinationFile(
                dest=self.dest[current_index] / dest_name,
                source=obj,
            )
        else:
            # If self.dest is a single Path
            dest_path = DestinationFile(dest=self.dest / dest_name, source=obj)

        self.output.debug(f"Looking at {dest_path}")
        if obj.is_file():
            dest_path.set_content(template_data, self.templar)

        if dest_path.needs_write:
            conflict_msg = dest_path.conflict
            if conflict_msg:
                self.output.warning(conflict_msg)

            if obj.is_dir() and obj.name not in SKIP_DIRS:
                return FileList(
                    [
                        dest_path,
                        *self._recursive_walk(
                            root=obj,
                            resource=resource,
                            current_index=current_index,
                            template_data=template_data,
                        ),
                    ],
                )
            if obj.is_file():
                return FileList([dest_path])
        if obj.is_dir() and obj.name not in SKIP_DIRS:
            return self._recursive_walk(
                root=obj,
                resource=resource,
                current_index=current_index,
                template_data=template_data,
            )
        return FileList()

    def _per_container(self, resource: str, current_index: int) -> FileList:
        """Generate a list of all paths that will be written to for a particular resource.

        Args:
            resource: The resource to search through.
            current_index: Current index in the list of objects.

        Returns:
            A list of paths to be written to.
        """
        msg = f"starting recursive walk with source container '{resource}'"
        self.output.debug(msg)

        # Cast the template data to not pollute the original
        template_data = copy.deepcopy(self.template_data)

        # Collect and template any resource specific variables
        meta_file = impl_resources.files(f"{self.resource_root}.{resource}") / "__meta__.yml"
        try:
            with meta_file.open("r", encoding="utf-8") as meta_fileh:
                self.output.debug(
                    msg=f"loading resource specific vars from {meta_file}",
                )
                meta = yaml.safe_load(meta_fileh.read())
        except FileNotFoundError:
            meta = {}
            self.output.debug(msg="no resource specific vars found")

        found = meta.get(self.resource_id, {})
        for key, value in found.items():
            if value["template"] and self.templar:
                serialized = yaml.dump(value["value"])
                templated = self.templar.render_from_content(
                    template=serialized,
                    data=template_data,
                )
                deserialized = yaml.safe_load(templated)
                # Use the deserialized templated value
                setattr(template_data, key, deserialized)
            else:
                setattr(template_data, key, value["value"])

        return self._recursive_walk(
            impl_resources.files(f"{self.resource_root}.{resource}"),
            resource,
            current_index,
            template_data,
        )

    def collect_paths(self) -> FileList:
        """Determine paths that will be written to.

        Returns:
            A list of paths to be written to.
        """
        file_list = FileList()
        current_index: int = 0
        for current_index, resource in enumerate(self.resources):
            file_list.extend(self._per_container(resource, current_index))

        return file_list


@dataclass
class Copier:
    """Configuration for the Copier class.

    Attributes:
        output: An instance of the Output class.
    """

    output: Output

    def _copy_file(
        self,
        dest_path: DestinationFile,
    ) -> None:
        """Copy a file to destination.

        Args:
            dest_path: The destination path to copy the file to.
        """
        # remove .j2 suffix at destination
        self.output.debug(msg=f"Writing to {dest_path}")

        with dest_path.dest.open("w", encoding="utf-8") as df_handle:
            df_handle.write(dest_path.content)

    def copy_containers(self, paths: FileList) -> None:
        """Copy multiple containers to destination.

        Args:
            paths: A list of paths to create in the destination.
        """
        for path in paths:
            path.remove_existing()

            if path.source.is_dir():
                path.dest.mkdir(parents=True, exist_ok=True)

            elif path.source.is_file():
                self._copy_file(path)


def ask_yes_no(question: str) -> bool:
    """Ask a question and return the answer.

    Args:
        question: The question to ask.

    Returns:
        The answer as a boolean.
    """
    answer = ""
    while answer not in ["y", "n"]:
        answer = input(f"{Color.MAGENTA}{question} (y/n){Color.END}: ").lower()
    return answer == "y"

================
File: tests/fixtures/collection/testorg/testcol/.devcontainer/docker/devcontainer.json
================
{
  "name": "ansible-dev-container-docker",
  "image": "ghcr.io/ansible/community-ansible-dev-tools:latest",
  "containerUser": "root",
  "runArgs": [
    "--security-opt",
    "seccomp=unconfined",
    "--security-opt",
    "label=disable",
    "--cap-add=SYS_ADMIN",
    "--cap-add=SYS_RESOURCE",
    "--device",
    "/dev/fuse",
    "--security-opt",
    "apparmor=unconfined",
    "--hostname=ansible-dev-container"
  ],
  "updateRemoteUserUID": true,
  "customizations": {
    "vscode": {
      "extensions": ["redhat.ansible", "redhat.vscode-redhat-account"]
    }
  }
}

================
File: tests/fixtures/collection/testorg/testcol/.devcontainer/podman/devcontainer.json
================
{
  "name": "ansible-dev-container-podman",
  "image": "ghcr.io/ansible/community-ansible-dev-tools:latest",
  "containerUser": "root",
  "runArgs": [
    "--cap-add=CAP_MKNOD",
    "--cap-add=NET_ADMIN",
    "--cap-add=SYS_ADMIN",
    "--cap-add=SYS_RESOURCE",
    "--device",
    "/dev/fuse",
    "--security-opt",
    "seccomp=unconfined",
    "--security-opt",
    "label=disable",
    "--security-opt",
    "apparmor=unconfined",
    "--security-opt",
    "unmask=/sys/fs/cgroup",
    "--userns=host",
    "--hostname=ansible-dev-container"
  ],
  "customizations": {
    "vscode": {
      "extensions": ["redhat.ansible", "redhat.vscode-redhat-account"]
    }
  }
}

================
File: tests/fixtures/collection/testorg/testcol/.devcontainer/devcontainer.json
================
{
  "name": "ansible-dev-container-codespaces",
  "image": "ghcr.io/ansible/community-ansible-dev-tools:latest",
  "containerUser": "root",
  "runArgs": [
    "--security-opt",
    "seccomp=unconfined",
    "--security-opt",
    "label=disable",
    "--cap-add=SYS_ADMIN",
    "--cap-add=SYS_RESOURCE",
    "--device",
    "/dev/fuse",
    "--security-opt",
    "apparmor=unconfined",
    "--hostname=ansible-dev-container"
  ],
  "updateRemoteUserUID": true,
  "customizations": {
    "vscode": {
      "extensions": ["redhat.ansible", "redhat.vscode-redhat-account"]
    }
  }
}

================
File: tests/fixtures/collection/testorg/testcol/.github/workflows/release.yml
================
---
name: Release testorg.testcol

on: # yamllint disable-line rule:truthy
  release:
    types: [published]

jobs:
  release_automation_hub:
    uses: ansible/ansible-content-actions/.github/workflows/release_galaxy.yaml@main
    with:
      environment: release
    secrets:
      ansible_galaxy_api_key: ${{ secrets.ANSIBLE_GALAXY_API_KEY }}

================
File: tests/fixtures/collection/testorg/testcol/.github/workflows/tests.yml
================
---
name: "CI"

concurrency:
  group: ${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

on: # yamllint disable-line rule:truthy
  pull_request:
    branches: [main]
  workflow_dispatch:
  # TO-DO: Below is an example cron scheduler. Uncomment and tweak it as per your requirement
  # schedule:
    # - cron: '0 0 * * *'

jobs:
  changelog:
    uses: ansible/ansible-content-actions/.github/workflows/changelog.yaml@main
    if: github.event_name == 'pull_request'
  build-import:
    uses: ansible/ansible-content-actions/.github/workflows/build_import.yaml@main
  ansible-lint:
    uses: ansible/ansible-content-actions/.github/workflows/ansible_lint.yaml@main
  sanity:
    uses: ansible/ansible-content-actions/.github/workflows/sanity.yaml@main
  unit-galaxy:
    uses: ansible/ansible-content-actions/.github/workflows/unit.yaml@main
  unit-source:
    uses: ansible-network/github_actions/.github/workflows/unit_source.yml@main
    with:
      collection_pre_install: >-
        git+https://github.com/ansible-collections/ansible.utils.git
  all_green:
    if: ${{ always() }}
    needs:
      - changelog
      - build-import
      - sanity
      - unit-galaxy
      - unit-source
      - ansible-lint
    runs-on: ubuntu-latest
    steps:
      - run: >-
          python -c "assert 'failure' not in
          set([
          '${{ needs.changelog.result }}',
          '${{ needs.sanity.result }}',
          '${{ needs.unit-galaxy.result }}'
          '${{ needs.ansible-lint.result }}'
          '${{ needs.unit-source.result }}'
          ])"

================
File: tests/fixtures/collection/testorg/testcol/.vscode/extensions.json
================
{
  "recommendations": ["redhat.ansible", "redhat.vscode-redhat-account"]
}

================
File: tests/fixtures/collection/testorg/testcol/changelogs/config.yaml
================
---
changelog_filename_template: ../CHANGELOG.rst
changelog_filename_version_depth: 0
changes_file: changelog.yaml
changes_format: combined
keep_fragments: false
mention_ancestor: true
new_plugins_after_name: removed_features
notesdir: fragments
prelude_section_name: release_summary
prelude_section_title: Release Summary
flatmap: true
sections:
  - - major_changes
    - Major Changes
  - - minor_changes
    - Minor Changes
  - - breaking_changes
    - Breaking Changes / Porting Guide
  - - deprecated_features
    - Deprecated Features
  - - removed_features
    - Removed Features (previously deprecated)
  - - security_fixes
    - Security Fixes
  - - bugfixes
    - Bugfixes
  - - known_issues
    - Known Issues
  - - doc_changes
    - Documentation Changes
title: "Testorg Testcol Collection"
trivial_section_name: trivial

================
File: tests/fixtures/collection/testorg/testcol/docs/docsite/links.yml
================
---
# This will make sure that plugin and module documentation gets Edit on GitHub links
# that allow users to directly create a PR for this plugin or module in GitHub's UI.
# Remove this section if the collection repository is not on GitHub, or if you do not
# want this functionality for your collection.
edit_on_github:
  # TO-DO: Update this if your collection lives in a different GitHub organization.
  repository: ansible-collections/testorg.testcol
  branch: main
  # If your collection root (the directory containing galaxy.yml) does not coincide with your
  # repository's root, you have to specify the path to the collection root here. For example,
  # if the collection root is in a subdirectory ansible_collections/community/REPO_NAME
  # in your repository, you have to set path_prefix to 'ansible_collections/community/REPO_NAME'.
  path_prefix: ""

# Here you can add arbitrary extra links. Please keep the number of links down to a
# minimum! Also please keep the description short, since this will be the text put on
# a button.
#
# Also note that some links are automatically added from information in galaxy.yml.
# The following are automatically added:
#   1. A link to the issue tracker (if `issues` is specified);
#   2. A link to the homepage (if `homepage` is specified and does not equal the
#      `documentation` or `repository` link);
#   3. A link to the collection's repository (if `repository` is specified).

extra_links:
  - description: Report an issue
    # TO-DO: Update this if your collection lives in a different GitHub organization.
    url: https://github.com/ansible-collections/testorg.testcol/issues/new/choose

# Specify communication channels for your collection. We suggest to not specify more
# than one place for communication per communication tool to avoid confusion.
communication:
  forum:
    - topic: Ansible Forum
      url: https://forum.ansible.com/

================
File: tests/fixtures/collection/testorg/testcol/extensions/eda/rulebooks/rulebook.yml
================
---
- name: Hello Events
  hosts: localhost
  sources:
    - ansible.eda.range:
        limit: 5
  rules:
    - name: Say Hello
      condition: event.i == 1
      action:
        run_playbook:
          name: ansible.eda.hello

================
File: tests/fixtures/collection/testorg/testcol/extensions/molecule/integration_hello_world/molecule.yml
================
---
platforms:
  - name: na

provisioner:
  name: ansible
  playbooks:
    cleanup: ../utils/playbooks/noop.yml
    converge: ../utils/playbooks/converge.yml
    destroy: ../utils/playbooks/noop.yml
    prepare: ../utils/playbooks/noop.yml
  config_options:
    defaults:
      collections_path: ${ANSIBLE_COLLECTIONS_PATH}
scenario:
  test_sequence:
    - prepare
    - converge
  destroy_sequence:
    - destroy

================
File: tests/fixtures/collection/testorg/testcol/extensions/molecule/utils/playbooks/converge.yml
================
---
- name: Shared integration test runner
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Load the vars
      ansible.builtin.include_vars:
        file: ../../utils/vars/vars.yml

    - name: "Integration test: {{ test_name }}"
      ansible.builtin.include_role:
        name: "{{ test_path }}"
      vars:
        test_path: "{{ integration_tests_path }}{{ test_name }}"
        test_name: "{{ molecule_scenario_name.replace('integration_', '') }}"

================
File: tests/fixtures/collection/testorg/testcol/extensions/molecule/utils/playbooks/noop.yml
================
---
- name: No-op
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Run a noop
      ansible.builtin.debug:
        msg: "This does nothing!"

================
File: tests/fixtures/collection/testorg/testcol/extensions/molecule/utils/vars/vars.yml
================
collection_root: "{{ lookup('env', 'MOLECULE_PROJECT_DIRECTORY') }}/.."
integration_tests_path: "{{ collection_root }}/tests/integration/targets/"
molecule_scenario_name: "{{ molecule_scenario_directory | basename }}"

================
File: tests/fixtures/collection/testorg/testcol/meta/runtime.yml
================
---
requires_ansible: ">=2.15.0"

================
File: tests/fixtures/collection/testorg/testcol/plugins/action/sample_action.py
================
# sample_action.py - A custom action plugin for Ansible.
# Author: Your Name
# License: GPL-3.0-or-later
# pylint: disable=E0401

from __future__ import absolute_import, annotations, division, print_function

__metaclass__ = type  # pylint: disable=C0103

from typing import TYPE_CHECKING
from ansible_collections.ansible.utils.plugins.module_utils.common.argspec_validate import (  # type: ignore
    AnsibleArgSpecValidator,
)
from ansible_collections.ansible.utils.plugins.modules.fact_diff import DOCUMENTATION  # type: ignore
from ansible.plugins.action import ActionBase  # type: ignore


if TYPE_CHECKING:
    from typing import Optional, Dict, Any


class ActionModule(ActionBase):  # type: ignore[misc]
    """
    Custom Ansible action plugin: sample_action
    A custom action plugin for Ansible.
    """

    def _check_argspec(self, result: dict[str, Any]) -> None:
        aav = AnsibleArgSpecValidator(
            data=self._task.args,
            schema=DOCUMENTATION,
            schema_format="doc",
            name=self._task.action,
        )
        valid, errors, self._task.args = aav.validate()
        if not valid:
            result["failed"] = True
            result["msg"] = errors

    def run(
        self,
        tmp: Optional[str] = None,
        task_vars: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Executes the action plugin.

        Args:
            tmp: Temporary path provided by Ansible for the module execution. Defaults to None.
            task_vars: Dictionary of task variables available to the plugin. Defaults to None.

        Returns:
            dict: Result of the action plugin execution.
        """
        # Get the task arguments
        if task_vars is None:
            task_vars = {}
        result: Dict[str, Any] = {}
        warnings: list[str] = []

        # Example processing logic - Replace this with actual action code
        result = super(ActionModule, self).run(tmp, task_vars)
        self._check_argspec(result)

        # Copy the task arguments
        module_args = self._task.args.copy()

        prefix = module_args.get("prefix", "DefaultPrefix")
        message = module_args.get("msg", "No message provided")
        module_args["msg"] = f"{prefix}: {message}"

        result.update(
            self._execute_module(
                module_name="debug",
                module_args=module_args,
                task_vars=task_vars,
                tmp=tmp,
            ),
        )

        if warnings:
            if "warnings" in result:
                result["warnings"].extend(warnings)
            else:
                result["warnings"] = warnings
        return result

================
File: tests/fixtures/collection/testorg/testcol/plugins/filter/sample_filter.py
================
# sample_filter.py - A custom filter plugin for Ansible.
# Author: Your Name
# License: GPL-3.0-or-later

from __future__ import absolute_import, annotations, division, print_function


__metaclass__ = type  # pylint: disable=C0103

from typing import TYPE_CHECKING


if TYPE_CHECKING:
    from typing import Callable


DOCUMENTATION = """
    name: sample_filter
    author: Your Name
    version_added: "1.0.0"
    short_description: A custom filter plugin for Ansible.
    description:
      - This is a demo filter plugin designed to return Hello message.
    options:
      name:
        description: Value specified here is appended to the Hello message.
        type: str
"""

EXAMPLES = """
# sample_filter filter example

- name: Display a hello message
  ansible.builtin.debug:
    msg: "{{ 'ansible-creator' | sample_filter }}"
"""


def _sample_filter(name: str) -> str:
    """Returns Hello message.

    Args:
        name: The name to greet.

    Returns:
        str: The greeting message.
    """
    return "Hello, " + name


class FilterModule:
    """filter plugin."""

    def filters(self) -> dict[str, Callable[[str], str]]:
        """Map filter plugin names to their functions.

        Returns:
            dict: The filter plugin functions.
        """
        return {"sample_filter": _sample_filter}

================
File: tests/fixtures/collection/testorg/testcol/plugins/lookup/sample_lookup.py
================
# sample_lookup.py - A custom lookup plugin for Ansible.

# pylint: disable=E0401
# sample_lookup.py - A custom lookup plugin for Ansible.
# Author: Your Name (@username)
# Copyright 2020 Red Hat
# GNU General Public License v3.0+
# (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

DOCUMENTATION = """
    name: sample_lookup
    author: Your Name (@username)
    version_added: "1.0.0"
    short_description: A custom lookup plugin for Ansible.
    description:
      - This is a custom lookup plugin to provide lookup functionality.
    options:
      _terms:
        description: Terms to lookup
        required: True
    notes:
      - This is a scaffold template. Customize the plugin to fit your needs.
"""

EXAMPLES = """
- name: Example usage of sample_lookup
  ansible.builtin.debug:
    msg: "{{ lookup('sample_lookup', 'example_term') }}"
"""

RETURN = """
_list:
  description: The list of values found by the lookup
  type: list
"""

from typing import Any, Dict, List, Optional

from ansible.errors import AnsibleError  # type: ignore
from ansible.plugins.lookup import LookupBase  # type: ignore
from ansible.utils.display import Display  # type: ignore

display = Display()


class LookupModule(LookupBase):  # type: ignore[misc]
    """
    Custom Ansible lookup plugin: sample_lookup
    A custom lookup plugin for Ansible.
    """

    def run(
        self,
        terms: List[str],
        variables: Optional[Dict[str, Any]] = None,
        **kwargs: Dict[str, Any],
    ) -> list[str]:
        """
        Run the lookup with the specified terms.

        Args:
            terms: A list of terms to lookup.
            variables: Additional variables.
            **kwargs: Additional keyword arguments.

        Returns:
            list: A list of processed results.

        Raises:
            AnsibleError: If the 'terms' parameter is not a list.
        """
        if not isinstance(terms, list):
            raise AnsibleError("The 'terms' parameter must be a list.")

        display.vvv(f"Running sample_lookup lookup plugin with terms: {terms}")

        try:
            # Example processing logic - Replace this with actual lookup code
            result = [term.upper() for term in terms]

            display.vvv(f"Result from sample_lookup lookup: {result}")
            return result

        except Exception as e:
            raise AnsibleError(f"Error in sample_lookup plugin: {e}") from e

================
File: tests/fixtures/collection/testorg/testcol/plugins/modules/sample_action.py
================
# sample_action.py
# GNU General Public License v3.0+

DOCUMENTATION = """
    module: sample_action
    author: Your Name (@username)
    version_added: "1.0.0"
    short_description: A custom action plugin for Ansible.
    description:
      - This is a custom action plugin to provide action functionality.
    options:
      prefix:
        description:
          - A string that is added as a prefix to the message passed to the module.
        type: str
      msg:
        description: The message to display in the output.
        type: str
      with_prefix:
        description:
          - A boolean flag indicating whether to include the prefix in the message.
        type: bool
    notes:
      - This is a scaffold template. Customize the plugin to fit your needs.
"""

EXAMPLES = """
- name: Example Action Plugin
  hosts: localhost
  tasks:
    - name: Example sample_action plugin
      with_prefix:
        prefix: "Hello, World"
        msg: "Ansible!"
"""

================
File: tests/fixtures/collection/testorg/testcol/plugins/modules/sample_module.py
================
#!/usr/bin/python
# pylint: disable=E0401
# sample_module.py - A custom module plugin for Ansible.
# Author: Your Name (@username)
# License: GPL-3.0-or-later
# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)

from __future__ import absolute_import, annotations, division, print_function


DOCUMENTATION = """
    module: sample_module
    author: Your Name (@username)
    version_added: "1.0.0"
    short_description: A custom module plugin for Ansible.
    description:
      - This is a demo module plugin designed to return Hello message.
    options:
      name:
        description: Value specified here is appended to the Hello message.
        type: str
        required: true
"""

EXAMPLES = """
- name: Run the module
  register: result
  sample_module:
    name: "ansible-creator"

- name: Display the message
  ansible.builtin.debug:
    msg: result.message
"""

RETURN = """
message:
  description:
  - A demo message.
  type: str
  returned: always
  sample: "Hello, ansible-creator"
"""


__metaclass__ = type  # pylint: disable=C0103

from typing import TYPE_CHECKING

from ansible.module_utils.basic import AnsibleModule  # type: ignore


if TYPE_CHECKING:
    from typing import Callable


def _sample_module(name: str) -> str:
    """Returns Hello message.

    Args:
        name: The name to greet.

    Returns:
        str: The greeting message.
    """
    return "Hello, " + name


def main() -> None:
    """Entry point for module execution"""
    argument_spec = dict(
        name=dict(type="str", required=True),
    )
    module = AnsibleModule(
        argument_spec=argument_spec,
    )

    message = _sample_module(module.params["name"])

    result = {
        "changed": False,
        "message": message,
    }
    module.exit_json(**result)


if __name__ == "__main__":
    main()

================
File: tests/fixtures/collection/testorg/testcol/plugins/test/sample_test.py
================
# sample_test.py - A custom test plugin for Ansible.
# Author: Your Name
# License: GPL-3.0-or-later

from __future__ import absolute_import, annotations, division, print_function


__metaclass__ = type  # pylint: disable=C0103

from typing import TYPE_CHECKING


if TYPE_CHECKING:
    from typing import Callable


DOCUMENTATION = """
    name: sample_test
    author: Your Name
    version_added: "1.0.0"
    short_description: A custom test plugin for Ansible.
    description:
      - This is a demo test plugin designed to return a bool.
    options:
      name:
        type: bool
        description: This is a sample option.
"""

EXAMPLES = """
# sample_test test example

- name: Display a bool
  ansible.builtin.debug:
    msg: "{{ 50 | sample_test }}"
"""


def _sample_test(val: int) -> bool:
    """Returns a bool.

    Args:
        val: The value to test.

    Returns:
        bool: The result.
    """
    return val > 42


class TestModule:
    """test plugin."""

    def tests(self) -> dict[str, Callable[[int], bool]]:
        """Map test plugin names to their functions.

        Returns:
            dict: The test plugin functions.
        """
        return {"sample_test": _sample_test}

================
File: tests/fixtures/collection/testorg/testcol/roles/run/defaults/main.yml
================
---
# defaults file for testorg.testcol.run

================
File: tests/fixtures/collection/testorg/testcol/roles/run/handlers/main.yml
================
---
# handlers file for testorg.testcol.run

================
File: tests/fixtures/collection/testorg/testcol/roles/run/meta/argument_specs.yml
================
---
# argument spec file for testorg.testcol.run

argument_specs:
  main:
    short_description: Role description.
    options:
      my_variable:
        type: str
        description: A simple string argument for demonstration.
        default: "default_value"

================
File: tests/fixtures/collection/testorg/testcol/roles/run/meta/main.yml
================
galaxy_info:
  author: foo
  description: testorg.testcol run Role
  company: testorg

  # If the issue tracker for your role is not on github, uncomment the
  # next line and provide a value
  # issue_tracker_url: http://example.com/issue/tracker

  # Choose a valid license ID from https://spdx.org - some suggested licenses:
  # - BSD-3-Clause (default)
  # - MIT
  # - GPL-2.0-or-later
  # - GPL-3.0-only
  # - Apache-2.0
  # - CC-BY-4.0
  license: GPL-2.0-or-later

  min_ansible_version: "2.14"

  # If this a Container Enabled role, provide the minimum Ansible Container version.
  # min_ansible_container_version:

  #
  # Provide a list of supported platforms, and for each platform a list of versions.
  # If you don't wish to enumerate all versions for a particular platform, use 'all'.
  # To view available platforms and versions (or releases), visit:
  # https://galaxy.ansible.com/api/v1/platforms/
  #
  # platforms:
  # - name: Fedora
  #   versions:
  #   - all
  #   - 25
  # - name: SomePlatform
  #   versions:
  #   - all
  #   - 1.0
  #   - 7
  #   - 99.99

  galaxy_tags:
    []
    # List tags for your role here, one per line. A tag is a keyword that describes
    # and categorizes the role. Users find roles by searching for tags. Be sure to
    # remove the '[]' above, if you add tags to this list.
    #
    # NOTE: A tag is limited to a single word comprised of alphanumeric characters.
    #       Maximum 20 tags per role.

dependencies:
  []
  # List your role dependencies here, one per line. Be sure to remove the '[]' above,
  # if you add dependencies to this list.

================
File: tests/fixtures/collection/testorg/testcol/roles/run/tasks/main.yml
================
---
# tasks file for testorg.testcol.run

# task example for debugging a value
- name: Debug the value of my_variable
  ansible.builtin.debug:
    msg: "The value of my_variable is {{ my_variable }}"

================
File: tests/fixtures/collection/testorg/testcol/roles/run/tests/inventory
================
localhost

================
File: tests/fixtures/collection/testorg/testcol/roles/run/vars/main.yml
================
---
# vars file for testorg.testcol.run

================
File: tests/fixtures/collection/testorg/testcol/roles/run/README.md
================
testorg.testcol run Role
========================

A brief description of the role goes here.

Requirements
------------

Any pre-requisites that may not be covered by Ansible itself or the role should be mentioned here. For instance, if the role uses the EC2 module, it may be a good idea to mention in this section that the boto package is required.

Role Variables
--------------

A description of the settable variables for this role should go here, including any variables that are in defaults/main.yml, vars/main.yml, and any variables that can/should be set via parameters to the role. Any variables that are read from other roles and/or the global scope (ie. hostvars, group vars, etc.) should be mentioned here as well.

Dependencies
------------

A list of other roles hosted on Galaxy should go here, plus any details in regards to parameters that may need to be set for other roles, or variables that are used from other roles.

Example Playbook
----------------

Including an example of how to use your role (for instance, with variables passed in as parameters) is always nice for users too:

```yaml
- name: Execute tasks on servers
  hosts: servers
  roles:
    - role: testorg.testcol.run
      run_x: 42
```

Another way to consume this role would be:

```yaml
- name: Initialize the run role from testorg.testcol
  hosts: servers
  gather_facts: false
  tasks:
    - name: Trigger invocation of run role
      ansible.builtin.include_role:
        name: testorg.testcol.run
      vars:
        run_x: 42
```

Role Idempotency
----------------

Designation of the role as idempotent (True/False)

Role Atomicity
----------------

Designation of the role as atomic if applicable (True/False)

Roll-back capabilities
----------------------

Define the roll-back capabilities of the role

Argument Specification
----------------------

Including an example of how to add an argument Specification file that validates the arguments provided to the role.

```
argument_specs:
  main:
    short_description: Role description.
    options:
      string_arg1:
        description: string argument description.
        type: "str"
        default: "x"
        choices: ["x", "y"]
```

License
-------

# TO-DO: Update the license to the one you want to use (delete this line after setting the license)
BSD

Author Information
------------------

An optional section for the role authors to include contact information, or a website (HTML is not allowed).

================
File: tests/fixtures/collection/testorg/testcol/tests/integration/targets/hello_world/tasks/main.yml
================
---
- name: Test the Hello World filter plugin
  ansible.builtin.set_fact:
    msg: "{{ 'ansible-creator' | testorg.testcol.sample_filter }}"

- name: Assert that the filter worked
  ansible.builtin.assert:
    that:
      - msg == 'Hello, ansible-creator'

================
File: tests/fixtures/collection/testorg/testcol/tests/integration/test_integration.py
================
"""Tests for molecule scenarios."""

from __future__ import absolute_import, division, print_function

from pytest_ansible.molecule import MoleculeScenario


def test_integration(molecule_scenario: MoleculeScenario) -> None:
    """Run molecule for each scenario.

    Args:
        molecule_scenario: The molecule scenario object
    Raises:
        AssertionError: If the molecule scenario test does not return a zero exit code.
    """
    proc = molecule_scenario.test()
    assert proc.returncode == 0

================
File: tests/fixtures/collection/testorg/testcol/tests/unit/test_basic.py
================
"""Unit tests for testorg.testcol."""


def test_basic() -> None:
    """Dummy unit test that always passes.

    Raises:
        AssertionError: If the assertion fails.
    """
    assert bool(1) is True

================
File: tests/fixtures/collection/testorg/testcol/tests/.gitignore
================
output/

================
File: tests/fixtures/collection/testorg/testcol/.gitignore
================
# https://raw.githubusercontent.com/github/gitignore/main/Python.gitignore
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# MacOS
.DS_Store

# Ansible
.ansible/

================
File: tests/fixtures/collection/testorg/testcol/.isort.cfg
================
[settings]
known_first_party=ansible_collections.testorg.testcol
line_length=100
lines_after_imports=2
lines_between_types=1
profile=black

================
File: tests/fixtures/collection/testorg/testcol/.pre-commit-config.yaml
================
---
repos:
  - repo: https://github.com/ansible-network/collection_prep
    rev: 1.1.1
    hooks:
      - id: update-docs

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: check-merge-conflict
      - id: check-symlinks
      - id: debug-statements
      - id: end-of-file-fixer
      - id: no-commit-to-branch
        args: [--branch, main]
      - id: trailing-whitespace

  - repo: https://github.com/asottile/add-trailing-comma
    rev: v3.0.0
    hooks:
      - id: add-trailing-comma

  - repo: https://github.com/pre-commit/mirrors-prettier
    rev: "v3.0.0"
    hooks:
      - id: prettier
        entry: env CI=1 bash -c "prettier --list-different . || ec=$? && prettier --loglevel=error --write . && exit $ec"
        pass_filenames: false
        args: []
        additional_dependencies:
          - prettier
          - prettier-plugin-toml

  - repo: https://github.com/PyCQA/isort
    rev: 5.12.0
    hooks:
      - id: isort
        name: Sort import statements using isort
        args: ["--filter-files"]

  - repo: https://github.com/psf/black
    rev: 23.7.0
    hooks:
      - id: black

  - repo: https://github.com/pycqa/flake8
    rev: 7.0.0
    hooks:
      - id: flake8

================
File: tests/fixtures/collection/testorg/testcol/.prettierignore
================
# files we don't want prettier to ever to look into
.*/
coverage/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# A linked collection directory created by pytest-ansible-units
collections/

tests/output/

README.md

================
File: tests/fixtures/collection/testorg/testcol/CHANGELOG.rst
================
This should be updated by antsibull-changelog. Do not edit this manually!

See https://github.com/ansible-community/antsibull-changelog/blob/main/docs/changelogs.rst for
information on how to use antsibull-changelog.

Check out ``changelogs/config.yaml`` for its configuration. You need to change at least the ``title`` field in there.

================
File: tests/fixtures/collection/testorg/testcol/CODE_OF_CONDUCT.md
================
# Community Code of Conduct

Please see the official
[Ansible Community Code of Conduct](https://docs.ansible.com/ansible/latest/community/code_of_conduct.html).

================
File: tests/fixtures/collection/testorg/testcol/CONTRIBUTING
================
# Contributing

Refer to the [Ansible community guide](https://docs.ansible.com/ansible/devel/community/index.html).

================
File: tests/fixtures/collection/testorg/testcol/devfile.yaml
================
schemaVersion: 2.2.2
metadata:
  name: testorg.testcol
components:
  - name: tooling-container
    container:
      image: ghcr.io/ansible/ansible-devspaces:latest
      memoryRequest: 256M
      memoryLimit: 6Gi
      cpuRequest: 250m
      cpuLimit: 2000m
      args: ["tail", "-f", "/dev/null"]
      env:
        - name: KUBEDOCK_ENABLED
          value: "true"

================
File: tests/fixtures/collection/testorg/testcol/galaxy.yml
================
---
# This collection is initialized by https://github.com/ansible/ansible-creator 0.0.1

# See https://docs.ansible.com/ansible/latest/dev_guide/collections_galaxy_meta.html

namespace: "testorg"
name: "testcol"
version: 1.0.0
readme: README.md
authors:
  - your name <example@domain.com>

description: your collection description
license_file: LICENSE

# TO-DO: update the tags based on your content type
tags: ["linux", "tools"]

# TO-DO: maintain this list to reflect the collection's dependencies
dependencies:
  "ansible.utils": "*" # note: "*" selects the latest version available

repository: http://example.com/repository
documentation: http://docs.example.com
homepage: http://example.com
issues: http://example.com/issue/tracker

# A list of file glob-like patterns used to filter any files or directories that should not be included in the build
# artifact. A pattern is matched from the relative path of the file or directory of the collection directory. This
# uses 'fnmatch' to match the files or directories. Some directories and files like 'galaxy.yml', '*.pyc', '*.retry',
# and '.git' are always filtered. Mutually exclusive with 'manifest'
build_ignore:
  - .gitignore
  - changelogs/.plugin-cache.yaml
# A dict controlling use of manifest directives used in building the collection artifact. The key 'directives' is a
# list of MANIFEST.in style
# L(directives,https://packaging.python.org/en/latest/guides/using-manifest-in/#manifest-in-commands). The key
# 'omit_default_directives' is a boolean that controls whether the default directives are used. Mutually exclusive
# with 'build_ignore'
# manifest: null

================
File: tests/fixtures/collection/testorg/testcol/LICENSE
================
GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

  Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

  For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

  Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

  Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Use with the GNU Affero General Public License.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

    <program>  Copyright (C) <year>  <name of author>
    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an "about box".

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU GPL, see
<https://www.gnu.org/licenses/>.

  The GNU General Public License does not permit incorporating your program
into proprietary programs.  If your program is a subroutine library, you
may consider it more useful to permit linking proprietary applications with
the library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.  But first, please read
<https://www.gnu.org/licenses/why-not-lgpl.html>.

================
File: tests/fixtures/collection/testorg/testcol/pyproject.toml
================
[tool.black]
line-length = 100

[tool.pytest.ini_options]
addopts = ["-vvv", "-n", "2", "--log-level", "WARNING", "--color", "yes"]
filterwarnings = ['ignore:AnsibleCollectionFinder has already been configured']
testpaths = ["tests"]

================
File: tests/fixtures/collection/testorg/testcol/README.md
================
# Testorg Testcol Collection

This repository contains the `testorg.testcol` Ansible Collection.

<!--start requires_ansible-->
<!--end requires_ansible-->

## External requirements

Some modules and plugins require external libraries. Please check the
requirements for each plugin or module you use in the documentation to find out
which requirements are needed.

## Included content

<!--start collection content-->
<!--end collection content-->

## Using this collection

```bash
    ansible-galaxy collection install testorg.testcol
```

You can also include it in a `requirements.yml` file and install it via
`ansible-galaxy collection install -r requirements.yml` using the format:

```yaml
collections:
  - name: testorg.testcol
```

To upgrade the collection to the latest available version, run the following
command:

```bash
ansible-galaxy collection install testorg.testcol --upgrade
```

You can also install a specific version of the collection, for example, if you
need to downgrade when something is broken in the latest version (please report
an issue in this repository). Use the following syntax where `X.Y.Z` can be any
[available version](https://galaxy.ansible.com/testorg/testcol):

```bash
ansible-galaxy collection install testorg.testcol:==X.Y.Z
```

See
[Ansible Using Collections](https://docs.ansible.com/ansible/latest/user_guide/collections_using.html)
for more details.

## Release notes

See the
[changelog](https://github.com/ansible-collections/testorg.testcol/tree/main/CHANGELOG.rst).

## Roadmap

<!-- Optional. Include the roadmap for this collection, and the proposed release/versioning strategy so users can anticipate the upgrade/update cycle. -->

## More information

<!-- List out where the user can find additional information, such as working group meeting times, slack/matrix channels, or documentation for the product this collection automates. At a minimum, link to: -->

- [Ansible collection development forum](https://forum.ansible.com/c/project/collection-development/27)
- [Ansible User guide](https://docs.ansible.com/ansible/devel/user_guide/index.html)
- [Ansible Developer guide](https://docs.ansible.com/ansible/devel/dev_guide/index.html)
- [Ansible Collections Checklist](https://docs.ansible.com/ansible/devel/community/collection_contributors/collection_requirements.html)
- [Ansible Community code of conduct](https://docs.ansible.com/ansible/devel/community/code_of_conduct.html)
- [The Bullhorn (the Ansible Contributor newsletter)](https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn)
- [News for Maintainers](https://forum.ansible.com/tag/news-for-maintainers)

## Licensing

GNU General Public License v3.0 or later.

See [LICENSE](https://www.gnu.org/licenses/gpl-3.0.txt) to see the full text.

================
File: tests/fixtures/collection/testorg/testcol/requirements.txt
================
# TO-DO: add python packages that are required for this collection

================
File: tests/fixtures/collection/testorg/testcol/test-requirements.txt
================
# TO-DO: add python packages that are required for testing this collection
pytest-ansible
pytest-xdist
molecule

================
File: tests/fixtures/collection/testorg/testcol/tox-ansible.ini
================
[ansible]

skip =
    py3.7
    py3.8
    2.9
    2.10
    2.11
    2.12
    2.13

================
File: tests/fixtures/common/execution-environment/execution-environment.yml
================
---
version: 3

images:
  base_image:
    name: quay.io/fedora/fedora:41

dependencies:
  ansible_core:
    package_pip: ansible-core

  ansible_runner:
    package_pip: ansible-runner

  system:
    - openssh-clients
    - sshpass

  python:
    - requests
    - boto3

  galaxy:
    collections:
      - name: ansible.posix
      - name: ansible.utils

additional_build_steps:
  append_base:
    - RUN $PYCMD -m pip install -U pip

options:
  tags:
    - ansible_sample_ee

================
File: tests/fixtures/project/ee_project/.github/workflows/ci.yml
================
# Combine workflow for pull-request, push-to-main and release events.

name: Execution environment build

on:
  pull_request_target:
    branches:
      - main
    types: [opened, reopened, synchronize]
  push:
    branches:
      - main
  release:
    types: [published]

jobs:
  ee-build:
    uses: ansible/ansible-content-actions/.github/workflows/ee-build.yml@main
    with:
      registry: ghcr.io
    secrets:
      registry_username: ${{ github.actor }}
      registry_password: ${{ secrets.GITHUB_TOKEN }}
      # Only needed if base image of execution-environment.yml file is from Red Hat (ee-minimal)
      # registry_redhat_username: ${{ secrets.registry_redhat_username }}
      # registry_redhat_password: ${{ secrets.registry_redhat_password }}

================
File: tests/fixtures/project/ee_project/.gitignore
================
context/
.DS_Store

================
File: tests/fixtures/project/ee_project/execution-environment.yml
================
---
version: 3

images:
  base_image:
    name: quay.io/fedora/fedora:41

dependencies:
  # Use python3
  python_interpreter:
    package_system: python3
    python_path: /usr/bin/python3

  ansible_core:
    package_pip: ansible-core

  ansible_runner:
    package_pip: ansible-runner

  system:
    - openssh-clients
    - sshpass

  python:
    - ansible-navigator
    - boto3
    - requests

  galaxy:
    collections:
      - name: ansible.posix
      - name: ansible.utils

additional_build_steps:
  append_base:
    - RUN $PYCMD -m pip install -U pip

options:
  tags:
    - ansible_sample_ee

================
File: tests/fixtures/project/ee_project/README.md
================
# Execution Environment Project

### This is a sample execution environment project to build and publish your EE.

## Included content/ Directory Structure

The directory structure follows best practices recommended by the Ansible
community. Feel free to customize this template according to your specific
project requirements.

```
├── .github
│   └── workflows
│       └── ci.yml
├── .gitignore
├── README.md
└── execution-environment.yml
```

================
File: tests/fixtures/project/playbook_project/.devcontainer/docker/devcontainer.json
================
{
  "name": "ansible-dev-container-docker",
  "image": "ghcr.io/ansible/community-ansible-dev-tools:latest",
  "containerUser": "root",
  "runArgs": [
    "--security-opt",
    "seccomp=unconfined",
    "--security-opt",
    "label=disable",
    "--cap-add=SYS_ADMIN",
    "--cap-add=SYS_RESOURCE",
    "--device",
    "/dev/fuse",
    "--security-opt",
    "apparmor=unconfined",
    "--hostname=ansible-dev-container"
  ],
  "updateRemoteUserUID": true,
  "customizations": {
    "vscode": {
      "extensions": ["redhat.ansible", "redhat.vscode-redhat-account"]
    }
  }
}

================
File: tests/fixtures/project/playbook_project/.devcontainer/podman/devcontainer.json
================
{
  "name": "ansible-dev-container-podman",
  "image": "ghcr.io/ansible/community-ansible-dev-tools:latest",
  "containerUser": "root",
  "runArgs": [
    "--cap-add=CAP_MKNOD",
    "--cap-add=NET_ADMIN",
    "--cap-add=SYS_ADMIN",
    "--cap-add=SYS_RESOURCE",
    "--device",
    "/dev/fuse",
    "--security-opt",
    "seccomp=unconfined",
    "--security-opt",
    "label=disable",
    "--security-opt",
    "apparmor=unconfined",
    "--security-opt",
    "unmask=/sys/fs/cgroup",
    "--userns=host",
    "--hostname=ansible-dev-container"
  ],
  "customizations": {
    "vscode": {
      "extensions": ["redhat.ansible", "redhat.vscode-redhat-account"]
    }
  }
}

================
File: tests/fixtures/project/playbook_project/.devcontainer/devcontainer.json
================
{
  "name": "ansible-dev-container-codespaces",
  "image": "ghcr.io/ansible/community-ansible-dev-tools:latest",
  "containerUser": "root",
  "runArgs": [
    "--security-opt",
    "seccomp=unconfined",
    "--security-opt",
    "label=disable",
    "--cap-add=SYS_ADMIN",
    "--cap-add=SYS_RESOURCE",
    "--device",
    "/dev/fuse",
    "--security-opt",
    "apparmor=unconfined",
    "--hostname=ansible-dev-container"
  ],
  "updateRemoteUserUID": true,
  "customizations": {
    "vscode": {
      "extensions": ["redhat.ansible", "redhat.vscode-redhat-account"]
    }
  }
}

================
File: tests/fixtures/project/playbook_project/.github/workflows/tests.yml
================
---
name: "CI"

concurrency:
  group: ${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

on:  # yamllint disable-line rule:truthy
  pull_request:
    branches: [main]
  workflow_dispatch:
  # TO-DO: Below is an example cron scheduler. Uncomment and tweak it as per your requirement
  # schedule:
    # - cron: '0 0 * * *'

jobs:
  ansible-lint:
    uses: ansible/ansible-content-actions/.github/workflows/ansible_lint.yaml@main

================
File: tests/fixtures/project/playbook_project/.github/ansible-code-bot.yml
================
---
schedule:
  interval: "daily"

================
File: tests/fixtures/project/playbook_project/.vscode/extensions.json
================
{
  "recommendations": ["redhat.ansible", "redhat.vscode-redhat-account"]
}

================
File: tests/fixtures/project/playbook_project/collections/ansible_collections/weather/demo/meta/runtime.yml
================
---
requires_ansible: ">=2.17.0"

================
File: tests/fixtures/project/playbook_project/collections/ansible_collections/weather/demo/roles/run/tasks/main.yml
================
---
- name: Debug print task-1
  ansible.builtin.debug:
    msg: "This is task-1"

- name: Debug print task-2
  ansible.builtin.debug:
    msg: "This is task-2"

- name: Debug print task-3
  ansible.builtin.debug:
    msg: "This is task-3"

================
File: tests/fixtures/project/playbook_project/collections/ansible_collections/weather/demo/roles/run/README.md
================
Weather.Demo Run Role
========================

A brief description of the role is here.

Requirements
------------

Any prerequisites that may not be covered by Ansible itself or the role should be mentioned here. For instance, if the role uses the EC2 module, it may be a good idea to mention in this section that the boto package is required.

Role Variables
--------------

A description of the settable variables for this role should go here, including any variables that are in defaults/main.yml, vars/main.yml, and any variables that can/should be set via parameters to the role. Any variables that are read from other roles and/or the global scope (ie. host vars, group vars, etc.) should be mentioned here as well.

Dependencies
------------

A list of other roles hosted on Galaxy should go here, plus any details in regards to parameters that may need to be set for other roles, or variables that are used from other roles.

Example Playbook
----------------

Including an example of how to use your role (for instance, with variables passed in as parameters) is always nice for users too:

```yaml
- name: Execute tasks on servers
  hosts: servers
  roles:
    - role: weather.demo.run
      run_x: 42
```

Another way to consume this role would be:

```yaml
- name: Initialize the run role from weather.demo
  hosts: servers
  gather_facts: false
  tasks:
    - name: Trigger invocation of run role
      ansible.builtin.include_role:
        name: weather.demo.run
      vars:
        run_x: 42
```

License
-------

# TO-DO: Update the license to the one you want to use (delete this line after setting the license)
BSD

Author Information
------------------

An optional section for the role authors to include contact information, or a website (HTML is not allowed).

================
File: tests/fixtures/project/playbook_project/collections/ansible_collections/weather/demo/galaxy.yml
================
---
# Minimal galaxy.yml for a playbook project for tools to recognize this as a collection

namespace: "weather"
name: "demo"
readme: README.md
version: 0.0.1
authors:
  - your name <example@domain.com>

description: Collection for weather.demo playbook project

# TO-DO: update the tags based on your content type
tags: ["tools"]

repository: NA

================
File: tests/fixtures/project/playbook_project/collections/ansible_collections/weather/demo/README.md
================
# Weather Demo Collection

This repository contains the `weather.demo` Ansible Collection.

## Tested with Ansible

Tested with ansible-core >=2.14 releases and the current development version of
ansible-core.

## External requirements

Some modules and plugins require external libraries. Please check the
requirements for each plugin or module you use in the documentation to find out
which requirements are needed.

## Included content

Please check the included content on the
[Ansible Galaxy page for this collection](https://galaxy.ansible.com/weather/demo).

## Using this collection

```
    ansible-galaxy collection install weather.demo
```

You can also include it in a `requirements.yml` file and install it via
`ansible-galaxy collection install -r requirements.yml` using the format:

```yaml
collections:
  - name: weather.demo
```

To upgrade the collection to the latest available version, run the following
command:

```bash
ansible-galaxy collection install weather.demo --upgrade
```

You can also install a specific version of the collection, for example, if you
need to downgrade when something is broken in the latest version (please report
an issue in this repository). Use the following syntax where `X.Y.Z` can be any
[available version](https://galaxy.ansible.com/weather/demo):

```bash
ansible-galaxy collection install weather.demo:==X.Y.Z
```

See
[Ansible Using Collections](https://docs.ansible.com/ansible/latest/user_guide/collections_using.html)
for more details.

## Release notes

See the
[changelog](https://github.com/ansible-collections/weather.demo/tree/main/CHANGELOG.rst).

## Roadmap

<!-- Optional. Include the roadmap for this collection, and the proposed release/versioning strategy so users can anticipate the upgrade/update cycle. -->

## More information

<!-- List out where the user can find additional information, such as working group meeting times, slack/Matrix channels, or documentation for the product this collection automates. At a minimum, link to: -->

- [Ansible collection development forum](https://forum.ansible.com/c/project/collection-development/27)
- [Ansible User guide](https://docs.ansible.com/ansible/devel/user_guide/index.html)
- [Ansible Developer guide](https://docs.ansible.com/ansible/devel/dev_guide/index.html)
- [Ansible Collections Checklist](https://docs.ansible.com/ansible/devel/community/collection_contributors/collection_requirements.html)
- [Ansible Community code of conduct](https://docs.ansible.com/ansible/devel/community/code_of_conduct.html)
- [The Bullhorn (the Ansible Contributor newsletter)](https://docs.ansible.com/ansible/devel/community/communication.html#the-bullhorn)
- [News for Maintainers](https://forum.ansible.com/tag/news-for-maintainers)

## Licensing

GNU General Public License v3.0 or later.

See [LICENSE](https://www.gnu.org/licenses/gpl-3.0.txt) to see the full text.

================
File: tests/fixtures/project/playbook_project/collections/requirements.yml
================
---
collections:
  - name: ansible.posix
    version: 1.4.0

  - name: ansible.scm
    version: 2.0.0

  - name: ansible.utils
    version: 4.0.0

  - name: cisco.ios

  - name: https://github.com/redhat-cop/network.backup
    type: git

  # TO-DO: User's own collections can also be specified as mention below.
  # - name: my_organization.my_collection
  #   version: 1.2.3
  #   source: https://github.com/my_organization/my_collection.git

================
File: tests/fixtures/project/playbook_project/inventory/group_vars/all.yml
================
---
ansible_user: your_username
ansible_ssh_private_key_file: /path/to/your/private/key

================
File: tests/fixtures/project/playbook_project/inventory/group_vars/db_servers.yml
================
---
http_port: 80
app_version: "1.0.0"

================
File: tests/fixtures/project/playbook_project/inventory/group_vars/production.yml
================
---
http_port: 80
app_version: "1.0.0"

================
File: tests/fixtures/project/playbook_project/inventory/group_vars/test.yml
================
---
http_port: 80
app_version: "1.0.0"

================
File: tests/fixtures/project/playbook_project/inventory/group_vars/web_servers.yml
================
---
http_port: 80
app_version: "1.0.0"

================
File: tests/fixtures/project/playbook_project/inventory/host_vars/server1.yml
================
---
server_name: webserver1

================
File: tests/fixtures/project/playbook_project/inventory/host_vars/server2.yml
================
---
server_name: webserver2

================
File: tests/fixtures/project/playbook_project/inventory/host_vars/server3.yml
================
---
server_name: webserver3

================
File: tests/fixtures/project/playbook_project/inventory/host_vars/switch1.yml
================
---
ansible_network_os: cisco.ios.ios
ansible_connection: ansible.netcommon.network_cli
ansible_become: true

================
File: tests/fixtures/project/playbook_project/inventory/host_vars/switch2.yml
================
---
ansible_network_os: cisco.nxos.nxos
ansible_connection: ansible.netcommon.httpapi
ansible_httpapi_port: 80

================
File: tests/fixtures/project/playbook_project/inventory/argspec_validation_inventory.yml
================
---
all:
  vars:
    ping_data: Pong
    stat:
      description: Custom stat data
      returned: always
      type: raw
      sample: Hello, World!

================
File: tests/fixtures/project/playbook_project/inventory/hosts.yml
================
---
all:
  hosts:
    server1:
      ansible_host: 192.168.1.101
    server2:
      ansible_host: 192.168.1.102
    switch1:
      ansible_host: 192.168.1.106
    switch2:
      ansible_host: 192.168.1.107
  children:
    web_servers:
      hosts:
        server1:
        server2:
    db_servers:
      hosts:
        server3:
          ansible_host: 192.168.1.103
    switches:
      hosts:
        switch1:
        switch2:
    production:
      hosts:
        server1:
          ansible_host: 192.168.1.101
        server2:
          ansible_host: 192.168.1.102
    test:
      hosts:
        server3:
          ansible_host: 192.168.1.103

================
File: tests/fixtures/project/playbook_project/.gitignore
================
.logs/*
*.retry
*.vault
collections/*
!collections/ansible_collections
!collections/requirements.yml
collections/ansible_collections/*
!collections/ansible_collections/weather
collections/ansible_collections/weather/*
!collections/ansible_collections/weather/demo
# https://raw.githubusercontent.com/github/gitignore/main/Python.gitignore
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# MacOS
.DS_Store

# Ansible
.ansible/

================
File: tests/fixtures/project/playbook_project/ansible-navigator.yml
================
---
ansible-navigator:
  logging:
    level: debug
    append: false
    file: $PWD/.logs/ansible-navigator.log

  playbook-artifact:
    enable: true
    save-as: "$PWD/.logs/{playbook_name}-artifact-{time_stamp}.json"

================
File: tests/fixtures/project/playbook_project/ansible.cfg
================
[defaults]
# Specify the inventory file
inventory = inventory/hosts.yml

# Define the directory for host and group variables
host_vars_inventory = inventory/host_vars
group_vars_inventory = inventory/group_vars

# Set the logging verbosity level
verbosity = 2

# Set the default user for SSH connections
remote_user = myuser

# Define the default become method
become_method = sudo

[persistent_connection]
# Controls how long the persistent connection will remain idle before it is destroyed
connect_timeout=30

# Controls the amount of time to wait for response from remote device before timing out persistent connection
command_timeout=30

================
File: tests/fixtures/project/playbook_project/argspec_validation_plays.meta.yml
================
# Example play argspec file
---
short_description: A shorter summary of `description` below
description: This is a description of a playbook, that may contain multiple plays with multiple play argument specs
argument_specs:
  debug_localhost:
    short_description: Play for printing a debug message
    description:
      - Example play within a collection containing an argspec for printing a debug message
    author:
      - developer (@developer)
    options:
      message:
        description: Debug message to print
        type: str
        required: true
    examples: |
      - import_playbook: argspec_validation_plays.yml
        vars:
          message: 'Custom debug message'
    return: ~
  ping_localhost:
    short_description: Play for pinging localhost with custom data
    description:
      - Example play within a collection containing an argspec for pinging localhost with custom data
    author:
      - developer (@developer)
    options:
      ping_data:
        description: Ping data
        type: str
        required: true
    examples: |
      - import_playbook: argspec_validation_plays.yml
        vars:
          data: Pong
    return: ~
  set_stats:
    short_description: Play for setting a custom stat
    description:
      - Example play within a collection containing an argspec for setting a custom stat
    author:
      - developer (@developer)
    options:
      stat:
        description: Stat data
        type: raw
        required: true
    notes:
      - This play has some notes
      - They specify additional information
    examples: |
      - import_playbook: argspec_validation_plays.yml
        vars:
          stat: This is some custom stat
    return:
      stat:
        description: Custom stat data
        returned: always
        type: raw
        sample: Hello, World!

================
File: tests/fixtures/project/playbook_project/argspec_validation_plays.yml
================
# Example playbook using play argspec validation
# Run with:
# ansible-playbook argspec_validation_plays.yml -e message=hello -i inventory/argspec_validation_inventory.yml
---
- name: Debug_localhost
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Verify with argspec
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs'][lowercase_play_name]['options'] }}"
      vars:
        lowercase_play_name: "{{ ansible_play_name | lower }}"
        filename: "argspec_validation_plays.meta.yml"
    - name: Print debug message
      ansible.builtin.debug:
        msg: "{{ message }}"

- name: Ping_localhost
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Verify with argspec
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs'][lowercase_play_name]['options'] }}"
      vars:
        lowercase_play_name: "{{ ansible_play_name | lower }}"
        filename: "argspec_validation_plays.meta.yml"
    - name: Print debug message
      ansible.builtin.ping:
        data: "{{ ping_data }}"

- name: Set_stats
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Verify with argspec
      ansible.builtin.validate_argument_spec:
        argument_spec: "{{ (lookup('ansible.builtin.file', filename) | from_yaml)['argument_specs'][lowercase_play_name]['options'] }}"
      vars:
        lowercase_play_name: "{{ ansible_play_name | lower }}"
        filename: "argspec_validation_plays.meta.yml"
    - name: Set custom stats
      ansible.builtin.set_stats:
        data: "{{ stat }}"

================
File: tests/fixtures/project/playbook_project/devfile.yaml
================
schemaVersion: 2.2.2
metadata:
  name: weather.demo
components:
  - name: tooling-container
    container:
      image: ghcr.io/ansible/ansible-devspaces:latest
      memoryRequest: 256M
      memoryLimit: 6Gi
      cpuRequest: 250m
      cpuLimit: 2000m
      args: ["tail", "-f", "/dev/null"]
      env:
        - name: KUBEDOCK_ENABLED
          value: "true"

================
File: tests/fixtures/project/playbook_project/linux_playbook.yml
================
---
- name: Update web servers
  hosts: webservers
  become: true

  tasks:
    - name: Ensure apache is at the present version
      ansible.builtin.dnf:
        name: httpd
        state: present

    - name: Write the apache config file
      ansible.builtin.template:
        src: /srv/httpd.j2
        dest: /etc/httpd.conf
        mode: "0644"

- name: Update db servers
  hosts: databases
  become: true

  tasks:
    - name: Ensure postgresql is at the present version
      ansible.builtin.dnf:
        name: postgresql
        state: present

    - name: Ensure that postgresql is started
      ansible.builtin.service:
        name: postgresql
        state: started

================
File: tests/fixtures/project/playbook_project/network_playbook.yml
================
---
- name: Network Getting Started First Playbook Extended
  gather_facts: false
  hosts: switch1
  tasks:
    - name: Get config for IOS devices
      cisco.ios.ios_facts:
        gather_subset: all

    - name: Display the config
      ansible.builtin.debug:
        msg: "The hostname is {{ ansible_net_hostname }} and the OS is {{ ansible_net_version }}"

    - name: Update the hostname
      cisco.ios.ios_config:
        lines:
          - hostname ios-changed

    - name: Get changed config for IOS devices
      cisco.ios.ios_facts:
        gather_subset: all

    - name: Display the changed config
      ansible.builtin.debug:
        msg: "The new hostname is {{ ansible_net_hostname }} and the OS is {{ ansible_net_version }}"

================
File: tests/fixtures/project/playbook_project/README.md
================
# Weather Demo Ansible Project

## Included content/ Directory Structure

The directory structure follows best practices recommended by the Ansible
community. Feel free to customize this template according to your specific
project requirements.

```
 ansible-project/
 |── .devcontainer/
 |    └── docker/
 |        └── devcontainer.json
 |    └── podman/
 |        └── devcontainer.json
 |    └── devcontainer.json
 |── .github/
 |    └── workflows/
 |        └── tests.yml
 |    └── ansible-code-bot.yml
 |── .vscode/
 |    └── extensions.json
 |── collections/
 |   └── requirements.yml
 |   └── ansible_collections/
 |       └── project_org/
 |           └── project_repo/
 |               └── README.md
 |               └── roles/sample_role/
 |                         └── README.md
 |                         └── tasks/main.yml
 |── inventory/
 |   |── hosts.yml
 |   |── argspec_validation_inventory.yml
 |   └── groups_vars/
 |   └── host_vars/
 |── ansible-navigator.yml
 |── ansible.cfg
 |── devfile.yaml
 |── linux_playbook.yml
 |── network_playbook.yml
 |── README.md
 |── site.yml
```

## Compatible with Ansible-lint

Tested with ansible-lint >=24.2.0 releases and the current development version
of ansible-core.

================
File: tests/fixtures/project/playbook_project/site.yml
================
---
- name: Example playbook
  hosts: localhost
  roles:
    - role: weather.demo.run

================
File: tests/integration/__init__.py
================
"""Integration tests."""

================
File: tests/integration/test_init.py
================
"""Unit tests for ansible-creator init."""

from __future__ import annotations

import re
import sys

from pathlib import Path
from typing import TYPE_CHECKING

import pytest


if TYPE_CHECKING:
    from tests.conftest import CliRunCallable


CREATOR_BIN = Path(sys.executable).parent / "ansible-creator"


def test_run_help(cli: CliRunCallable) -> None:
    """Test running ansible-creator --help.

    Args:
        cli: cli_run function.

    Raises:
        AssertionError: If the assertion fails.
    """
    # Get the path to the current python interpreter
    result = cli(f"{CREATOR_BIN} --help")
    assert result.returncode == 0, (result.stdout, result.stderr)

    assert "The fastest way to generate all your ansible content." in result.stdout
    assert "Positional arguments:" in result.stdout
    assert "add" in result.stdout
    assert "Add resources to an existing Ansible project." in result.stdout
    assert "init" in result.stdout
    assert "Initialize a new Ansible project." in result.stdout


def test_run_no_subcommand(cli: CliRunCallable) -> None:
    """Test running ansible-creator without subcommand.

    Args:
        cli: cli_run function.

    Raises:
        AssertionError: If the assertion fails.
    """
    result = cli(str(CREATOR_BIN))
    assert result.returncode != 0
    assert "the following arguments are required: command" in result.stderr


def test_run_init_no_input(cli: CliRunCallable) -> None:
    """Test running ansible-creator init without any input.

    Args:
        cli: cli_run function.

    Raises:
        AssertionError: If the assertion fails.
    """
    result = cli(f"{CREATOR_BIN} init")
    assert result.returncode != 0
    err = "the following arguments are required: project-type"
    assert err in result.stderr


@pytest.mark.parametrize(
    argnames="command",
    argvalues=("init --project ansible-project", "init --init-path /tmp"),
    ids=["project_no_scm", "collection_no_name"],
)
def test_run_deprecated_failure(command: str, cli: CliRunCallable) -> None:
    """Test running ansible-creator init with deprecated options.

    Args:
        command: Command to run.
        cli: cli_run function.

    Raises:
        AssertionError: If the assertion fails.
    """
    result = cli(f"{CREATOR_BIN} {command}")
    assert result.returncode != 0
    assert "is no longer needed and will be removed." in result.stdout
    assert "The CLI has changed." in result.stderr


@pytest.mark.parametrize(
    argnames=("args", "expected"),
    argvalues=(
        ("a.b", "must be longer than 2 characters."),
        ("_a.b", "cannot begin with an underscore."),
        ("foo", "must be in the format '<namespace>.<name>'."),
    ),
    ids=("short", "underscore", "no_dot"),
)
@pytest.mark.parametrize("command", ("collection", "playbook"))
def test_run_init_invalid_name(command: str, args: str, expected: str, cli: CliRunCallable) -> None:
    """Test running ansible-creator init with invalid collection name.

    Args:
        command: Command to run.
        args: Arguments to pass to the CLI.
        expected: Expected error message.
        cli: cli_run function.

    Raises:
        AssertionError: If the assertion fails.
    """
    result = cli(f"{CREATOR_BIN} init {command} {args}")
    assert result.returncode != 0
    assert result.stderr.startswith("Critical:")
    assert expected in result.stderr


def test_run_init_basic(cli: CliRunCallable, tmp_path: Path) -> None:
    """Test running ansible-creator init with empty/non-empty/force.

    Args:
        cli: cli_run function.
        tmp_path: Temporary path.

    Raises:
        AssertionError: If the assertion fails.
    """
    final_dest = f"{tmp_path}/collections/ansible_collections"
    cli(f"mkdir -p {final_dest}")

    result = cli(
        f"{CREATOR_BIN} init testorg.testcol --init-path {final_dest}",
    )
    assert result.returncode == 0

    # check stdout
    assert re.search(r"Note: collection project created at", result.stdout) is not None

    # fail to override existing collection with force=false (default)
    result = cli(
        f"{CREATOR_BIN} init testorg.testcol --init-path {final_dest}",
    )

    assert result.returncode != 0

    # override existing collection with force=true
    result = cli(f"{CREATOR_BIN} init testorg.testcol --init-path {tmp_path} --force")
    assert result.returncode == 0
    assert re.search(r"Warning: re-initializing existing directory", result.stdout) is not None

    # override existing collection with override=true
    result = cli(f"{CREATOR_BIN} init testorg.testcol --init-path {tmp_path} --overwrite")
    assert result.returncode == 0
    assert re.search(f"Note: collection project created at {tmp_path}", result.stdout) is not None

    # use no-override=true
    result = cli(f"{CREATOR_BIN} init testorg.testcol --init-path {tmp_path} --no-overwrite")
    assert result.returncode != 0
    assert re.search(r"The flag `--no-overwrite` restricts overwriting.", result.stderr) is not None


def test_run_init_ee(cli: CliRunCallable, tmp_path: Path) -> None:
    """Test running ansible-creator init for ee_project.

    Args:
        cli: cli_run function.
        tmp_path: Temporary path.

    Raises:
        AssertionError: If the assertion fails.
    """
    final_dest = f"{tmp_path}/ee_project"
    cli(f"mkdir -p {final_dest}")

    result = cli(
        f"{CREATOR_BIN} init execution_env {final_dest}",
    )
    assert result.returncode == 0

    # check stdout
    assert re.search(r"Note: execution_env project created at", result.stdout) is not None

================
File: tests/integration/test_lint.py
================
"""Check fixture content integration with ansible-lint.

The fixture content is compared to the output of ansible-creator in the
test_run_success_for_collection and test_run_success_ansible_project
tests.
"""

from __future__ import annotations

import re
import sys

from pathlib import Path
from typing import TYPE_CHECKING

from tests.defaults import FIXTURES_DIR


if TYPE_CHECKING:
    import pytest

    from tests.conftest import CliRunCallable

GALAXY_BIN = Path(sys.executable).parent / "ansible-galaxy"
LINT_BIN = Path(sys.executable).parent / "ansible-lint"

LINT_RE = re.compile(
    r"Passed: (?P<failures>\d+) failure\(s\),"
    r" (?P<warnings>\d+) warning\(s\) on (?P<files>\d+) files.",
)
LINT_PROFILE_RE = re.compile(
    r"Last profile that met the validation criteria was '(?P<profile>\w+)'.",
)


def test_lint_collection(
    cli: CliRunCallable,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Lint the scaffolded collection with ansible-lint.

    Args:
        cli: CLI callable.
        monkeypatch: Monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    project_path = FIXTURES_DIR / "collection"
    monkeypatch.chdir(project_path)

    args = str(LINT_BIN)
    env = {"NO_COLOR": "1"}
    result = cli(args=args, env=env)

    assert result.returncode == 0

    match = LINT_RE.search(result.stderr)
    assert match is not None
    assert int(match.group("failures")) == 0
    assert int(match.group("warnings")) == 0
    assert int(match.group("files")) > 0

    match = LINT_PROFILE_RE.search(result.stderr)
    assert match is not None
    assert match.group("profile") == "production"


def test_lint_playbook_project(
    tmp_path: Path,
    cli: CliRunCallable,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Lint the scaffolded playbook project with ansible-lint.

    This is an expensive test as it installs collections from the requirements.yml file.
    If it becomes necessary again, consider using a session fixture to install the collections.

    Args:
        tmp_path: Temporary path.
        cli: CLI callable.
        monkeypatch: Monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    req_path = str(
        FIXTURES_DIR / "project" / "playbook_project" / "collections" / "requirements.yml",
    )
    dest_path = tmp_path / "collections"
    galaxy_cmd = f"{GALAXY_BIN} collection install -r {req_path} -p {dest_path}"
    result = cli(args=galaxy_cmd)
    assert result.returncode == 0

    project_path = FIXTURES_DIR / "project" / "playbook_project"
    monkeypatch.chdir(project_path)
    args = str(LINT_BIN)
    env = {"NO_COLOR": "1", "ANSIBLE_COLLECTIONS_PATH": str(dest_path)}
    result = cli(args=args, env=env)

    assert result.returncode == 0

    match = LINT_RE.search(result.stderr)
    assert match is not None
    assert int(match.group("failures")) == 0
    assert int(match.group("warnings")) == 0
    assert int(match.group("files")) > 0

    match = LINT_PROFILE_RE.search(result.stderr)
    assert match is not None
    assert match.group("profile") == "production"

================
File: tests/units/__init__.py
================
"""Unit tests for ansible-creator."""

================
File: tests/units/test_add.py
================
# cspell: ignore dcmp, subdcmp
# ruff: noqa: ERA001
# pylint: disable=C0302
"""Unit tests for ansible-creator add."""

from __future__ import annotations

import json
import shutil
import subprocess
import sys

from filecmp import cmp, dircmp
from typing import TYPE_CHECKING, Any, TypedDict

import pytest
import yaml

from ansible_creator.config import Config
from ansible_creator.exceptions import CreatorError


if TYPE_CHECKING:
    from pathlib import Path

    from ansible_creator.output import Output

from ansible_creator.subcommands.add import Add
from tests.defaults import FIXTURES_DIR


class ConfigDict(TypedDict):
    """Type hint for Config dictionary.

    Attributes:
        creator_version: The version of the creator.
        output: The output object to use for logging.
        subcommand: The subcommand to execute.
        resource_type: The type of resource to be scaffolded.
        plugin_type: The type of the plugin to be scaffolded.
        plugin_name: The name of the plugin to be scaffolded.
        type: The type of the project for which the resource is being scaffolded.
        path: The file path where the resource should be added.
        force: Force overwrite of existing directory.
        overwrite: To overwrite files in an existing directory.
        no_overwrite: To not overwrite files in an existing directory.
        image: The image to be used while scaffolding devcontainer.
        role_name: The name of role to be used while scaffolding.
    """

    creator_version: str
    output: Output
    subcommand: str
    resource_type: str
    plugin_type: str
    plugin_name: str
    type: str
    path: str
    force: bool
    overwrite: bool
    no_overwrite: bool
    image: str
    role_name: str


@pytest.fixture(name="cli_args")
def fixture_cli_args(tmp_path: Path, output: Output) -> ConfigDict:
    """Create a dict to use for a Add class object as fixture.

    Args:
        tmp_path: Temporary directory path.
        output: Output class object.

    Returns:
        dict: Dictionary, partial Add class object.
    """
    return {
        "creator_version": "0.0.1",
        "output": output,
        "subcommand": "add",
        "type": "resource",
        "resource_type": "",
        "plugin_type": "",
        "plugin_name": "hello_world",
        "path": str(tmp_path),
        "force": False,
        "overwrite": False,
        "no_overwrite": False,
        "image": "",
        "role_name": "",
    }


def has_differences(dcmp: dircmp[str], errors: list[str]) -> list[str]:
    """Recursively check for differences in dircmp object.

    Args:
        dcmp: dircmp object.
        errors: List of errors.

    Returns:
        list: List of errors.
    """
    errors.extend([f"Only in {dcmp.left}: {f}" for f in dcmp.left_only])
    errors.extend([f"Only in {dcmp.right}: {f}" for f in dcmp.right_only])
    errors.extend(
        [f"Differing files: {dcmp.left}/{f} {dcmp.right}/{f}" for f in dcmp.diff_files],
    )
    for subdcmp in dcmp.subdirs.values():
        errors = has_differences(subdcmp, errors)
    return errors


def test_run_success_add_devfile(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Add.run().

    Successfully add devfile to path

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["resource_type"] = "devfile"
    add = Add(
        Config(**cli_args),
    )

    # Mock the "unique_name_in_devfile" method
    def mock_unique_name_in_devfile() -> str:
        """Mock function to generate a unique name for use in a devfile.

        Returns:
            str: A placeholder name, "testorg".
        """
        return "testorg.testcol"

    with pytest.MonkeyPatch.context() as mp:
        # Apply the mock
        mp.setattr(
            Add,
            "unique_name_in_devfile",
            staticmethod(mock_unique_name_in_devfile),
        )
        add.run()
    result = capsys.readouterr().out
    assert "Note: Resource added to" in result

    expected_devfile = tmp_path / "devfile.yaml"
    effective_devfile = FIXTURES_DIR / "collection" / "testorg" / "testcol" / "devfile.yaml"
    cmp_result = cmp(expected_devfile, effective_devfile, shallow=False)
    assert cmp_result

    conflict_file = tmp_path / "devfile.yaml"
    conflict_file.write_text("schemaVersion: 2.2.2")

    # expect a CreatorError when the response to overwrite is no.
    monkeypatch.setattr("builtins.input", lambda _: "n")
    fail_msg = (
        "The destination directory contains files that will be overwritten."
        " Please re-run ansible-creator with --overwrite to continue."
    )
    with pytest.raises(
        CreatorError,
        match=fail_msg,
    ):
        add.run()

    # expect a warning followed by devfile resource creation msg
    # when response to overwrite is yes.
    monkeypatch.setattr("builtins.input", lambda _: "y")
    add.run()
    result = capsys.readouterr().out
    assert "already exists" in result, result
    assert "Note: Resource added to" in result


def test_run_error_no_overwrite(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
) -> None:
    """Test Add.run().

    Successfully add devfile to path

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["resource_type"] = "devfile"
    add = Add(
        Config(**cli_args),
    )

    # Mock the "unique_name_in_devfile" method
    def mock_unique_name_in_devfile() -> str:
        """Mock function to generate a unique name for use in a devfile.

        Returns:
            str: A placeholder name, "testorg".
        """
        return "testorg.testcol"

    with pytest.MonkeyPatch.context() as mp:
        # Apply the mock
        mp.setattr(
            Add,
            "unique_name_in_devfile",
            staticmethod(mock_unique_name_in_devfile),
        )
        add.run()
    result = capsys.readouterr().out
    assert "Note: Resource added to" in result

    expected_devfile = tmp_path / "devfile.yaml"
    effective_devfile = FIXTURES_DIR / "collection" / "testorg" / "testcol" / "devfile.yaml"
    cmp_result = cmp(expected_devfile, effective_devfile, shallow=False)
    assert cmp_result

    conflict_file = tmp_path / "devfile.yaml"
    conflict_file.write_text("schemaVersion: 2.2.2")

    cli_args["no_overwrite"] = True
    add = Add(
        Config(**cli_args),
    )
    with pytest.raises(CreatorError) as exc_info:
        add.run()
    assert "Please re-run ansible-creator with --overwrite to continue." in str(exc_info.value)


def test_error_invalid_path(
    cli_args: ConfigDict,
) -> None:
    """Test Add.run().

    Successfully add devfile to path

    Args:
        cli_args: Dictionary, partial Add class object.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["resource_type"] = "devfile"
    cli_args["path"] = "/invalid"
    add = Add(
        Config(**cli_args),
    )

    with pytest.raises(CreatorError) as exc_info:
        add.run()
    assert "does not exist. Please provide an existing directory" in str(exc_info.value)


@pytest.mark.parametrize("skip_collection_check", (False, True))
def test_error_invalid_collection_path(
    capsys: pytest.CaptureFixture[str], cli_args: ConfigDict, *, skip_collection_check: bool
) -> None:
    """Test Add.run().

    Check if collection exists.

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        cli_args: Dictionary, partial Add class object.
        skip_collection_check: Whether to check for a valid collection.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["plugin_type"] = "lookup"
    add = Add(
        Config(**cli_args),
        skip_collection_check=skip_collection_check,
    )

    if skip_collection_check:
        add.run()
        result = capsys.readouterr().out
        assert "Note: Lookup plugin added to" in result
    else:
        with pytest.raises(CreatorError) as exc_info:
            add.run()
        assert (
            "is not a valid Ansible collection path. "
            "Please provide the root path of a valid ansible collection."
        ) in str(
            exc_info.value,
        )


def test_run_error_unsupported_resource_type(
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Add.run() with an unsupported resource type.

    This test checks if the CreatorError is raised when an unsupported
    resource type is provided.

    Args:
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["resource_type"] = "devfile"
    add = Add(
        Config(**cli_args),
    )
    # Mock the _resource_type to bypass the validation step
    monkeypatch.setattr(add, "_resource_type", "unsupported_type")

    # Expect a CreatorError with the appropriate message
    with pytest.raises(CreatorError) as exc_info:
        add.run()
    assert "Unsupported resource type: unsupported_type" in str(exc_info.value)


def test_run_success_add_devcontainer(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Add.run() for adding a devcontainer.

    Successfully adds devcontainer to path.

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    # Set the resource_type to devcontainer
    cli_args["resource_type"] = "devcontainer"
    cli_args["image"] = "auto"
    add = Add(
        Config(**cli_args),
    )
    add.run()
    result = capsys.readouterr().out
    assert "Note: Resource added to" in result

    # Verify the generated devcontainer files match the expected structure
    expected_devcontainer = tmp_path / ".devcontainer"
    effective_devcontainer = FIXTURES_DIR / "collection" / "testorg" / "testcol" / ".devcontainer"

    cmp_result = dircmp(expected_devcontainer, effective_devcontainer)
    diff = has_differences(dcmp=cmp_result, errors=[])
    assert diff == [], diff

    # Test for overwrite prompt and failure with no overwrite option
    conflict_file = tmp_path / ".devcontainer" / "devcontainer.json"
    conflict_file.write_text('{ "name": "conflict" }')

    # expect a CreatorError when the response to overwrite is no.
    monkeypatch.setattr("builtins.input", lambda _: "n")
    fail_msg = (
        "The destination directory contains files that will be overwritten."
        " Please re-run ansible-creator with --overwrite to continue."
    )
    with pytest.raises(
        CreatorError,
        match=fail_msg,
    ):
        add.run()

    # expect a warning followed by devcontainer resource creation msg
    # when response to overwrite is yes.
    monkeypatch.setattr("builtins.input", lambda _: "y")
    add.run()
    result = capsys.readouterr().out
    assert "already exists" in result, result
    assert "Note: Resource added to" in result


# Skip this test on macOS due to unavailability of docker on macOS GHA runners
@pytest.mark.skipif(sys.platform == "darwin", reason="Skip test on macOS")
def test_devcontainer_usability(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
) -> None:
    """Test Add.run() for adding a devcontainer.

    Successfully adds devcontainer to path.

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.

    Raises:
        AssertionError: If the assertion fails.
        FileNotFoundError: If the 'npm' or 'docker' executable is not found in the PATH.
    """
    # Set the resource_type to devcontainer
    cli_args["resource_type"] = "devcontainer"
    cli_args["image"] = "auto"
    add = Add(
        Config(**cli_args),
    )
    add.run()
    result = capsys.readouterr().out
    assert "Note: Resource added to" in result

    npm_executable = shutil.which("npm")
    if not npm_executable:
        err = "npm executable not found in PATH"
        raise FileNotFoundError(err)

    # Start the devcontainer using devcontainer CLI
    devcontainer_up_cmd = (
        f"devcontainer up --workspace-folder {tmp_path} --remove-existing-container"
    )
    devcontainer_up_output = subprocess.run(  # noqa: S603
        [
            npm_executable,
            "exec",
            "-c",
            devcontainer_up_cmd,
        ],
        capture_output=True,
        text=True,
        check=True,
    )
    assert devcontainer_up_output.returncode == 0

    devcontainer_id = json.loads(devcontainer_up_output.stdout.strip("\n")).get("containerId")

    # Execute the command within the container
    devcontainer_exec_cmd = f"devcontainer exec --container-id {devcontainer_id} adt --version"
    devcontainer_exec_output = subprocess.run(  # noqa: S603
        [npm_executable, "exec", "-c", devcontainer_exec_cmd],
        capture_output=True,
        text=True,
        check=True,
    )
    assert devcontainer_exec_output.returncode == 0

    docker_executable = shutil.which("docker")
    if not docker_executable:
        err = "docker executable not found in PATH"
        raise FileNotFoundError(err)
    # Stop devcontainer
    stop_container = subprocess.run(  # noqa: S603
        [docker_executable, "rm", "-f", devcontainer_id],
        capture_output=True,
        text=True,
        check=True,
    )
    assert stop_container.returncode == 0


@pytest.mark.parametrize(
    ("plugin_type", "plugin_name", "expected_message", "expected_file_path"),
    (
        (
            "action",
            "sample_action",
            "Note: Action plugin added to",
            "plugins/action/sample_action.py",
        ),
        (
            "filter",
            "sample_filter",
            "Note: Filter plugin added to",
            "plugins/filter/sample_filter.py",
        ),
        (
            "lookup",
            "sample_lookup",
            "Note: Lookup plugin added to",
            "plugins/lookup/sample_lookup.py",
        ),
        # (
        #     "module",
        #     "sample_module",
        #     "Note: Module plugin added to",
        #     "plugins/modules/sample_module.py",
        # ),
        (
            "test",
            "sample_test",
            "Note: Test plugin added to",
            "plugins/test/sample_test.py",
        ),
    ),
)
def test_run_success_add_plugin(  # noqa: PLR0913, # pylint: disable=too-many-positional-arguments
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
    plugin_type: str,
    plugin_name: str,
    expected_message: str,
    expected_file_path: str,
) -> None:
    """Test Add.run().

    Successfully add plugin to path
    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.
        plugin_type: Type of the plugin to add.
        plugin_name: Name of the plugin to add.
        expected_message: Expected success message.
        expected_file_path: Expected file path for the plugin.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["plugin_type"] = plugin_type
    cli_args["plugin_name"] = plugin_name
    add = Add(Config(**cli_args))

    # Mock the "_check_collection_path" method
    def mock_check_collection_path() -> None:
        """Mock function to skip checking collection path."""

    monkeypatch.setattr(
        Add,
        "_check_collection_path",
        staticmethod(mock_check_collection_path),
    )

    # Mock the "update_galaxy_dependency" method (for action plugin)
    def mock_update_galaxy_dependency() -> None:
        """Mock function to skip updating galaxy file."""

    monkeypatch.setattr(
        Add,
        "update_galaxy_dependency",
        staticmethod(mock_update_galaxy_dependency),
    )

    add.run()
    result = capsys.readouterr().out
    assert expected_message in result

    expected_file = tmp_path / expected_file_path
    effective_file = FIXTURES_DIR / "collection" / "testorg" / "testcol" / expected_file_path
    cmp_result = cmp(expected_file, effective_file, shallow=False)
    if not cmp_result:
        diff = subprocess.run(
            f"diff -u {expected_file} {effective_file}",
            shell=True,
            capture_output=True,
            text=True,
            check=False,
        )
        assert False, f"Files are different:\n{diff.stdout}"  # noqa: B011, PT015
    assert cmp_result

    # Test conflict handling
    conflict_file = tmp_path / expected_file_path
    conflict_file.write_text("Author: Your Name")

    # expect a CreatorError when the response to overwrite is no.
    monkeypatch.setattr("builtins.input", lambda _: "n")
    fail_msg = (
        "The destination directory contains files that will be overwritten."
        " Please re-run ansible-creator with --overwrite to continue."
    )
    with pytest.raises(
        CreatorError,
        match=fail_msg,
    ):
        add.run()

    # expect a warning followed by plugin addition msg
    # when response to overwrite is yes.
    monkeypatch.setattr("builtins.input", lambda _: "y")
    add.run()
    result = capsys.readouterr().out
    assert "already exists" in result, result
    assert expected_message in result


def test_run_error_plugin_no_overwrite(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Add.run().

    Successfully add devfile to path

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["plugin_type"] = "lookup"
    cli_args["plugin_name"] = "sample_lookup"
    add = Add(
        Config(**cli_args),
    )

    # Mock the "_check_collection_path" method
    def mock_check_collection_path() -> None:
        """Mock function to skip checking collection path."""

    monkeypatch.setattr(
        Add,
        "_check_collection_path",
        staticmethod(mock_check_collection_path),
    )
    add.run()
    result = capsys.readouterr().out
    assert "Note: Lookup plugin added to" in result

    expected_file = tmp_path / "plugins" / "lookup" / "sample_lookup.py"
    effective_file = (
        FIXTURES_DIR
        / "collection"
        / "testorg"
        / "testcol"
        / "plugins"
        / "lookup"
        / "sample_lookup.py"
    )
    cmp_result = cmp(expected_file, effective_file, shallow=False)
    assert cmp_result

    conflict_file = tmp_path / "plugins" / "lookup" / "sample_lookup.py"
    conflict_file.write_text("name: Your Name")

    cli_args["no_overwrite"] = True
    add = Add(
        Config(**cli_args),
    )
    with pytest.raises(CreatorError) as exc_info:
        add.run()
    assert "Please re-run ansible-creator with --overwrite to continue." in str(exc_info.value)


def test_run_error_unsupported_plugin_type(
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Add.run() with an unsupported plugin type.

    This test checks if the CreatorError is raised when an unsupported
    resource type is provided.

    Args:
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    add = Add(
        Config(**cli_args),
    )

    # Mock the "_check_collection_path" method
    def mock_check_collection_path() -> None:
        """Mock function to skip checking collection path."""

    monkeypatch.setattr(
        Add,
        "_check_collection_path",
        staticmethod(mock_check_collection_path),
    )
    monkeypatch.setattr(add, "_plugin_type", "unsupported_type")

    # Expect a CreatorError with the appropriate message
    with pytest.raises(CreatorError) as exc_info:
        add.run()
    assert "Unsupported plugin type: unsupported_type" in str(exc_info.value)


def test_run_success_add_execution_env(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Add.run() for adding a execution-environment sample file.

    Successfully adds execution-environment.yml sample file to path.

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    # Set the resource_type to execution-environment
    cli_args["resource_type"] = "execution-environment"
    add = Add(
        Config(**cli_args),
    )
    add.run()
    result = capsys.readouterr().out
    assert "Note: Resource added to" in result

    # Verify the generated execution-environment file match the expected structure
    expected_ee_file = tmp_path / "execution-environment.yml"
    effective_ee_file = (
        FIXTURES_DIR / "common" / "execution-environment" / "execution-environment.yml"
    )

    cmp_result = cmp(expected_ee_file, effective_ee_file, shallow=False)
    assert cmp_result

    # Test for overwrite prompt and failure with no overwrite option
    conflict_file = tmp_path / "execution-environment.yml"
    conflict_file.write_text('{ "version": "1" }')

    # expect a CreatorError when the response to overwrite is no.
    monkeypatch.setattr("builtins.input", lambda _: "n")
    fail_msg = (
        "The destination directory contains files that will be overwritten."
        " Please re-run ansible-creator with --overwrite to continue."
    )
    with pytest.raises(
        CreatorError,
        match=fail_msg,
    ):
        add.run()

    # expect a warning followed by execution-environment resource creation msg
    # when response to overwrite is yes.
    monkeypatch.setattr("builtins.input", lambda _: "y")
    add.run()
    result = capsys.readouterr().out
    assert "already exists" in result, result
    assert "Note: Resource added to" in result


def test_run_success_add_play_argspec(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Add.run() for adding play-argspec sample files.

    Successfully adds playbook argspec sample files to path.

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    # Set the resource_type to play-argspec
    cli_args["resource_type"] = "play-argspec"
    add = Add(
        Config(**cli_args),
    )
    add.run()
    result = capsys.readouterr().out
    assert "Note: Resource added to" in result

    # Verify the generated play-argspec files match the expected structure and content
    argspec_file_paths = [
        "argspec_validation_plays.yml",
        "argspec_validation_plays.meta.yml",
        "inventory/argspec_validation_inventory.yml",
    ]

    for file_path in argspec_file_paths:
        expected_file = tmp_path / file_path
        effective_file = FIXTURES_DIR / "project" / "playbook_project" / file_path
        cmp_file_result = cmp(expected_file, effective_file, shallow=False)
        assert cmp_file_result

    # Test for overwrite prompt and failure with no overwrite option, then confirm overwrite
    conflict_file = tmp_path / "argspec_validation_plays.yml"
    conflict_file.write_text('{ "version": "1" }')

    monkeypatch.setattr("builtins.input", lambda _: "n")
    fail_msg = (
        "The destination directory contains files that will be overwritten."
        " Please re-run ansible-creator with --overwrite to continue."
    )
    with pytest.raises(
        CreatorError,
        match=fail_msg,
    ):
        add.run()

    monkeypatch.setattr("builtins.input", lambda _: "y")
    add.run()
    result = capsys.readouterr().out
    assert "already exists" in result, result
    assert "Note: Resource added to" in result


def test_run_success_add_role(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Add.run() for adding a role sample file.

    Successfully adds role sample file to path.

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
        ValueError: If the file is not found.
    """
    # Set the resource_type to role
    cli_args["resource_type"] = "role"
    cli_args["role_name"] = "run"
    add = Add(
        Config(**cli_args),
    )

    # Mock the "_check_collection_path" method
    def mock_check_collection_path() -> None:
        """Mock function to skip checking collection path."""

    monkeypatch.setattr(
        Add,
        "_check_collection_path",
        staticmethod(mock_check_collection_path),
    )

    # Mock the "role_galaxy" method
    def mock_role_galaxy() -> tuple[str, str]:
        """Mock this function to return specific values.

        Returns:
            tuple[str, str]: Values for namespace and collection name.
        """
        return "testorg", "testcol"

    monkeypatch.setattr(
        Add,
        "role_galaxy",
        staticmethod(mock_role_galaxy),
    )

    add.run()
    result = capsys.readouterr().out
    assert "Note: Resource added to" in result

    # Verify the role file match the expected structure
    try:
        expected_role_file = tmp_path / "roles" / "run" / "meta" / "main.yml"
        effective_role_file = (
            FIXTURES_DIR
            / "collection"
            / "testorg"
            / "testcol"
            / "roles"
            / "run"
            / "meta"
            / "main.yml"
        )
    except ValueError as e:
        # Assign the error message to a variable before raising the exception
        error_message = "file not found"
        raise ValueError(error_message) from e

    cmp_result = cmp(expected_role_file, effective_role_file, shallow=False)
    assert cmp_result

    # Test for overwrite prompt and failure with no overwrite option
    conflict_file = tmp_path / "roles" / "run" / "meta" / "main.yml"
    conflict_file.write_text('{ "version": "1" }')

    # expect a CreatorError when the response to overwrite is no.
    monkeypatch.setattr("builtins.input", lambda _: "n")
    fail_msg = (
        "The destination directory contains files that will be overwritten."
        " Please re-run ansible-creator with --overwrite to continue."
    )
    with pytest.raises(
        CreatorError,
        match=fail_msg,
    ):
        add.run()

    # expect a warning followed by execution-environment resource creation msg
    # when response to overwrite is yes.
    monkeypatch.setattr("builtins.input", lambda _: "y")
    add.run()
    result = capsys.readouterr().out
    assert "already exists" in result, result
    assert "Note: Resource added to" in result


def test_update_galaxy_dependency(tmp_path: Path, cli_args: ConfigDict) -> None:
    """Test update_galaxy_dependency method.

    Args:
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.

    Raises:
        AssertionError: If the assertion fails.
    """
    galaxy_file = tmp_path / "galaxy.yml"
    initial_data: dict[str, Any]

    # Test case 1: No dependencies key
    initial_data = {"name": "test_collection"}
    galaxy_file.write_text(yaml.dump(initial_data))
    add = Add(Config(**cli_args))
    add.update_galaxy_dependency()

    with galaxy_file.open("r") as file:
        updated_data = yaml.safe_load(file)
    assert "dependencies" in updated_data
    assert updated_data["dependencies"] == {"ansible.utils": "*"}

    # Test case 2: Empty dependencies
    initial_data = {"name": "test_collection", "dependencies": {}}
    galaxy_file.write_text(yaml.dump(initial_data))
    add.update_galaxy_dependency()

    with galaxy_file.open("r") as file:
        updated_data = yaml.safe_load(file)
    assert updated_data["dependencies"] == {"ansible.utils": "*"}

    # Test case 3: Existing dependencies without ansible.utils
    initial_data = {"name": "test_collection", "dependencies": {"another.dep": "1.0.0"}}
    galaxy_file.write_text(yaml.dump(initial_data))
    add.update_galaxy_dependency()

    with galaxy_file.open("r") as file:
        updated_data = yaml.safe_load(file)
    assert updated_data["dependencies"] == {"another.dep": "1.0.0", "ansible.utils": "*"}

    # Test case 4: Existing dependencies with ansible.utils
    initial_data = {"name": "test_collection", "dependencies": {"ansible.utils": "1.0.0"}}
    galaxy_file.write_text(yaml.dump(initial_data))
    add.update_galaxy_dependency()

    with galaxy_file.open("r") as file:
        updated_data = yaml.safe_load(file)
    assert updated_data["dependencies"] == {"ansible.utils": "1.0.0"}


def test_role_galaxy(tmp_path: Path, cli_args: ConfigDict) -> None:
    """Test update_galaxy_dependency method.

    Args:
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Add class object.

    Raises:
        AssertionError: If the assertion fails.
        AssertionError: If the namespace or collection name mismatch.
    """
    galaxy_file = tmp_path / "galaxy.yml"
    initial_data: dict[str, Any]

    # Test case 1: No dependencies key
    initial_data = {}
    galaxy_file.write_text(yaml.dump(initial_data))
    add = Add(Config(**cli_args))
    namespace, collection_name = add.role_galaxy()

    with galaxy_file.open("r") as file:
        updated_data = yaml.safe_load(file)
    if namespace != "your-collection-namespace" or collection_name != "your-collection-name":
        error = "Namespace or collection name mismatch"
        raise AssertionError(error)
    assert namespace == "your-collection-namespace"
    assert collection_name == "your-collection-name"

    # Test case 3: Existing dependencies without ansible.utils
    initial_data = {"namespace": "test_collection", "name": "collection_test"}
    galaxy_file.write_text(yaml.dump(initial_data))
    namespace, collection_name = add.role_galaxy()

    with galaxy_file.open("r") as file:
        updated_data = yaml.safe_load(file)

    assert namespace == updated_data["namespace"]
    assert collection_name == updated_data["name"]


def test_run_success_add_pattern(
    capsys: pytest.CaptureFixture[str],
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Add.run() for adding a sample pattern structure.

    Successfully adds a pattern structure to path.

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        cli_args: Dictionary, partial Add class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    # Set the resource_type to pattern
    cli_args["resource_type"] = "pattern"
    add = Add(
        Config(**cli_args),
    )

    # Mock the "_check_collection_path" method
    def mock_check_collection_path() -> None:
        """Mock function to skip checking collection path."""

    monkeypatch.setattr(
        Add,
        "_check_collection_path",
        staticmethod(mock_check_collection_path),
    )

    add.run()
    result = capsys.readouterr().out
    assert "Note: Resource added to" in result

================
File: tests/units/test_argparse_help.py
================
"""Test the custom help formatter."""

from __future__ import annotations

import argparse

import pytest

from ansible_creator.arg_parser import CustomHelpFormatter


def test_custom_help_single() -> None:
    """Test the custom help formatter with single.

    Raises:
        AssertionError: If the assertion fails.
    """
    parser = argparse.ArgumentParser(formatter_class=CustomHelpFormatter)
    parser.add_argument("--foo", help="foo help")
    help_text = parser.format_help()
    line = " --foo          foo help"
    assert line in help_text.splitlines()


def test_custom_help_double() -> None:
    """Test the custom help formatter with double.

    Raises:
        AssertionError: If the assertion fails.
    """
    parser = argparse.ArgumentParser(formatter_class=CustomHelpFormatter)
    parser.add_argument("-f", "--foo", help="foo help")
    help_text = parser.format_help()
    line = " -f     --foo   foo help"
    assert line in help_text.splitlines()


def test_custom_help_triple() -> None:
    """Test the custom help formatter with triple."""
    parser = argparse.ArgumentParser(formatter_class=CustomHelpFormatter)
    parser.add_argument("-f", "--foo", "--foolish", help="foo help")

    with pytest.raises(ValueError, match="Too many option strings"):
        parser.format_help()

================
File: tests/units/test_basic.py
================
"""Basic unit tests for ansible-creator."""

from __future__ import annotations

import re
import runpy
import sys

from pathlib import Path, PosixPath

import pytest

from ansible_creator.cli import Cli
from ansible_creator.config import Config
from ansible_creator.output import Output
from ansible_creator.utils import TermFeatures, expand_path


def test_configuration_class(output: Output) -> None:
    """Test Config() dataclass post_init.

    Args:
        output: Output dataclass object.

    Raises:
        AssertionError: If the assertion fails.
    """
    app_config = Config(
        creator_version="0.0.1",
        subcommand="init",
        collection="testorg.testcol",
        init_path="$HOME",
        output=output,
    )
    assert app_config.namespace == "testorg"
    assert app_config.collection_name == "testcol"
    home_path = Path.home()
    assert app_config.init_path == home_path


@pytest.mark.parametrize(
    argnames=("sysargs", "expected"),
    argvalues=(
        (
            ["ansible-creator", "init", "testorg.testcol"],
            {
                "subcommand": "init",
                "no_ansi": False,
                "log_file": str(Path.cwd() / "ansible-creator.log"),
                "log_level": "notset",
                "log_append": "true",
                "json": False,
                "verbose": 0,
                "collection": "testorg.testcol",
                "init_path": "./",
                "force": False,
                "no_overwrite": False,
                "overwrite": False,
                "project": "collection",  # default value
            },
        ),
        (
            [
                "ansible-creator",
                "init",
                "--project=ansible-project",
                f"--init-path={Path.home()}/my-ansible-project",
                "--scm-org=weather",
                "--scm-project=demo",
            ],
            {
                "subcommand": "init",
                "no_ansi": False,
                "log_file": str(Path.cwd() / "ansible-creator.log"),
                "log_level": "notset",
                "log_append": "true",
                "json": False,
                "verbose": 0,
                "collection": "weather.demo",
                "init_path": f"{Path.home()}/my-ansible-project",
                "force": False,
                "no_overwrite": False,
                "overwrite": False,
                "project": "playbook",
            },
        ),
        (
            [
                "ansible-creator",
                "init",
                "testorg.testcol",
                f"--init-path={Path.home()}",
                "-vvv",
                "--json",
                "--no-ansi",
                "--la=false",
                "--lf=test.log",
                "--ll=debug",
                "--force",
            ],
            {
                "subcommand": "init",
                "no_ansi": True,
                "log_file": "test.log",
                "log_level": "debug",
                "log_append": "false",
                "json": True,
                "verbose": 3,
                "collection": "testorg.testcol",
                "init_path": f"{Path.home()}",
                "force": True,
                "no_overwrite": False,
                "overwrite": False,
                "project": "collection",  # default value
            },
        ),
        (
            [
                "ansible-creator",
                "init",
                "--project=ansible-project",
                "--scm-org=weather",
                "--scm-project=demo",
                f"--init-path={Path.home()}/my-ansible-project",
                "-vvv",
                "--json",
                "--no-ansi",
                "--la=false",
                "--lf=test.log",
                "--ll=debug",
                "--force",
            ],
            {
                "subcommand": "init",
                "no_ansi": True,
                "log_file": "test.log",
                "log_level": "debug",
                "log_append": "false",
                "json": True,
                "verbose": 3,
                "collection": "weather.demo",
                "init_path": f"{Path.home()}/my-ansible-project",
                "force": True,
                "no_overwrite": False,
                "overwrite": False,
                "project": "playbook",
            },
        ),
        (
            [
                "ansible-creator",
                "init",
                "collection",
                "foo.bar",
                "/test/test",
                "--lf=test.log",
            ],
            {
                "subcommand": "init",
                "project": "collection",
                "collection": "foo.bar",
                "init_path": "/test/test",
                "force": False,
                "no_overwrite": False,
                "overwrite": False,
                "json": False,
                "log_append": "true",
                "log_file": "test.log",
                "log_level": "notset",
                "no_ansi": False,
                "verbose": 0,
            },
        ),
        (
            [
                "ansible-creator",
                "init",
                "playbook",
                "foo.bar",
                "/test/test",
                "--lf=test.log",
            ],
            {
                "subcommand": "init",
                "project": "playbook",
                "collection": "foo.bar",
                "init_path": "/test/test",
                "force": False,
                "no_overwrite": False,
                "overwrite": False,
                "json": False,
                "log_append": "true",
                "log_file": "test.log",
                "log_level": "notset",
                "no_ansi": False,
                "verbose": 0,
            },
        ),
    ),
)
def test_cli_parser(
    monkeypatch: pytest.MonkeyPatch,
    sysargs: list[str],
    expected: dict[str, str | bool | None],
) -> None:
    """Test CLI args parsing.

    Args:
        monkeypatch: Pytest monkeypatch fixture.
        sysargs: List of CLI arguments.
        expected: Expected values for the parsed CLI arguments.

    Raises:
        AssertionError: If the assertion fails.
    """
    monkeypatch.setattr("sys.argv", sysargs)
    parsed_args = Cli().args
    assert parsed_args == expected


def test_missing_j2(monkeypatch: pytest.MonkeyPatch) -> None:
    """Test missing Jinja2.

    Args:
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    fail_msg = (
        "jinja2 is required but does not appear to be installed."
        "It can be installed using `pip install jinja2`"
    )

    monkeypatch.setattr("sys.path", [])
    monkeypatch.delitem(sys.modules, "jinja2", raising=False)
    monkeypatch.delitem(sys.modules, "ansible_creator.templar", raising=False)

    import ansible_creator.templar  # noqa: PLC0415

    assert ansible_creator.templar.HAS_JINJA2 is False
    with pytest.raises(ImportError, match=fail_msg):
        ansible_creator.templar.Templar()


def test_cli_init_output(monkeypatch: pytest.MonkeyPatch, home_path: PosixPath) -> None:
    """Test CLI init_output method.

    Args:
        monkeypatch: Pytest monkeypatch fixture.
        home_path: Home directory.

    Raises:
        AssertionError: If the assertion fails.
    """
    sysargs = [
        "ansible-creator",
        "init",
        "testorg.testcol",
        f"--init-path={home_path}",
        "-vvv",
        "--json",
        "--no-ansi",
        "--la=false",
        "--lf=test.log",
        "--ll=debug",
        "--force",
    ]
    output = Output(
        log_append="false",
        log_file=str(expand_path("test.log")),
        log_level="debug",
        term_features=TermFeatures(color=False, links=False),
        verbosity=3,
        display="json",
    )

    monkeypatch.setattr("sys.argv", sysargs)
    cli = Cli()
    cli.init_output()
    assert vars(cli.output) == vars(output)


def test_cli_main(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test CLI main method.

    Args:
        capsys: Pytest capsys fixture.
        tmp_path: Temporary path.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    sysargs = [
        "ansible-creator",
        "init",
        "testns.testcol",
        f"--init-path={tmp_path}/testns/testcol",
        "--json",
        "--force",
        "-vvv",
    ]

    monkeypatch.setattr("sys.argv", sysargs)
    cli = Cli()
    cli.init_output()
    cli.run()

    result = capsys.readouterr().out
    # check stdout
    assert re.search(r"collection project created", result) is not None


@pytest.mark.parametrize(argnames="project", argvalues=("collection", "playbook"))
def test_collection_name_short(
    project: str,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test invalid collection name.

    Args:
        project: The project type.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    sysargs = [
        "ansible-creator",
        "init",
        project,
        "a.b",
    ]
    monkeypatch.setattr("sys.argv", sysargs)

    cli = Cli()

    msg = "Both the collection namespace and name must be longer than 2 characters."
    assert any(msg in log.message for log in cli.pending_logs)


@pytest.mark.parametrize(argnames="project", argvalues=("collection", "playbook"))
def test_collection_name_invalid(
    project: str,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test invalid collection name.

    Args:
        project: The project type.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    sysargs = [
        "ansible-creator",
        "init",
        project,
        "$____.^____",
    ]
    monkeypatch.setattr("sys.argv", sysargs)

    cli = Cli()

    msg = (
        "Collection name can only contain lower case letters, underscores,"
        " and numbers and cannot begin with an underscore."
    )
    assert any(msg in log.message for log in cli.pending_logs)


def test_is_a_tty(monkeypatch: pytest.MonkeyPatch) -> None:
    """Test is a tty.

    Args:
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    sysargs = [
        "ansible-creator",
        "init",
        "testorg.testcol",
        f"{Path.home()}",
    ]

    monkeypatch.setattr("sys.argv", sysargs)
    monkeypatch.setattr("sys.stdout.isatty", lambda: True)

    cli = Cli()
    cli.init_output()
    assert cli.output.term_features.color is True
    assert cli.output.term_features.links is True
    assert cli.output.term_features.any_enabled() is True


def test_not_a_tty(monkeypatch: pytest.MonkeyPatch) -> None:
    """Test not a tty.

    Args:
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    sysargs = [
        "ansible-creator",
        "init",
        "testorg.testcol",
        f"{Path.home()}",
    ]

    monkeypatch.setattr("sys.argv", sysargs)
    monkeypatch.setattr("sys.stdout.isatty", lambda: False)

    cli = Cli()
    cli.init_output()
    assert cli.output.term_features.color is False
    assert cli.output.term_features.links is False
    assert cli.output.term_features.any_enabled() is False


def test_main(monkeypatch: pytest.MonkeyPatch, capsys: pytest.CaptureFixture[str]) -> None:
    """Test cli main.

    Args:
        monkeypatch: Pytest monkeypatch fixture.
        capsys: Pytest capsys fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    monkeypatch.setattr("sys.argv", ["ansible-creator", "--help"])

    with pytest.raises(SystemExit):
        runpy.run_module("ansible_creator.cli", run_name="__main__")
    stdout, _stderr = capsys.readouterr()
    assert "The fastest way" in stdout


def test_proj_main(monkeypatch: pytest.MonkeyPatch, capsys: pytest.CaptureFixture[str]) -> None:
    """Test project main.

    Args:
        monkeypatch: Pytest monkeypatch fixture.
        capsys: Pytest capsys fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    monkeypatch.setattr("sys.argv", ["ansible-creator", "--help"])

    with pytest.raises(SystemExit):
        runpy.run_module("ansible_creator", run_name="__main__")
    stdout, _stderr = capsys.readouterr()
    assert "The fastest way" in stdout


def test_config_post_init(
    tmp_path: Path,
    output: Output,
) -> None:
    """Test for a check in post_init in Config class.

    Args:
        tmp_path: Temporary directory path.
        output: Output class object.

    Raises:
        AssertionError: If the assertion fails.
    """
    config = Config(
        creator_version="24.10.0",
        output=output,
        subcommand="init",
        collection="foo.bar",
        init_path=str(tmp_path / "test_path"),
        project="ansible-project",
    )
    config.__post_init__()
    assert config.project == "playbook"

================
File: tests/units/test_compat.py
================
"""Tests for compat module."""

from __future__ import annotations

from ansible_creator.compat import Traversable


def test_import() -> None:
    """Test the import of traversable.

    This is a simple test to ensure that the import of Traversable is working.
    Since it is only imported for type checking.

    Raises:
        AssertionError: If the assertion fails.
    """
    assert Traversable is not None

================
File: tests/units/test_init.py
================
# cspell: ignore dcmp, subdcmp
"""Unit tests for ansible-creator init."""

from __future__ import annotations

import re
import shutil
import subprocess

from filecmp import dircmp
from pathlib import Path
from typing import TypedDict

import pytest

from ansible_creator.config import Config
from ansible_creator.exceptions import CreatorError
from ansible_creator.output import Output
from ansible_creator.subcommands.init import Init
from ansible_creator.utils import TermFeatures
from tests.defaults import FIXTURES_DIR, UUID_LENGTH


class ConfigDict(TypedDict):
    """Type hint for Config dictionary.

    Attributes:
        creator_version: The version of the creator.
        output: The output object to use for logging.
        subcommand: The subcommand to execute.
        collection: The name of the collection.
        init_path: Path to initialize the project.
        project: The type of project to scaffold.
        force: Force overwrite of existing directory.
        overwrite: To overwrite files in an existing directory.
        no_overwrite: To not overwrite files in an existing directory.
    """

    creator_version: str
    output: Output
    subcommand: str
    collection: str
    init_path: str
    project: str
    force: bool
    overwrite: bool
    no_overwrite: bool


@pytest.fixture(name="cli_args")
def fixture_cli_args(tmp_path: Path, output: Output) -> ConfigDict:
    """Create a dict to use for a Init class object as fixture.

    Args:
        tmp_path: Temporary directory path.
        output: Output class object.

    Returns:
        dict: Dictionary, partial Init class object.
    """
    return {
        "creator_version": "0.0.1",
        "output": output,
        "subcommand": "init",
        "collection": "testorg.testcol",
        "init_path": str(tmp_path / "testorg" / "testcol"),
        "project": "",
        "force": False,
        "overwrite": False,
        "no_overwrite": False,
    }


def has_differences(dcmp: dircmp[str], errors: list[str]) -> list[str]:
    """Recursively check for differences in dircmp object.

    Args:
        dcmp: dircmp object.
        errors: List of errors.

    Returns:
        list: List of errors.
    """
    errors.extend([f"Only in {dcmp.left}: {f}" for f in dcmp.left_only])
    errors.extend([f"Only in {dcmp.right}: {f}" for f in dcmp.right_only])
    errors.extend(
        [f"Differing files: {dcmp.left}/{f} {dcmp.right}/{f}" for f in dcmp.diff_files],
    )
    for subdcmp in dcmp.subdirs.values():
        errors = has_differences(subdcmp, errors)

    for f in dcmp.diff_files:
        result = subprocess.run(
            f"git diff --no-index {dcmp.left}/{f} {dcmp.right}/{f}",
            shell=True,
            capture_output=True,
            text=True,
            check=False,
        )
        errors.append(f"Differing files: {dcmp.left}/{f} {dcmp.right}/{f}:\n{result.stdout}")
    return errors


def test_run_success_for_collection(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Init.run().

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Init class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["project"] = "collection"
    init = Init(
        Config(**cli_args),
    )

    # Mock the "unique_name_in_devfile" method
    def mock_unique_name_in_devfile(init: Init) -> str:
        coll_namespace = init._namespace
        coll_name = init._collection_name
        return f"{coll_namespace}.{coll_name}"

    with pytest.MonkeyPatch.context() as mp:
        # Apply the mock
        mp.setattr(
            Init,
            "unique_name_in_devfile",
            mock_unique_name_in_devfile,
        )
        init.run()
    result = capsys.readouterr().out

    # check stdout
    assert r"Note: collection project created" in result

    # recursively assert files created
    cmp = dircmp(str(tmp_path), str(FIXTURES_DIR / "collection"), ignore=[".DS_Store", ".ansible"])
    diff = has_differences(dcmp=cmp, errors=[])
    assert diff == [], diff
    # expect a CreatorError when the response to overwrite is no.
    monkeypatch.setattr("builtins.input", lambda _: "n")
    fail_msg = (
        "The destination directory contains files that will be overwritten."
        " Please re-run ansible-creator with --overwrite to continue."
    )
    with pytest.raises(
        CreatorError,
        match=fail_msg,
    ):
        init.run()

    # expect a warning followed by collection project creation msg
    # when response to overwrite is yes.
    monkeypatch.setattr("builtins.input", lambda _: "y")
    init.run()
    result = capsys.readouterr().out
    assert r"already exists" in result, result
    assert r"Note: collection project created at" in result, result

    # override existing collection with force=true
    cli_args["force"] = True
    init = Init(
        Config(**cli_args),
    )
    init.run()
    result = capsys.readouterr().out
    assert r"Warning: re-initializing existing directory" in result, result


def test_run_success_ee_project(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
) -> None:
    """Test Init.run().

    Successfully create new ee project

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Init class object.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["project"] = "execution_env"
    cli_args["init_path"] = str(tmp_path / "new_project")
    init = Init(
        Config(**cli_args),
    )

    init.run()
    result = capsys.readouterr().out

    # check stdout
    assert r"Note: execution_env project created" in result

    # recursively assert files created
    cmp = dircmp(
        str(tmp_path / "new_project"),
        str(FIXTURES_DIR / "project" / "ee_project"),
    )
    diff = has_differences(dcmp=cmp, errors=[])
    assert diff == [], diff


def test_run_success_ansible_project(
    capsys: pytest.CaptureFixture[str],
    tmp_path: Path,
    cli_args: ConfigDict,
    monkeypatch: pytest.MonkeyPatch,
) -> None:
    """Test Init.run().

    Successfully create new playbook project

    Args:
        capsys: Pytest fixture to capture stdout and stderr.
        tmp_path: Temporary directory path.
        cli_args: Dictionary, partial Init class object.
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["collection"] = "weather.demo"
    cli_args["project"] = "playbook"
    cli_args["init_path"] = str(tmp_path / "new_project")
    init = Init(
        Config(**cli_args),
    )

    # Mock the "unique_name_in_devfile" method
    def mock_unique_name_in_devfile(init: Init) -> str:
        coll_namespace = init._namespace
        coll_name = init._collection_name
        return f"{coll_namespace}.{coll_name}"

    with pytest.MonkeyPatch.context() as mp:
        # Apply the mock
        mp.setattr(
            Init,
            "unique_name_in_devfile",
            mock_unique_name_in_devfile,
        )
        init.run()
    result = capsys.readouterr().out

    # check stdout
    assert r"Note: playbook project created" in result

    # recursively assert files created
    cmp = dircmp(
        str(tmp_path / "new_project"),
        str(FIXTURES_DIR / "project" / "playbook_project"),
        ignore=[".DS_Store", ".ansible"],
    )
    diff = has_differences(dcmp=cmp, errors=[])
    assert diff == [], diff

    # expect a CreatorError when the response to overwrite is no.
    monkeypatch.setattr("builtins.input", lambda _: "n")
    fail_msg = (
        "The destination directory contains files that will be overwritten."
        " Please re-run ansible-creator with --overwrite to continue."
    )
    with pytest.raises(
        CreatorError,
        match=fail_msg,
    ):
        init.run()

    # expect a warning followed by playbook project creation msg
    # when response to overwrite is yes.
    monkeypatch.setattr("builtins.input", lambda _: "y")
    init.run()
    result = capsys.readouterr().out
    assert r"already exists" in result, result
    assert r"Note: playbook project created at" in result, result

    # override existing playbook directory with force=true
    cli_args["force"] = True
    init = Init(
        Config(**cli_args),
    )
    init.run()
    result = capsys.readouterr().out
    assert r"Warning: re-initializing existing directory" in result, result


def test_run_success_collections_alt_dir(
    tmp_path: Path,
    capsys: pytest.CaptureFixture[str],
    cli_args: ConfigDict,
) -> None:
    """Test Init.run() when init_path ends with "collections" / "ansible_collections.

    Successfully create new collection

    Args:
        tmp_path: Temporary directory path.
        capsys: Pytest fixture to capture stdout and stderr.
        cli_args: Dictionary, partial Init class object.

    Raises:
        AssertionError: If the assertion fails.
    """
    cli_args["project"] = "collection"
    cli_args["init_path"] = str(tmp_path / "collections" / "ansible_collections")
    final_path = Path(cli_args["init_path"]) / "testorg" / "testcol"
    init = Init(
        Config(**cli_args),
    )
    init.run()
    result = capsys.readouterr().out

    # this is required to handle random line breaks in CI, especially with macos runners
    mod_result = "".join([line.strip() for line in result.splitlines()])

    assert (
        re.search(
            rf"Note:\s*collection\s*project\s*created\s*at\s*{final_path}",
            mod_result,
        )
        is not None
    )


def test_delete_error(monkeypatch: pytest.MonkeyPatch, tmp_path: Path) -> None:
    """Test a remove fails gracefully.

    Args:
        monkeypatch: Pytest monkeypatch fixture.
        tmp_path: Temporary directory path.

    Raises:
        AssertionError: If the assertion fails.
    """
    (tmp_path / "file.txt").touch()

    init = Init(
        Config(
            creator_version="0.0.1",
            force=True,
            subcommand="init",
            collection="testorg.testcol",
            init_path=str(tmp_path),
            output=Output(
                log_file=str(tmp_path / "log.log"),
                log_level="DEBUG",
                log_append="false",
                term_features=TermFeatures(color=False, links=False),
                verbosity=0,
            ),
        ),
    )

    err = "Test thrown error"

    def rmtree(path: Path) -> None:  # noqa: ARG001
        raise OSError(err)

    monkeypatch.setattr(shutil, "rmtree", rmtree)

    with pytest.raises(CreatorError, match=err) as exc_info:
        init.run()
    assert "failed to remove existing directory" in str(exc_info.value)


def test_is_file_error(tmp_path: Path) -> None:
    """Test a file dest fails gracefully.

    Args:
        tmp_path: Temporary directory path.

    Raises:
        AssertionError: If the assertion fails.
    """
    file = tmp_path / "file.txt"
    file.touch()
    init = Init(
        Config(
            creator_version="0.0.1",
            force=True,
            subcommand="init",
            collection="testorg.testcol",
            init_path=str(file),
            output=Output(
                log_file=str(tmp_path / "log.log"),
                log_level="DEBUG",
                log_append="false",
                term_features=TermFeatures(color=False, links=False),
                verbosity=0,
            ),
        ),
    )

    with pytest.raises(CreatorError) as exc_info:
        init.run()
    assert "but is a file" in str(exc_info.value)


@pytest.fixture(name="cli_args_collection")
def fixture_collection_project(tmp_path: Path, output: Output) -> Config:
    """Fixture for Config object with collection project.

    Args:
        tmp_path: Temporary directory path.
        output: Output class object.

    Returns:
        Config: Config class object.
    """
    return Config(
        subcommand="init",
        namespace="testns",
        collection_name="testname",
        init_path=str(tmp_path / "test_path"),
        force=False,
        creator_version="1.0.0",
        project="collection",
        output=output,
    )


@pytest.fixture(name="cli_args_playbook")
def fixture_playbook_project(tmp_path: Path, output: Output) -> Config:
    """Fixture for Config object with playbook.

    Args:
        tmp_path: Temporary directory path.
        output: Output class object.

    Returns:
        Config: Config class object.
    """
    return Config(
        subcommand="init",
        namespace="foo",
        collection_name="bar",
        init_path=str(tmp_path / "test_path"),
        force=False,
        creator_version="1.0.0",
        project="playbook",
        output=output,
    )


def test_name_in_devfile_collection(cli_args_collection: Config) -> None:
    """Test unique_name_in_devfile method for collection project.

    Args:
        cli_args_collection: Configuration object for collection project.

    Raises:
        AssertionError: If the assertion fails.
    """
    init = Init(cli_args_collection)
    unique_name = init.unique_name_in_devfile()
    assert unique_name.startswith("testns.testname-")
    uuid_part = unique_name.rsplit("-", maxsplit=1)[-1]  # Extract the UUID part
    assert len(uuid_part) == UUID_LENGTH, "UUID part length mismatch"


def test_name_in_devfile_playbook(
    cli_args_playbook: Config,
) -> None:
    """Test unique_name_in_devfile method for playbook project.

    Args:
        cli_args_playbook: Configuration object for playbook project.

    Raises:
        AssertionError: If the assertion fails.
    """
    init = Init(cli_args_playbook)
    unique_name = init.unique_name_in_devfile()
    assert unique_name.startswith("foo.bar-")
    uuid_part = unique_name.rsplit("-", maxsplit=1)[-1]  # Extract the UUID part
    assert len(uuid_part) == UUID_LENGTH, "UUID part length mismatch"

================
File: tests/units/test_output.py
================
"""Test the output module."""

from __future__ import annotations

from types import SimpleNamespace
from typing import TYPE_CHECKING

import pytest

from ansible_creator.output import Color, Level, Msg, Output, console_width
from ansible_creator.utils import TermFeatures


if TYPE_CHECKING:
    from pathlib import Path


@pytest.mark.parametrize(
    argnames=("width", "expected"),
    argvalues=((79, 79), (131, 81), (133, 132)),
)
def test_console_width(width: int, expected: int, monkeypatch: pytest.MonkeyPatch) -> None:
    """Test the console width function."""

    def mock_get_terminal_size() -> SimpleNamespace:
        return SimpleNamespace(columns=width, lines=24)

    monkeypatch.setattr("shutil.get_terminal_size", mock_get_terminal_size)

    monkeypatch.delenv("COLUMNS", raising=False)

    assert console_width() == expected


@pytest.mark.parametrize(
    "params",
    (
        (Level.CRITICAL, Color.BRIGHT_RED),
        (Level.DEBUG, Color.GREY),
        (Level.ERROR, Color.RED),
        (Level.HINT, Color.CYAN),
        (Level.INFO, Color.MAGENTA),
        (Level.NOTE, Color.GREEN),
        (Level.WARNING, Color.YELLOW),
    ),
    ids=("critical", "debug", "error", "hint", "info", "note", "warning"),
)
def test_color_mapping(params: tuple[Level, Color]) -> None:
    """Test the color mapping for Msg in the output module.

    Args:
        params: Tuple of Level and Color.
    """
    assert Msg(message="", prefix=params[0]).color == str(params[1])


@pytest.mark.parametrize("level", ("info", "warning", "error", "debug", "critical", "hint", "note"))
def test_console_output(level: str, capsys: pytest.CaptureFixture[str], tmp_path: Path) -> None:
    """Test the console output function.

    Args:
        level: Log level.
        capsys: Pytest fixture.
        tmp_path: Pytest fixture
    """
    output = Output(
        log_file=str(tmp_path / "test.log"),
        log_level="debug",
        log_append="false",
        term_features=TermFeatures(color=True, links=True),
        verbosity=3,
    )
    message = f"{level} message"
    msg = Msg(message=message, prefix=getattr(Level, level.upper()))
    if level == "critical":
        with pytest.raises(SystemExit):
            getattr(output, level)(message)
    else:
        getattr(output, level)(message)
    captured = capsys.readouterr()
    standard_x = captured.err if level in ("critical", "error") else captured.out
    assert standard_x.startswith(msg.color)
    assert standard_x.endswith(Color.END + "\n")
    assert level.capitalize() in standard_x
    assert message in standard_x

================
File: tests/units/test_templar.py
================
"""Tests for templar."""

from __future__ import annotations

from ansible_creator.templar import Templar
from ansible_creator.types import TemplateData


def test_templar() -> None:
    """Test templar.

    Raises:
        AssertionError: If the assertion fails.
    """
    templar = Templar()
    data = TemplateData(collection_name="test")
    template = "{{ collection_name }}"
    assert templar.render_from_content(template, data) == "test"


def test_templar_json_simple() -> None:
    """Test templar json with a simple structure.

    Raises:
        AssertionError: If the assertion fails.
    """
    templar = Templar()
    data = TemplateData(recommended_extensions=["value"])
    template = "{{ recommended_extensions | json }}"
    assert templar.render_from_content(template, data) == '["value"]'


def test_templar_json_complex() -> None:
    """Test templar json with a complex structure.

    Raises:
        AssertionError: If the assertion fails.
    """
    templar = Templar()
    data = TemplateData(additions={"key": {"key": {"key": True}}})
    template = "{{ additions | json }}"
    assert templar.render_from_content(template, data) == '{"key": {"key": {"key": true}}}'

================
File: tests/units/test_utils.py
================
"""Test the utils module."""

from __future__ import annotations

import shutil

from pathlib import Path
from typing import TYPE_CHECKING

from ansible_creator.types import TemplateData
from ansible_creator.utils import Copier, Walker, ask_yes_no, expand_path


if TYPE_CHECKING:
    import pytest

    from ansible_creator.output import Output


def test_expand_path() -> None:
    """Test expand_path utils.

    Raises:
        AssertionError: If the assertion fails.
    """
    home = Path.home().resolve()
    expected = home / "collections/ansible_collections/namespace/collection"
    assert expand_path("~/$DEV_WORKSPACE/namespace/collection") == expected
    assert expand_path("~") == home
    assert expand_path("foo") == Path.cwd() / "foo"
    assert expand_path("$HOME") == home
    assert expand_path("~/$HOME") == Path(f"{home}/{Path.home()}")


def test_skip_dirs(tmp_path: Path, monkeypatch: pytest.MonkeyPatch, output: Output) -> None:
    """Test the skip dirs constant.

    Args:
        tmp_path: Temporary directory path.
        monkeypatch: Pytest monkeypatch fixture.
        output: Output class object.

    Raises:
        AssertionError: If the assertion fails.
    """
    monkeypatch.setattr("ansible_creator.utils.SKIP_DIRS", ["docker"])

    walker = Walker(
        resources=("common.devcontainer",),
        resource_id="common.devcontainer",
        dest=tmp_path,
        output=output,
        template_data=TemplateData(),
    )
    paths = walker.collect_paths()

    copier = Copier(
        output=output,
    )
    copier.copy_containers(paths)
    assert (tmp_path / ".devcontainer" / "podman").exists()
    assert not (tmp_path / ".devcontainer" / "docker").exists()


def test_overwrite(tmp_path: Path, output: Output) -> None:
    """Test Copier overwriting existing files.

    Args:
        tmp_path: Temporary directory path.
        output: Output class object.

    Raises:
        AssertionError: If the assertion fails.
    """
    walker = Walker(
        resources=("common.devcontainer",),
        resource_id="common.devcontainer",
        dest=tmp_path,
        output=output,
        template_data=TemplateData(),
    )
    paths = walker.collect_paths()

    # We will be manipulating these paths later
    base_file = tmp_path / ".devcontainer" / "devcontainer.json"
    podman_dir = tmp_path / ".devcontainer" / "podman"
    docker_file = tmp_path / ".devcontainer" / "docker" / "devcontainer.json"

    copier = Copier(
        output=output,
    )
    copier.copy_containers(paths)
    base_contents = base_file.read_text()
    assert podman_dir.is_dir()
    assert docker_file.is_file()

    # Rewrite devcontainer.json
    base_file.write_text("This is not what a devcontainer file looks like.")
    # Replace podman with a file
    shutil.rmtree(podman_dir)
    podman_dir.write_text("This is an error")
    # Replace docker devcontainer with a directory
    docker_file.unlink()
    docker_file.mkdir()

    # Re-walk directory to generate warnings, but not make changes
    paths = walker.collect_paths()
    assert base_file.read_text() != base_contents
    assert podman_dir.is_file()
    assert docker_file.is_dir()
    assert paths.has_conflicts()

    # Re-copy to overwrite structure
    copier.copy_containers(paths)
    assert base_file.read_text() == base_contents
    assert podman_dir.is_dir()
    assert docker_file.is_file()


def test_skip_repeats(tmp_path: Path, output: Output) -> None:
    """Test Copier skipping existing files.

    Args:
        tmp_path: Temporary directory path.
        output: Output class object.

    Raises:
        AssertionError: If the assertion fails.
    """
    walker = Walker(
        resources=("common.devcontainer",),
        resource_id="common.devcontainer",
        dest=tmp_path,
        output=output,
        template_data=TemplateData(),
    )
    paths = walker.collect_paths()
    assert paths

    copier = Copier(
        output=output,
    )
    copier.copy_containers(paths)

    # Re-walk directory to generate new path list
    paths = walker.collect_paths()
    assert not paths


def test_ask_yes_no_yes(monkeypatch: pytest.MonkeyPatch) -> None:
    """Test ask_yes_no function with 'y' input.

    Args:
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the ask_yes_no function does not return True.
    """
    # Mock input to return 'y'
    monkeypatch.setattr("builtins.input", lambda _: "y")
    assert ask_yes_no("Do you want to continue?") is True


def test_ask_yes_no_no(monkeypatch: pytest.MonkeyPatch) -> None:
    """Test ask_yes_no function with 'n' input.

    Args:
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the ask_yes_no function does not return False.
    """
    # Mock input to return 'n'
    monkeypatch.setattr("builtins.input", lambda _: "n")
    assert ask_yes_no("Do you want to continue?") is False


def test_ask_yes_no_invalid_then_yes(monkeypatch: pytest.MonkeyPatch) -> None:
    """Test ask_yes_no function with invalid then 'y' input.

    Args:
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the ask_yes_no function does not return True.
    """
    # Mock input to return an invalid response first, then 'y'
    inputs = iter(["invalid", "y"])
    monkeypatch.setattr("builtins.input", lambda _: next(inputs))
    assert ask_yes_no("Do you want to continue?") is True


def test_ask_yes_no_invalid_then_no(monkeypatch: pytest.MonkeyPatch) -> None:
    """Test ask_yes_no function with invalid then 'n' input.

    Args:
        monkeypatch: Pytest monkeypatch fixture.

    Raises:
        AssertionError: If the ask_yes_no function does not return False.
    """
    # Mock input to return an invalid response first, then 'n'
    inputs = iter(["invalid", "n"])
    monkeypatch.setattr("builtins.input", lambda _: next(inputs))
    assert ask_yes_no("Do you want to continue?") is False

================
File: tests/__init__.py
================
"""Tests for ansible-creator."""

================
File: tests/conftest.py
================
"""conftest."""

from __future__ import annotations

import os
import subprocess

from pathlib import Path
from subprocess import CalledProcessError, CompletedProcess
from typing import Protocol

import pytest

from ansible_creator.output import Output
from ansible_creator.utils import TermFeatures


os.environ["HOME"] = str(Path.home())
os.environ["DEV_WORKSPACE"] = "collections/ansible_collections"


@pytest.fixture
def cli() -> CliRunCallable:
    """Fixture to run CLI commands.

    Returns:
        function: cli_run function.
    """
    return cli_run


@pytest.fixture
def output(tmp_path: Path) -> Output:
    """Create an Output class object as fixture.

    Args:
        tmp_path: Temporary path.

    Returns:
        Output: Output class object.
    """
    return Output(
        display="text",
        log_file=str(tmp_path) + "ansible-creator.log",
        log_level="notset",
        log_append="false",
        term_features=TermFeatures(color=False, links=False),
        verbosity=0,
    )


@pytest.fixture
def home_path() -> Path:
    """Create the home directory as a fixture.

    Returns:
        Path: Home directory.
    """
    return Path.home()


class CliRunCallable(Protocol):
    """Callable protocol for cli_run function."""

    def __call__(
        self,
        args: str,
        env: dict[str, str] | None = None,
    ) -> CompletedProcess[str] | CalledProcessError:
        """Run a command using subprocess.

        Args:
            args: Command to run.
            env: Supplemental environment variables.

        Returns:
            CompletedProcess: CompletedProcess object.
            CalledProcessError: CalledProcessError object.
        """


def cli_run(
    args: str,
    env: dict[str, str] | None = None,
) -> CompletedProcess[str] | CalledProcessError:
    """Run a command using subprocess.

    Args:
        args: Command to run.
        env: Supplemental environment variables.

    Returns:
        CompletedProcess: CompletedProcess object.
        CalledProcessError: CalledProcessError object.
    """
    updated_env = os.environ.copy()
    # this helps asserting stdout/stderr
    updated_env.update({"LINES": "40", "COLUMNS": "300", "TERM": "xterm-256color"})
    if env:
        updated_env.update(env)
    try:
        result = subprocess.run(
            args,
            shell=True,
            capture_output=True,
            check=True,
            text=True,
            env=updated_env,
        )
    except subprocess.CalledProcessError as err:
        return err
    return result

================
File: tests/defaults.py
================
"""Constants with default values used throughout the tests."""

from __future__ import annotations

from pathlib import Path


FIXTURES_DIR = (Path(__file__).parent / "fixtures").resolve()

UUID_LENGTH = 8

================
File: tools/report-coverage
================
#!/bin/bash
set -euo pipefail
coverage combine -q "--data-file=${TOX_ENV_DIR}/.coverage" "${TOX_ENV_DIR}"/.coverage.*
coverage xml "--data-file=${TOX_ENV_DIR}/.coverage" -o "${TOX_ENV_DIR}/coverage.xml" --ignore-errors --fail-under=0
COVERAGE_FILE="${TOX_ENV_DIR}/.coverage" coverage lcov --fail-under=0 --ignore-errors -q
COVERAGE_FILE="${TOX_ENV_DIR}/.coverage" coverage report --ignore-errors

================
File: .gitignore
================
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
junit.xml
nosetests.xml
coverage.xml
*.cover
*.lcov
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/



# In contrast to the entries above this line which largely come from
# untracked sources, the following have been inidividually rationalized
# and should all have detailed explanations

# Version created and populated by setuptools_scm
/src/*/_version.py

.DS_Store
node_modules
_readthedocs

================
File: .pre-commit-config.yaml
================
---
ci:
  # format compatible with commitlint
  autoupdate_commit_msg: "chore: pre-commit autoupdate"
  autoupdate_schedule: monthly
  autofix_commit_msg: "chore: auto fixes from pre-commit.com hooks"
  skip:
    # https://github.com/pre-commit-ci/issues/issues/55
    - ccv
    - lock
    # No docker on pre-commit.ci

repos:
  - repo: meta
    hooks:
      - id: check-useless-excludes
  - repo: https://github.com/rbubley/mirrors-prettier
    # keep it before yamllint
    rev: v3.6.2
    hooks:
      - id: prettier
        always_run: true
        additional_dependencies:
          - prettier
          - prettier-plugin-sort-json@3.1.0
  - repo: https://github.com/streetsidesoftware/cspell-cli
    rev: v9.2.0
    hooks:
      - id: cspell
        name: Spell check with cspell
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v5.0.0
    hooks:
      - id: check-added-large-files
      - id: check-merge-conflict
      - id: check-symlinks
      - id: debug-statements
      - id: detect-private-key
      - id: end-of-file-fixer
      - id: trailing-whitespace

  - repo: https://github.com/Lucas-C/pre-commit-hooks.git
    rev: v1.5.5
    hooks:
      - id: remove-tabs
        exclude: >
          (?x)^(
            .config/pydoclint-baseline.txt
          )$

  - repo: https://github.com/rbubley/mirrors-prettier
    rev: v3.6.2
    hooks:
      - id: prettier
        always_run: true
        additional_dependencies:
          - prettier
          - prettier-plugin-toml
          - prettier-plugin-sort-json

  - repo: https://github.com/pappasam/toml-sort
    rev: v0.24.2
    hooks:
      - id: toml-sort-fix
        alias: toml

  - repo: https://github.com/tox-dev/tox-ini-fmt
    rev: 1.6.0
    hooks:
      - id: tox-ini-fmt

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.12.7
    hooks:
      - id: ruff
        entry: sh -c 'ruff check --fix --force-exclude && ruff format --force-exclude'
  - repo: https://github.com/pre-commit/mirrors-mypy.git
    rev: v1.17.1
    hooks:
      - id: mypy
        additional_dependencies: &deps
          - argcomplete
          - jinja2
          - pytest
          - pyyaml
          - types-pyyaml
        # Override default pre-commit '--ignore-missing-imports'
        args: []
  - repo: https://github.com/jsh9/pydoclint
    rev: "0.6.7"
    hooks:
      - id: pydoclint
        # This allows automatic reduction of the baseline file when needed.
        entry: sh -ec "pydoclint . && pydoclint --generate-baseline=1 ."
        pass_filenames: false

  - repo: https://github.com/pycqa/pylint.git
    rev: v3.3.7
    hooks:
      - id: pylint
        args:
          - --output-format=colorized
        additional_dependencies: *deps

  # Keep last due to being considerably slower than the others:
  - repo: local
    hooks:
      - id: deps
        # To run it execute: `pre-commit run pip-compile-upgrade --hook-stage manual`
        name: Upgrade constraints files and requirements
        files: ^(pyproject\.toml|\.config/.*)$
        always_run: true
        language: python
        entry: python3 -m uv pip compile -q --all-extras --python-version=3.10 --output-file=.config/constraints.txt pyproject.toml --upgrade
        pass_filenames: false
        stages:
          - manual
        additional_dependencies:
          - uv>=0.6.6
      - id: lock
        name: Check constraints files and requirements
        files: ^(pyproject\.toml|\.config/.*)$
        language: python
        entry: uv pip compile -q --all-extras --python-version=3.10 --output-file=.config/constraints.txt pyproject.toml
        pass_filenames: false
        additional_dependencies:
          - uv>=0.6.6
  - repo: https://github.com/mashi/codecov-validator
    rev: "1.0.1"
    hooks:
      - id: ccv
        name: codecov

================
File: .prettierignore
================
# Stuff we don't want prettier to ever to look into
tests/fixtures/collection/testorg/testcol/roles/
tests/fixtures/collection/testorg/testcol/.github/workflows/tests.yml
tests/fixtures/project/playbook_project/collections/ansible_collections/project_org/project_repo/roles/run/README.md
tests/fixtures/project/playbook_project/.github/workflows/tests.yml
tests/fixtures/project/playbook_project/collections/ansible_collections/weather/demo/roles/run/README.md

================
File: .prettierrc.yaml
================
---
proseWrap: always
jsonRecursiveSort: true # prettier-plugin-sort-json
tabWidth: 2
useTabs: false
overrides:
  - files:
      - "*.md"
    options:
      # compatibility with markdownlint
      proseWrap: always
      printWidth: 80
  - files:
      - "*.yaml"
      - "*.yml"
    options:
      # compatibility with yamllint
      proseWrap: preserve

================
File: .python-version
================
3.10

# Needed by dependabot, see https://github.com/dependabot/dependabot-core/issues/1455

================
File: .readthedocs.yml
================
---
version: 2

mkdocs:
  fail_on_warning: true
  configuration: mkdocs.yml

build:
  os: ubuntu-24.04
  tools:
    python: "3.11"
  commands:
    - pip install --user tox
    - python3 -m tox -e docs
python:
  install:
    - method: pip
      path: tox
    - method: pip
      path: .
      extra_requirements:
        - docs
submodules:
  include: all
  recursive: true

================
File: .sonarcloud.properties
================
sonar.python.version=3.10, 3.11, 3.12, 3.13
sonar.sources=src/
sonar.tests=tests/

================
File: .taplo.toml
================
[formatting]
# cspell: disable-next-line
# compatibility between toml-sort-fix pre-commit hook and panekj.even-betterer-toml extension
align_comments = false
array_trailing_comma = false
compact_arrays = true
compact_entries = false
compact_inline_tables = true
inline_table_expand = false
reorder_keys = true

================
File: .tool-versions
================
nodejs 20.18.0

================
File: .yamllint
================
ignore: |
  .tox
  .pre-commit-config.yaml

================
File: ansible.cfg
================
# User during testing to ensure local user config does not affect testing

================
File: CHANGELOG.md
================
# Changelog

Please see the
[release notes](https://github.com/ansible-community/ansible-creator/releases).

================
File: codecov.yml
================
comment: false
coverage:
  status:
    patch: true

================
File: cspell.config.yaml
================
dictionaryDefinitions:
  - name: words
    path: .config/dictionary.txt
    addWords: true
dictionaries:
  - bash
  - networking-terms
  - python
  - words
  - "!aws"
  - "!backwards-compatibility"
  - "!cryptocurrencies"
  - "!cpp"
ignorePaths:
  - .config/requirements*
  - \.*
  - cspell.config.yaml
  - mkdocs.yml
  - pyproject.toml
  - tox.ini

languageSettings:
  - languageId: python
    allowCompoundWords: false

================
File: LICENSE
================
Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

================
File: mise.toml
================
[settings]
idiomatic_version_file_disable_tools = ["python"]

================
File: mkdocs.yml
================
---
# cspell:ignore autohide, autofix
site_name: Ansible Creator Documentation
site_url: https://ansible.readthedocs.io/projects/creator/
repo_url: https://github.com/ansible/ansible-creator
edit_uri: blob/main/docs/
copyright: Copyright © 2023 Red Hat, Inc.
docs_dir: docs
strict: true

# extra_css:
#   - stylesheets/extra.css

theme:
  name: ansible
  features:
    - announce.dismiss
    - content.action.edit
    - content.action.view
    - content.code.annotate
    - content.code.copy
    - content.tabs.link
    - content.tooltips
    - header.autohide
    - navigation.expand
    - navigation.footer
    - navigation.indexes
    - navigation.instant
    - navigation.path
    - navigation.prune
    - navigation.sections
    - navigation.tabs
    - navigation.tabs.sticky
    - navigation.top
    - navigation.tracking
    - search.highlight
    - search.share
    - search.suggest
    - toc.integrate
extra:
  generator: false
  social:
    - icon: fontawesome/brands/python
      link: https://pypi.org/project/ansible-creator/
      name: PyPI
    - icon: fontawesome/solid/scroll
      link: https://github.com/ansible/ansible-creator/releases
      name: Releases
    - icon: simple/mastodon
      link: https://fosstodon.org/@ansible
      name: Mastodon
    - icon: fontawesome/brands/twitter
      link: https://twitter.com/ansible
      name: Twitter
    - icon: simple/matrix
      link: https://matrix.to/#/#devtools:ansible.com
      name: Matrix
    - icon: fontawesome/brands/discourse
      link: https://forum.ansible.com/c/project/7
      name: Ansible forum
    - icon: fontawesome/brands/github-alt
      link: https://github.com/ansible/ansible-creator
      name: GitHub

nav:
  - Home:
      - home: index.md
  - Setup:
      - installing.md
      - content_creation.md
  - Contributing: contributing.md

exclude_docs: |
  _autofix_rules.md

plugins:
  - autorefs
  - macros:
      modules: [mkdocs-ansible:mkdocs_ansible]
  - markdown-exec
  - material/search:
      separator: '[\s\-,:!=\[\]()"`/]+|\.(?!\d)|&[lg]t;|(?!\b)(?=[A-Z][a-z])'
  - material/social
  - material/tags
  # https://github.com/manuzhang/mkdocs-htmlproofer-plugin
  # - htmlproofer

markdown_extensions:
  - markdown_include.include:
      base_path: docs
  - admonition
  - def_list
  - footnotes
  - pymdownx.highlight:
      anchor_linenums: true
  - pymdownx.inlinehilite
  - pymdownx.superfences
  - pymdownx.magiclink:
      repo_url_shortener: true
      repo_url_shorthand: true
      social_url_shorthand: true
      social_url_shortener: true
      user: facelessuser
      repo: pymdown-extensions
      normalize_issue_symbols: true
  - pymdownx.tabbed:
      alternate_style: true
  - toc:
      toc_depth: 2
      permalink: true
  - pymdownx.superfences:
      custom_fences:
        - name: mermaid
          class: mermaid
          format: !!python/name:pymdownx.superfences.fence_code_format
        - name: python
          class: python
          validator: !!python/name:markdown_exec.validator
          format: !!python/name:markdown_exec.formatter

================
File: package.json
================
{
  "devDependencies": {
    "@devcontainers/cli": "^0.80.0"
  }
}

================
File: pyproject.toml
================
[build-system]
build-backend = "setuptools.build_meta"
requires = [
  "setuptools >= 65.3.0", # required by pyproject+setuptools_scm integration and editable installs
  "setuptools_scm[toml] >= 7.0.5" # required for "no-local-version" scheme
]

[project]
authors = [{"email" = "nchakrab@redhat.com", "name" = "Nilashish Chakarborty"}]
classifiers = [
  'Development Status :: 5 - Production/Stable',
  'Intended Audience :: Developers',
  'License :: OSI Approved :: Apache Software License',
  'Operating System :: OS Independent',
  'Programming Language :: Python :: 3 :: Only',
  'Programming Language :: Python :: 3',
  'Programming Language :: Python :: 3.10',
  'Programming Language :: Python :: 3.11',
  'Programming Language :: Python :: 3.12',
  'Programming Language :: Python :: 3.13',
  'Programming Language :: Python :: Implementation :: CPython',
  'Programming Language :: Python',
  'Topic :: Software Development :: Code Generators',
  'Topic :: Utilities'
]
description = "A CLI tool for scaffolding Ansible Content."
dynamic = ["dependencies", "optional-dependencies", "version"]
keywords = ["ansible"]
license = {text = "Apache"}
maintainers = [{"email" = "info@ansible.com", "name" = "Ansible by Red Hat"}]
name = "ansible-creator"
readme = "README.md"
requires-python = ">=3.10"

[project.scripts]
ansible-creator = "ansible_creator.cli:main"

[project.urls]
changelog = "https://github.com/ansible/ansible-creator/releases"
documentation = "https://ansible.readthedocs.io/projects/creator/"
homepage = "https://github.com/ansible/ansible-creator"
repository = "https://github.com/ansible/ansible-creator"

[tool.coverage.report]
exclude_also = ["if TYPE_CHECKING:", "pragma: no cover"]
fail_under = 93
ignore_errors = true
show_missing = true
skip_covered = true
skip_empty = true
sort = "Cover"

[tool.coverage.run]
branch = false # https://github.com/nedbat/coveragepy/issues/605
concurrency = ["multiprocessing", "thread"]
omit = ["_version.py"]
parallel = true
source_pkgs = ["ansible_creator"]

[tool.mypy]
cache_dir = "./.cache/.mypy"
exclude = 'tests/fixtures'
files = ["src", "tests"]
strict = true

[[tool.mypy.overrides]]
ignore_missing_imports = true
module = ["pytest_ansible.molecule"]

[tool.pydoclint]
allow-init-docstring = true
arg-type-hints-in-docstring = false
baseline = ".config/pydoclint-baseline.txt"
check-return-types = false
exclude = '\.git|\.tox|build|out|venv'
should-declare-assert-error-if-assert-statement-exists = true
should-document-private-class-attributes = true
show-filenames-in-every-violation-message = true
skip-checking-short-docstrings = false
style = "google"

[tool.pylint]

[tool.pylint.format]
max-line-length = 100

[tool.pylint.master]
good-names = "i,j,k,ex,Run,_,f,fh"
ignore = [
  "_version.py", # built by setuptools_scm
  "test_integration.py" # will have a pytest-ansible import error
]
jobs = 0
no-docstring-rgx = "__.*__"

[tool.pylint.messages_control]
disable = [
  "unknown-option-value",
  # https://gist.github.com/cidrblock/ec3412bacfeb34dbc2d334c1d53bef83
  "C0103", # invalid-name / ruff N815
  "C0105", # typevar-name-incorrect-variance / ruff PLC0105
  "C0112", # empty-docstring / ruff D419
  "C0113", # unneeded-not / ruff SIM208
  "C0114", # missing-module-docstring / ruff D100
  "C0115", # missing-class-docstring / ruff D101
  "C0116", # missing-function-docstring / ruff D103
  "C0121", # singleton-comparison / ruff PLC0121
  "C0123", # unidiomatic-typecheck / ruff E721
  "C0131", # typevar-double-variance / ruff PLC0131
  "C0132", # typevar-name-mismatch / ruff PLC0132
  "C0198", # bad-docstring-quotes / ruff Q002
  "C0199", # docstring-first-line-empty / ruff D210
  "C0201", # consider-iterating-dictionary / ruff SIM118
  "C0202", # bad-classmethod-argument / ruff PLC0202
  "C0205", # single-string-used-for-slots / ruff PLC0205
  "C0208", # use-sequence-for-iteration / ruff PLC0208
  "C0301", # line-too-long / ruff E501
  "C0303", # trailing-whitespace / ruff W291
  "C0304", # missing-final-newline / ruff W292
  "C0321", # multiple-statements / ruff PLC0321
  "C0410", # multiple-imports / ruff E401
  "C0411", # wrong-import-order / ruff I001
  "C0412", # ungrouped-imports / ruff I001
  "C0413", # wrong-import-position / ruff E402
  "C0414", # useless-import-alias / ruff PLC0414
  "C0415", # import-outside-toplevel / ruff PLC0415
  "C0501", # consider-using-any-or-all / ruff PLC0501
  "C1901", # compare-to-empty-string / ruff PLC1901
  "C2201", # misplaced-comparison-constant / ruff SIM300
  "C2401", # non-ascii-name / ruff PLC2401
  "C2403", # non-ascii-module-import / ruff PLC2403
  "C2701", # import-private-name / ruff PLC2701
  "C2801", # unnecessary-dunder-call / ruff PLC2801
  "C3001", # unnecessary-lambda-assignment / ruff E731
  "C3002", # unnecessary-direct-lambda-call / ruff PLC3002
  "E0001", # syntax-error / ruff E999
  "E0100", # init-is-generator / ruff PLE0100
  "E0101", # return-in-init / ruff PLE0101
  "E0102", # function-redefined / ruff F811
  "E0103", # not-in-loop / ruff PLE0103
  "E0104", # return-outside-function / ruff F706
  "E0105", # yield-outside-function / ruff F704
  "E0107", # nonexistent-operator / ruff B002
  "E0112", # too-many-star-expressions / ruff F622
  "E0115", # nonlocal-and-global / ruff PLE0115
  "E0116", # continue-in-finally / ruff PLE0116
  "E0117", # nonlocal-without-binding / ruff PLE0117
  "E0118", # used-prior-global-declaration / ruff PLE0118
  "E0211", # no-method-argument / ruff N805
  "E0213", # no-self-argument / ruff N805
  "E0237", # assigning-non-slot / ruff PLE0237
  "E0241", # duplicate-bases / ruff PLE0241
  "E0302", # unexpected-special-method-signature / ruff PLE0302
  "E0303", # invalid-length-returned / ruff PLE0303
  "E0304", # invalid-bool-returned / ruff PLE0304
  "E0305", # invalid-index-returned / ruff PLE0305
  "E0308", # invalid-bytes-returned / ruff PLE0308
  "E0309", # invalid-hash-returned / ruff PLE0309
  "E0402", # relative-beyond-top-level / ruff TID252
  "E0602", # undefined-variable / ruff F821
  "E0603", # undefined-all-variable / ruff F822
  "E0604", # invalid-all-object / ruff PLE0604
  "E0605", # invalid-all-format / ruff PLE0605
  "E0643", # potential-index-error / ruff PLE0643
  "E0704", # misplaced-bare-raise / ruff PLE0704
  "E0711", # notimplemented-raised / ruff F901
  "E1132", # repeated-keyword / ruff PLE1132
  "E1142", # await-outside-async / ruff PLE1142
  "E1205", # logging-too-many-args / ruff PLE1205
  "E1206", # logging-too-few-args / ruff PLE1206
  "E1300", # bad-format-character / ruff PLE1300
  "E1301", # truncated-format-string / ruff F501
  "E1302", # mixed-format-string / ruff F506
  "E1303", # format-needs-mapping / ruff F502
  "E1304", # missing-format-string-key / ruff F524
  "E1305", # too-many-format-args / ruff F522
  "E1306", # too-few-format-args / ruff F524
  "E1307", # bad-string-format-type / ruff PLE1307
  "E1310", # bad-str-strip-call / ruff PLE1310
  "E1519", # singledispatch-method / ruff PLE1519
  "E1520", # singledispatchmethod-function / ruff PLE5120
  "E1700", # yield-inside-async-function / ruff PLE1700
  "E2502", # bidirectional-unicode / ruff PLE2502
  "E2510", # invalid-character-backspace / ruff PLE2510
  "E2512", # invalid-character-sub / ruff PLE2512
  "E2513", # invalid-character-esc / ruff PLE2513
  "E2514", # invalid-character-nul / ruff PLE2514
  "E2515", # invalid-character-zero-width-space / ruff PLE2515
  "E4703", # modified-iterating-set / ruff PLE4703
  "R0123", # literal-comparison / ruff F632
  "R0124", # comparison-with-itself / ruff PLR0124
  "R0133", # comparison-of-constants / ruff PLR0133
  "R0202", # no-classmethod-decorator / ruff PLR0202
  "R0203", # no-staticmethod-decorator / ruff PLR0203
  "R0205", # useless-object-inheritance / ruff UP004
  "R0206", # property-with-parameters / ruff PLR0206
  "R0904", # too-many-public-methods / ruff PLR0904
  "R0911", # too-many-return-statements / ruff PLR0911
  "R0912", # too-many-branches / ruff PLR0912
  "R0913", # too-many-arguments / ruff PLR0913
  "R0914", # too-many-locals / ruff PLR0914
  "R0915", # too-many-statements / ruff PLR0915
  "R0916", # too-many-boolean-expressions / ruff PLR0916
  "R1260", # too-complex / ruff C901
  "R1701", # consider-merging-isinstance / ruff PLR1701
  "R1702", # too-many-nested-blocks / ruff PLR1702
  "R1703", # simplifiable-if-statement / ruff SIM108
  "R1704", # redefined-argument-from-local / ruff PLR1704
  "R1705", # no-else-return / ruff RET505
  "R1706", # consider-using-ternary / ruff PLR1706
  "R1707", # trailing-comma-tuple / ruff COM818
  "R1710", # inconsistent-return-statements / ruff PLR1710
  "R1711", # useless-return / ruff PLR1711
  "R1714", # consider-using-in / ruff PLR1714
  "R1715", # consider-using-get / ruff SIM401
  "R1717", # consider-using-dict-comprehension / ruff C402
  "R1718", # consider-using-set-comprehension / ruff C401
  "R1719", # simplifiable-if-expression / ruff PLR1719
  "R1720", # no-else-raise / ruff RET506
  "R1721", # unnecessary-comprehension / ruff C416
  "R1722", # consider-using-sys-exit / ruff PLR1722
  "R1723", # no-else-break / ruff RET508
  "R1724", # no-else-continue / ruff RET507
  "R1725", # super-with-arguments / ruff UP008
  "R1728", # consider-using-generator / ruff C417
  "R1729", # use-a-generator / ruff C419
  "R1730", # consider-using-min-builtin / ruff PLR1730
  "R1731", # consider-using-max-builtin / ruff PLR1730
  "R1732", # consider-using-with / ruff SIM115
  "R1733", # unnecessary-dict-index-lookup / ruff PLR1733
  "R1734", # use-list-literal / ruff C405
  "R1735", # use-dict-literal / ruff C406
  "R1736", # unnecessary-list-index-lookup / ruff PLR1736
  "R2004", # magic-value-comparison / ruff PLR2004
  "R2044", # empty-comment / ruff PLR2044
  "R5501", # else-if-used / ruff PLR5501
  "R6002", # consider-using-alias / ruff UP006
  "R6003", # consider-alternative-union-syntax / ruff UP007
  "R6104", # consider-using-augmented-assign / ruff PLR6104
  "R6201", # use-set-for-membership / ruff PLR6201
  "R6301", # no-self-use / ruff PLR6301
  "W0102", # dangerous-default-value / ruff B006
  "W0104", # pointless-statement / ruff B018
  "W0106", # expression-not-assigned / ruff B018
  "W0107", # unnecessary-pass / ruff PIE790
  "W0108", # unnecessary-lambda / ruff PLW0108
  "W0109", # duplicate-key / ruff F601
  "W0120", # useless-else-on-loop / ruff PLW0120
  "W0122", # exec-used / ruff S102
  "W0123", # eval-used / ruff PGH001
  "W0127", # self-assigning-variable / ruff PLW0127
  "W0129", # assert-on-string-literal / ruff PLW0129
  "W0130", # duplicate-value / ruff B033
  "W0131", # named-expr-without-context / ruff PLW0131
  "W0133", # pointless-exception-statement / ruff PLW0133
  "W0150", # lost-exception / ruff B012
  "W0160", # consider-ternary-expression / ruff SIM108
  "W0177", # nan-comparison / ruff PLW0117
  "W0199", # assert-on-tuple / ruff F631
  "W0211", # bad-staticmethod-argument / ruff PLW0211
  "W0212", # protected-access / ruff SLF001
  "W0245", # super-without-brackets / ruff PLW0245
  "W0301", # unnecessary-semicolon / ruff E703
  "W0401", # wildcard-import / ruff F403
  "W0404", # reimported / ruff F811
  "W0406", # import-self / ruff PLW0406
  "W0410", # misplaced-future / ruff F404
  "W0511", # fixme / ruff PLW0511
  "W0602", # global-variable-not-assigned / ruff PLW0602
  "W0603", # global-statement / ruff PLW0603
  "W0604", # global-at-module-level / ruff PLW0604
  "W0611", # unused-import / ruff F401
  "W0612", # unused-variable / ruff F841
  "W0613", # unused-argument / ruff ARG001
  "W0622", # redefined-builtin / ruff A001
  "W0640", # cell-var-from-loop / ruff B023
  "W0702", # bare-except / ruff E722
  "W0705", # duplicate-except / ruff B014
  "W0706", # try-except-raise / ruff TRY302
  "W0707", # raise-missing-from / ruff TRY200
  "W0711", # binary-op-exception / ruff PLW0711
  "W0718", # broad-exception-caught / ruff PLW0718
  "W0719", # broad-exception-raised / ruff TRY002
  "W1113", # keyword-arg-before-vararg / ruff B026
  "W1201", # logging-not-lazy / ruff G
  "W1202", # logging-format-interpolation / ruff G
  "W1203", # logging-fstring-interpolation / ruff G
  "W1300", # bad-format-string-key / ruff PLW1300
  "W1301", # unused-format-string-key / ruff F504
  "W1302", # bad-format-string / ruff PLW1302
  "W1303", # missing-format-argument-key / ruff F524
  "W1304", # unused-format-string-argument / ruff F507
  "W1305", # format-combined-specification / ruff F525
  "W1308", # duplicate-string-formatting-argument / ruff PLW1308
  "W1309", # f-string-without-interpolation / ruff F541
  "W1310", # format-string-without-interpolation / ruff F541
  "W1401", # anomalous-backslash-in-string / ruff W605
  "W1404", # implicit-str-concat / ruff ISC001
  "W1405", # inconsistent-quotes / ruff Q000
  "W1406", # redundant-u-string-prefix / ruff UP025
  "W1501", # bad-open-mode / ruff PLW1501
  "W1508", # invalid-envvar-default / ruff PLW1508
  "W1509", # subprocess-popen-preexec-fn / ruff PLW1509
  "W1510", # subprocess-run-check / ruff PLW1510
  "W1514", # unspecified-encoding / ruff PLW1514
  "W1515", # forgotten-debug-statement / ruff T100
  "W1518", # method-cache-max-size-none / ruff B019
  "W1641", # eq-without-hash / ruff PLW1641
  "W2101", # useless-with-lock / ruff PLW2101
  "W2402", # non-ascii-file-name / ruff N999
  "W2901", # redefined-loop-name / ruff PLW2901
  "W3201", # bad-dunder-name / ruff PLW3201
  "W3301", # nested-min-max / ruff PLW3301
  "duplicate-code",
  "too-few-public-methods",
  "too-many-instance-attributes"
]
enable = [
  "useless-suppression"
]
fail-on = [
  "useless-suppression"
]

[tool.pytest.ini_options]
addopts = "-ra --showlocals --durations=10"
cache_dir = "./.cache/.pytest"
junit_family = "legacy" # see https://docs.codecov.com/docs/test-analytics
norecursedirs = "tests/fixtures"
testpaths = "tests"
tmp_path_retention_policy = "failed"
verbosity_assertions = 2

[tool.ruff]
builtins = ["__"]
cache-dir = "./.cache/.ruff"
exclude = ["tests/fixtures"]
fix = true
line-length = 100
target-version = "py310"

[tool.ruff.lint]
ignore = [
  "COM812", # conflicts with ISC001 on format
  "ISC001" # conflicts with COM812 on format
]
select = ["ALL"]

[tool.ruff.lint.flake8-pytest-style]
parametrize-values-type = "tuple"

[tool.ruff.lint.isort]
known-first-party = ["src"]
lines-after-imports = 2 # Ensures consistency for cases when there's variable vs function/class definitions after imports
lines-between-types = 1 # Separate import/from with 1 line
required-imports = ["from __future__ import annotations"]

[tool.ruff.lint.per-file-ignores]
"_version.py" = ["SIM108"]
"src/ansible_creator/resources/collection_project/tests/**" = ["SLF001", "S101", "S602", "T201"]
"src/ansible_creator/resources/collection_project/tests/unit/__init__.py" = ["D104"]
"tests/**" = ["SLF001", "S101", "S602", "T201"]

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.setuptools.dynamic]
dependencies = {file = [".config/requirements.in"]}
optional-dependencies.docs = {file = [".config/requirements-docs.in"]}
optional-dependencies.test = {file = [".config/requirements-test.in"]}

[tool.setuptools_scm]
# To prevent accidental pick of mobile version tags such 'v6'
git_describe_command = [
  "git",
  "describe",
  "--dirty",
  "--long",
  "--tags",
  "--match",
  "v*.*"
]
local_scheme = "no-local-version"
tag_regex = "^(?P<prefix>v)?(?P<version>\\d+[^\\+]*)(?P<suffix>.*)?$"
write_to = "src/ansible_creator/_version.py"

[tool.tomlsort]
in_place = true
sort_inline_tables = true
sort_table_keys = true

[tool.uv.pip]
annotation-style = "line"
custom-compile-command = "tox run -e deps"
no-emit-package = [
  "ansible-core",
  "exceptiongroup",
  "pip",
  "resolvelib",
  "ruamel-yaml-clib",
  "tomli",
  "typing_extensions",
  "uv"
]

================
File: README.md
================
[![codecov](https://codecov.io/github/ansible/ansible-creator/graph/badge.svg?token=QZKqxsNNsL)](https://codecov.io/github/ansible/ansible-creator)
[![PyPI - Status](https://img.shields.io/pypi/status/ansible-creator)](https://pypi.org/project/ansible-creator/)
[![PyPI - Version](https://img.shields.io/pypi/v/ansible-creator)](https://pypi.org/project/ansible-creator/)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ansible-creator)
![License](https://img.shields.io/github/license/ansible/ansible-creator)
[![Ansible Code of Conduct](https://img.shields.io/badge/Code%20of%20Conduct-Ansible-silver.svg)](https://docs.ansible.com/ansible/latest/community/code_of_conduct.html)
[![GitHub issues](https://img.shields.io/github/issues/ansible/ansible-creator)](https://github.com/ansible/ansible-creator/issues)

# ansible-creator

A CLI tool for scaffolding all your Ansible Content.

## Installation

```shell
pip install ansible-creator
```

```shell
$ ansible-creator --help
usage: ansible-creator [-h] command ...

The fastest way to generate all your ansible content.

Positional arguments:
 command
  add           Add resources to an existing Ansible project.
  init          Initialize a new Ansible project.

Options:
 --version      Print ansible-creator version and exit.
 -h     --help  Show this help message and exit
```

## Usage

Full documentation on how to use `ansible-creator`, including integration with
the VS Code Ansible Extension, is available in
[ansible-creator documentation](https://ansible.readthedocs.io/projects/creator/).

## Command line completion

`ansible-creator` has experimental command line completion for common shells.
Please ensure you have the `argcomplete` package installed and configured.

```shell
pip install argcomplete --user
activate-global-python-argcomplete --user
```

## Upcoming features

- Scaffold Ansible plugins of your choice with the `create` action. Switch to
  the [create](https://github.com/ansible-community/ansible-creator/tree/create)
  branch and try it out!

## Communication

Refer to the
[Get in Touch](https://ansible.readthedocs.io/projects/creator/contributing/#get-in-touch)
section of the Contributor Guide to find out how to communicate with us.

You can also find more information in the
[Ansible communication guide](https://docs.ansible.com/ansible/devel/community/communication.html).

## Contributing

See
[Contributing to ansible-creator](https://ansible.readthedocs.io/projects/creator/contributing/).

## Code of Conduct

Please see the
[Ansible Community Code of Conduct](https://docs.ansible.com/ansible/latest/community/code_of_conduct.html).

## Licensing

ansible-creator is released under the Apache License version 2.

See the [LICENSE](https://github.com/ansible/ansible-creator/blob/main/LICENSE)
file for more details.

================
File: tox.ini
================
[tox]
requires =
    tox>=4.23.2
    tox-uv>=1.20.2
env_list =
    py
    deps
    docs
    lint
    milestone
    pkg
skip_missing_interpreters = true

[testenv]
description = Run pytest under {basepython}
package = editable
extras =
    test
pass_env =
    CI
    CONTAINER_*
    DOCKER_*
    GITHUB_*
    HOME
    PYTEST_*
    SSH_AUTH_SOCK
    TERM
    USER
set_env =
    !milestone: PIP_CONSTRAINT = {toxinidir}/.config/constraints.txt
    !milestone: UV_CONSTRAINT = {toxinidir}/.config/constraints.txt
    COVERAGE_COMBINED = {envdir}/.coverage
    COVERAGE_FILE = {env:COVERAGE_FILE:{envdir}/.coverage.{envname}}
    COVERAGE_PROCESS_START = {toxinidir}/pyproject.toml
    FORCE_COLOR = 1
    PRE_COMMIT_COLOR = always
    TERM = xterm-256color
commands_pre =
    py{,310,311,312,313}: sh -c "rm -f {envdir}/.coverage* 2>/dev/null || true"
    py{,310,311,312,313}: sh -c "npm add -D @devcontainers/cli"
commands =
    python -c 'import pathlib; pathlib.Path("{env_site_packages_dir}/cov.pth").write_text("import coverage; coverage.process_startup()")'
    coverage run -m pytest {posargs:-n auto --junitxml=./junit.xml}
commands_post =
    py{,310,311,312,313}: ./tools/report-coverage
allowlist_externals =
    ./tools/report-coverage
    git
    rm
    sh

[testenv:deps]
description = Bump all dependencies
base_python = python3.10
skip_install = true
deps =
    {[testenv:lint]deps}
extras =
set_env =
    PIP_CONSTRAINT = /dev/null
    UV_CONSTRAINT = /dev/null
commands_pre =
commands =
    pre-commit run --all-files --show-diff-on-failure --hook-stage manual deps
    pre-commit run --all-files --show-diff-on-failure lock
    pre-commit autoupdate
    tox -e lint
    git diff --exit-code
env_dir = {toxworkdir}/lint

[testenv:docs]
description = Builds docs
package = editable
skip_install = false
extras =
    docs
set_env =
    DYLD_FALLBACK_LIBRARY_PATH = /opt/homebrew/lib:{env:LD_LIBRARY_PATH}
    NO_COLOR = 1
    TERM = dump
commands =
    mkdocs build {posargs:--strict --site-dir=_readthedocs/html/}

[testenv:lint]
description = Enforce quality standards under {basepython}
skip_install = true
deps =
    pre-commit
    pre-commit-uv>=4.1.4
    uv>=0.5.25
set_env =
    PIP_CONSTRAINT = /dev/null
    UV_CONSTRAINT = /dev/null
commands =
    pre-commit run --show-diff-on-failure --all-files

[testenv:milestone]
description =
    Run tests with ansible-core milestone branch and without dependencies constraints
deps =
    ansible-core@ https://github.com/ansible/ansible/archive/milestone.tar.gz
set_env =
    {[testenv]set_env}
    PIP_CONSTRAINT = /dev/null
    UV_CONSTRAINT = /dev/null

[testenv:pkg]
description =
    Do packaging/distribution
skip_install = true
deps =
    build>=0.9
    twine >= 4.0.2  # pyup: ignore
set_env =
commands =
    rm -rfv {toxinidir}/dist/
    python -m build --outdir {toxinidir}/dist/ {toxinidir}
    sh -c "python -m twine check --strict {toxinidir}/dist/*"




================================================================
End of Codebase
================================================================
