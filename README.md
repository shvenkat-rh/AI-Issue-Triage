# Gemini Issue Analyzer

![CI](https://github.com/shvenkat-rh/AI-Issue-Triage/actions/workflows/ci.yml/badge.svg)
[![Python 3.11+](https://img.shields.io/badge/python-3.11%20%7C%203.12%20%7C%203.13-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

An AI-powered issue analysis tool that uses Google's Gemini AI to perform comprehensive analysis of software issues based on your codebase content.

## Features

- **AI-Powered Analysis**: Uses Google Gemini 2.0 Flash for intelligent issue analysis with the latest [Google Gen AI SDK](https://googleapis.github.io/python-genai/)
- **Root Cause Analysis**: Identifies primary causes and contributing factors
- **Solution Generation**: Proposes specific code changes with rationale
- **Issue Triage**: Automatically classifies issues as bugs, enhancements, or feature requests
- **Severity Assessment**: Rates issues from low to critical priority
- **Code Location Mapping**: Identifies relevant files, functions, and classes
- **Export Capabilities**: Export analysis results in JSON format
- **Enhanced Performance**: Faster analysis with the latest Gemini 2.0 Flash model
- **Smart Retry Mechanism**: Automatically retries analysis if low-quality responses are detected
- **Security Protection**: Built-in prompt injection detection to protect against malicious inputs
- **Duplicate Detection**: Automatically identifies and flags duplicate issues
- **GitHub Actions Integration**: Automated issue analysis workflow for GitHub repositories

## Setup

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Get Gemini API Key

1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Create a new API key
3. Copy the `env_example.txt` to `.env` and add your API key:

```bash
cp env_example.txt .env
# Edit .env and add your API key
```

**Note**: The application now uses the latest [Google Gen AI SDK](https://googleapis.github.io/python-genai/) with the advanced `gemini-2.0-flash-001` model for faster and more accurate analysis.

### 3. Prepare Your Codebase

By default, the analyzer looks for a `repomix-output.txt` file in the project directory. This file should contain your codebase content generated by [Repomix](https://github.com/yamadashy/repomix).

To generate this file:
```bash
# Install repomix
npm install -g repomix

# Generate codebase file in your project directory
repomix --output repomix-output.txt
```

**Alternative**: You can use any text file containing your codebase content and specify its path using the `--source-path` option (see CLI usage below).

## Usage

The AI Issue Triage system can be used in three main ways:

### 1. GitHub Actions Workflow (Automated)

The most powerful way to use this system is through the automated GitHub Actions workflow, which provides continuous issue analysis for your repository.

#### Setup for GitHub Actions

1. **Add the workflow file** to your repository at `.github/workflows/gemini-issue-analysis.yml`
2. **Configure repository secrets**:
   - Go to your repository Settings â†’ Secrets and variables â†’ Actions
   - Add `GEMINI_API_KEY` with your Google Gemini API key
3. **Enable workflow permissions**:
   - Go to Settings â†’ Actions â†’ General
   - Set "Workflow permissions" to "Read and write permissions"

#### How It Works

When a new issue is opened in your repository, the workflow automatically:

1. **Security Check**: Scans for prompt injection attempts to protect the AI system
2. **Duplicate Detection**: Compares against existing issues to identify duplicates
3. **AI Analysis**: Performs comprehensive issue analysis using your codebase
4. **Auto-Labeling**: Adds appropriate labels based on issue type and severity
5. **Comment Generation**: Posts detailed analysis results as issue comments

#### Workflow Features

- **Security Protection**: Automatically detects and flags malicious prompt injection attempts
- **Duplicate Detection**: Identifies similar issues and prevents redundant analysis
- **Smart Labeling**: Adds labels like `type:bug`, `severity:high`, `gemini-analyzed`
- **Detailed Comments**: Posts comprehensive analysis directly to GitHub issues
- **Artifact Storage**: Saves analysis results and debug logs for review
- **Fast Processing**: Uses latest Gemini 2.0 Flash model for quick analysis

#### Workflow Configuration

The GitHub Actions workflow (`gemini-issue-analysis.yml`) can be customized for your needs:

```yaml
# Example workflow configuration
name: AI Issue Analysis

on:
  issues:
    types: [opened]  # Trigger on new issues

jobs:
  analyze-issue:
    runs-on: ubuntu-latest
    steps:
      # ... automated analysis steps
```

**Key Configuration Options:**
- **Trigger Events**: Modify `on.issues.types` to include `edited`, `reopened`, etc.
- **Repository Source**: Change the AI-Issue-Triage repository reference if using a fork
- **Node.js Version**: Adjust Node.js version for repomix compatibility
- **Python Version**: Modify Python version based on your requirements
- **Artifact Retention**: Adjust how long analysis artifacts are stored

#### Workflow Artifacts

The workflow generates several artifacts for debugging and audit purposes:

- **`prompt_injection_result.json`**: Security scan results
- **`prompt_injection_debug.log`**: Debug information for security checks
- **`duplicate_result.json`**: Duplicate detection results
- **`analysis_result.json`**: Complete AI analysis in JSON format
- **`analysis_result.txt`**: Human-readable analysis results
- **`repomix-output.txt`**: Generated codebase content

### 2. Web Interface (Interactive)

```bash
streamlit run app.py
```

This will open a web interface where you can:

1. **Enter your Gemini API key** in the sidebar
2. **Provide issue details**:
   - Issue Title
   - Detailed Description
3. **Click "Analyze Issue"** to get comprehensive analysis
4. **Review results** including:
   - Issue classification and severity
   - Root cause analysis
   - Proposed solutions with code changes
   - Confidence score
5. **Export results** as JSON for further use

### 3. Command Line Interface (CLI)

The analyzer also provides a powerful command-line interface for automation and scripting:

#### Quick Start
```bash
# Interactive mode - prompts for title and description
python cli.py

# Direct analysis
python cli.py --title "Login bug" --description "Users can't login on mobile devices"

# Analyze from file
python cli.py --file sample_issue.txt

# Use custom source of truth file
python cli.py --title "Bug" --description "Description" --source-path /path/to/my-codebase.txt

# Use custom prompt template
python cli.py --title "Bug" --description "Description" --custom-prompt /path/to/custom_prompt.txt

# Save output to file
python cli.py --title "Bug" --description "Description" --output analysis.txt

# JSON output for automation
python cli.py --title "Bug" --description "Description" --format json

# Quiet mode (no progress messages)
python cli.py --quiet --title "Bug" --description "Description"

# Configure retry attempts for better quality
python cli.py --title "Bug" --description "Description" --retries 3
```

#### CLI Options
```
positional arguments:
  none

options:
  -h, --help            show this help message and exit
  --title TITLE, -t TITLE
                        Issue title
  --description DESCRIPTION, -d DESCRIPTION
                        Issue description  
  --file FILE, -f FILE  Read issue from file (title on first line, description below)
  --output OUTPUT, -o OUTPUT
                        Output file (default: stdout)
  --format {text,json}  Output format (default: text)
  --source-path SOURCE_PATH, -s SOURCE_PATH
                        Path to source of truth file (default: repomix-output.txt)
  --api-key API_KEY     Gemini API key (default: from GEMINI_API_KEY env var)
  --quiet, -q           Suppress progress messages
  --version             show program's version number and exit
```

#### File Format for --file option
```
Issue Title Here
Issue description starts here.
Can be multiple lines.
Include all relevant details.
```

### Command Line Usage (Programmatic)

You can also use the analyzer programmatically:

```python
from gemini_analyzer import GeminiIssueAnalyzer

# Initialize analyzer with default source path
analyzer = GeminiIssueAnalyzer(api_key="your-api-key")

# Or initialize with custom source path
analyzer = GeminiIssueAnalyzer(
    api_key="your-api-key",
    source_path="/path/to/your/codebase.txt"
)

# Note: The analyzer now uses the Google Gen AI SDK with gemini-2.0-flash-001

# Analyze an issue
analysis = analyzer.analyze_issue(
    title="Login page crashes on mobile",
    issue_description="When users try to login on mobile devices, the app crashes..."
)

print(f"Issue Type: {analysis.issue_type}")
print(f"Severity: {analysis.severity}")
print(f"Root Cause: {analysis.root_cause_analysis.primary_cause}")
```

## Source of Truth Configuration

The analyzer uses a "source of truth" file containing your codebase content to perform intelligent analysis. This gives the AI context about your specific code structure, patterns, and implementation details.

### Default Behavior
- By default, the analyzer looks for `repomix-output.txt` in the current directory
- This file should contain your complete codebase content

### Custom Source Path
You can specify a different source file using the `--source-path` option:

```bash
# Use a custom codebase file
python cli.py --source-path /path/to/my-project-dump.txt --title "Issue" --description "Details"

# Use a file in a different directory
python cli.py -s ../other-project/codebase.txt --title "Issue" --description "Details"
```

### Supported File Formats
- Any plain text file containing your codebase
- Generated by tools like [Repomix](https://github.com/yamadashy/repomix)
- Manual concatenation of source files
- Output from other code analysis tools

### Best Practices
- Include all relevant source files in your source of truth
- Keep the file updated when your codebase changes
- Consider excluding large binary files or dependencies
- Include configuration files, documentation, and tests for better analysis

## Custom Prompt Templates

You can customize how the AI analyzes your issues by providing your own prompt template. This gives you complete control over the analysis style and focus areas.

### Creating a Custom Prompt

1. **Create a text file** with your custom prompt template
2. **Use placeholders** for dynamic content:
   - `{title}` - Issue title
   - `{issue_description}` - Issue description  
   - `{codebase_content}` - Full codebase content

3. **Example custom prompt** (`my_prompt.txt`):
```
You are a security-focused code reviewer analyzing the following issue:

Title: {title}
Description: {issue_description}

Codebase: {codebase_content}

Focus on:
- Security vulnerabilities
- Input validation issues
- Authentication/authorization problems
- Data exposure risks

Provide analysis in JSON format with security_risks field.
```

### Using Custom Prompts

```bash
# CLI usage
python cli.py --title "Security Issue" --description "Details..." --custom-prompt my_prompt.txt

# Web UI usage
# Enter the path in the "Custom Prompt Path" field in the sidebar
```

### Custom Prompt Use Cases
- **Security Analysis**: Focus on vulnerabilities and security best practices
- **Performance Review**: Emphasize performance optimization opportunities
- **Architecture Review**: Concentrate on design patterns and architectural improvements
- **Compliance Check**: Ensure code meets specific coding standards or regulations
- **Domain-Specific**: Tailor analysis for specific frameworks or technologies

## Security Features

The AI Issue Triage system includes comprehensive security protections to prevent misuse and protect the AI analysis system.

### Prompt Injection Detection

The system automatically scans all issue content for potential prompt injection attempts using:

- **Machine Learning Detection**: Uses the `pytector` library with trained models
- **Pattern-Based Detection**: Custom regex patterns for common injection techniques
- **Heuristic Analysis**: Behavioral analysis for suspicious content patterns

### Detection Categories

The system identifies various types of malicious inputs:

- **Role Manipulation**: Attempts to change the AI's role or persona
- **System Prompts**: Trying to inject system-level instructions
- **Instruction Bypass**: Commands to ignore previous instructions
- **File Manipulation**: Requests to create, modify, or access files
- **Code Injection**: Attempts to execute arbitrary code
- **Data Extraction**: Trying to extract sensitive information
- **Prompt Leakage**: Attempts to reveal system prompts

### Risk Levels

Issues are classified into risk levels:

- **Critical**: Severe injection attempts (flagged and processing stopped)
- **High**: Clear malicious intent (flagged with warning)
- **Medium**: Suspicious patterns (flagged for review)
- **Low**: Minor concerns (noted but processed)
- **Safe**: No security concerns detected

### Security Response

When prompt injection is detected:

1. **Issue Flagging**: Adds security labels (`security-alert`, `prompt-injection-detected`)
2. **Warning Comment**: Posts educational message explaining the detection
3. **Processing Halt**: Stops AI analysis to prevent system manipulation
4. **Audit Trail**: Logs detection details for security review

## Duplicate Detection

The system includes intelligent duplicate detection to prevent redundant analysis and improve issue management.

### How It Works

- **Semantic Analysis**: Uses AI to understand issue meaning beyond exact text matches
- **Similarity Scoring**: Calculates confidence scores for potential duplicates
- **Context Awareness**: Considers issue status, labels, and resolution state
- **Cross-Reference**: Compares against all existing open issues

### Duplicate Handling

When duplicates are detected:
- **Automatic Labeling**: Adds `duplicate` label
- **Reference Comment**: Links to the original issue
- **Processing Skip**: Avoids redundant AI analysis
- **Consolidation**: Helps maintainers merge related issues

## Smart Retry Mechanism

The analyzer includes an intelligent retry system that automatically detects low-quality responses and retries the analysis for better results.

### How It Works

The system automatically identifies responses that contain:
- Generic phrases like "requires further investigation" or "to be determined"
- Very low confidence scores (< 60%)
- Vague file paths or empty solutions
- Short or incomplete analysis summaries

### Configuration

```bash
# Default: 2 retries
python cli.py --title "Issue" --description "Details"

# Custom retry count
python cli.py --title "Issue" --description "Details" --retries 3

# Disable retries
python cli.py --title "Issue" --description "Details" --retries 0
```

### Benefits

- **Higher Quality**: Automatically improves analysis quality
- **Reliability**: Reduces chance of getting generic responses  
- **Transparency**: Shows retry attempts in progress messages
- **Configurable**: Adjust retry count based on your needs

## Analysis Components

### Issue Classification
- **Bug**: Issues that represent errors or defects
- **Enhancement**: Improvements to existing functionality
- **Feature Request**: New functionality requests

### Severity Levels
- **Critical**: System-breaking issues requiring immediate attention
- **High**: Important issues affecting core functionality
- **Medium**: Moderate impact issues
- **Low**: Minor issues with minimal impact

### Root Cause Analysis
- Primary cause identification
- Contributing factors
- Affected components
- Related code locations

### Solution Proposals
- Specific code changes
- Implementation rationale
- Target locations (files, functions, classes)
- Step-by-step implementation guidance

## Example Analysis

```json
{
  "title": "Authentication timeout not handled properly",
  "issue_type": "bug",
  "severity": "high",
  "root_cause_analysis": {
    "primary_cause": "Missing timeout exception handling in auth module",
    "contributing_factors": [
      "No retry mechanism implemented",
      "User feedback on timeout missing"
    ],
    "affected_components": ["authentication", "user_session"],
    "related_code_locations": [
      {
        "file_path": "src/auth/login.py",
        "line_number": 45,
        "function_name": "authenticate_user"
      }
    ]
  },
  "proposed_solutions": [
    {
      "description": "Add timeout exception handling with user feedback",
      "code_changes": "try:\n    response = auth_request()\nexcept TimeoutError:\n    return {'error': 'Authentication timeout'}",
      "location": {
        "file_path": "src/auth/login.py",
        "function_name": "authenticate_user"
      },
      "rationale": "Provides graceful error handling and user feedback"
    }
  ],
  "confidence_score": 0.85
}
```

## Testing

The project includes a comprehensive test suite to ensure code quality and reliability.

### Continuous Integration

Automated quality checks run on every pull request and push to main via GitHub Actions.

#### CI Workflow (`ci.yml`) - **All-in-One Status Check**
The main CI workflow combines all checks into a single status:
- **âœ… Unit Tests**: Run on Python 3.11, 3.12, and 3.13
- **âœ… Lint Checks**: Black, isort, and flake8
- **ðŸŸ¢ Single Status**: Only turns green when ALL checks pass
- **ðŸš« Branch Protection**: Use "CI / All Checks Pass" as required status check

The CI workflow runs both unit tests and linting, providing a single green checkmark when everything passes. This makes it easy to set up branch protection rules.

See `.github/workflows/` for configuration details.

### Running Tests Locally

```bash
# Run all tests
pytest tests/

# Run with verbose output
pytest tests/ -v

# Run with coverage report (optional, requires pytest-cov)
# pytest tests/ --cov=. --cov-report=html

# Run only unit tests (no API required)
pytest tests/ -m unit -v

# Run only integration tests (requires API key)
pytest tests/ -m integration -v

# Run specific test file
pytest tests/test_models.py -v

# Use the test runner script
python run_tests.py
```

### Running Linting Checks Locally

Before pushing code, run these checks locally:

```bash
# Install linting tools
pip install black isort flake8 flake8-docstrings flake8-bugbear

# Auto-fix formatting issues
black .
isort .

# Check formatting without fixing
black --check --diff .
isort --check-only --diff .

# Run flake8 linting
flake8 . --max-line-length=127 --extend-ignore=E203,W503

# Run all checks at once
black . && isort . && flake8 .
```

### Test Organization

```
tests/
â”œâ”€â”€ __init__.py                       # Package initialization
â”œâ”€â”€ conftest.py                       # Pytest configuration & fixtures
â”œâ”€â”€ test_models.py                    # Tests for data models (64 tests total)
â”œâ”€â”€ test_gemini_analyzer.py           # Tests for Gemini analyzer
â”œâ”€â”€ test_duplicate_analyzer.py        # Tests for Gemini duplicate detection
â”œâ”€â”€ test_cosine_duplicate_analyzer.py # Tests for cosine similarity analyzer
â””â”€â”€ README.md                         # Detailed test documentation
```

### Test Features

- **64 comprehensive test cases** covering all major functionality
- **Unit tests**: Fast tests that don't require API access
- **Integration tests**: Tests that interact with Gemini API
- **Fixtures**: Reusable test data and setup
- **Markers**: Categorize tests by type (unit, integration, slow)

See `tests/README.md` for detailed testing documentation.

## Project Structure

```
AI-Issue-Triage/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ gemini-issue-analysis.yml  # Auto issue analysis workflow
â”‚       â””â”€â”€ ci.yml                     # Combined CI workflow (tests + lint)
â”œâ”€â”€ tests/                      # Comprehensive test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_gemini_analyzer.py
â”‚   â”œâ”€â”€ test_duplicate_analyzer.py
â”‚   â”œâ”€â”€ test_cosine_duplicate_analyzer.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ app.py                      # Streamlit web interface
â”œâ”€â”€ cli.py                      # Command-line interface
â”œâ”€â”€ gemini_analyzer.py          # Core analyzer class
â”œâ”€â”€ models.py                   # Pydantic data models and enums
â”œâ”€â”€ prompt_injection.py         # Security: Prompt injection detection
â”œâ”€â”€ duplicate_analyzer.py       # Duplicate detection logic
â”œâ”€â”€ duplicate_cli.py            # CLI for duplicate detection
â”œâ”€â”€ cosine_duplicate_analyzer.py # Cosine similarity duplicate detection
â”œâ”€â”€ duplicate_cosine_cli.py     # CLI for cosine-based duplicate detection
â”œâ”€â”€ run_app.py                  # Application runner
â”œâ”€â”€ run_tests.py                # Test runner with options
â”œâ”€â”€ pytest.ini                  # Pytest configuration
â”œâ”€â”€ pyproject.toml              # Black, isort, and coverage configuration
â”œâ”€â”€ .flake8                     # Flake8 linting configuration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .gitignore                  # Git ignore patterns
â”œâ”€â”€ env_example.txt             # Environment variables template
â”œâ”€â”€ README.md                   # This documentation
â”œâ”€â”€ sample_issue.txt            # Example issue for testing
â”œâ”€â”€ sample_issues.json          # Sample issues data
â””â”€â”€ repomix-output.txt         # Your codebase content (generated)
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## License

This project is open source and available under the MIT License.

## Support

For issues and questions:
1. Check the existing issues
2. Create a new issue with detailed description
3. Include your environment details and error messages

---

**Note**: This tool requires a valid Google Gemini API key. Usage may incur costs based on Google's pricing for the Gemini API.
